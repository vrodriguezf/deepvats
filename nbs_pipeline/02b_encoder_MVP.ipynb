{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0772dd88-bbee-46b3-859d-d6db0bbeb148",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "print_flag                    = None\n",
    "check_memory_usage            = None\n",
    "time_flag                     = None\n",
    "window_size_percentage        = None\n",
    "show_plots                    = None\n",
    "reset_kernel                  = None\n",
    "pre_configured_case           = None\n",
    "case_id                       = None\n",
    "frequency_factor              = None\n",
    "frequency_factor_change_alias = None\n",
    "check_parameters              = True\n",
    "cuda_device                   = None"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e0213e9-bf48-49f2-b797-822ff61d9116",
   "metadata": {},
   "source": [
    "## Checking input parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2bbd02d3-184a-4efd-afe8-a6d1d323c13b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Check parameters ---\n",
      "print_flag: None check_memory_usage None time_flag: None window_size_percentage: None show_plots: None reset_kernel: None pre_configured_case: None case_id: None frequency_factor: None frequency_factor_change_alias None cuda_device None\n"
     ]
    }
   ],
   "source": [
    "if check_parameters:\n",
    "    print(\"--- Check parameters ---\")\n",
    "    print(\n",
    "        \"print_flag:\", print_flag,\n",
    "        \"check_memory_usage\", check_memory_usage,\n",
    "        \"time_flag:\", time_flag,\n",
    "        \"window_size_percentage:\" , window_size_percentage,\n",
    "        \"show_plots:\",show_plots,\n",
    "        \"reset_kernel:\",reset_kernel,\n",
    "        \"pre_configured_case:\",pre_configured_case,\n",
    "        \"case_id:\",case_id,\n",
    "        \"frequency_factor:\", frequency_factor, \n",
    "        \"frequency_factor_change_alias\", frequency_factor_change_alias,\n",
    "        \"cuda_device\", cuda_device\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d7674d1-7376-457d-bda1-968f4c8a6e04",
   "metadata": {},
   "source": [
    "## Set default input parameter values ensuring no errors\n",
    "### Values explained below in their natural execution place"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5cb62ce7-315a-4396-ae27-21fa32dc03a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "print_flag                    = True  if print_flag is None else print_flag\n",
    "check_memory_usage            = True  if check_memory_usage is None else check_memory_usage\n",
    "time_flag                     = True  if time_flag is None else time_flag\n",
    "window_size_percentage        = False if window_size_percentage is None else window_size_percentage\n",
    "show_plots                    = False if show_plots is None else show_plots\n",
    "reset_kernel                  = False  if reset_kernel is None else reset_kernel\n",
    "pre_configured_case           = True if pre_configured_case is None else pre_configured_case\n",
    "case_id                       = 7 if case_id is None else case_id\n",
    "frequency_factor              = 1 if frequency_factor is None else frequency_factor\n",
    "frequency_factor_change_alias = True if frequency_factor_change_alias is None else frequency_factor_change_alias\n",
    "cuda_device                   = 0 if  cuda_device is None else cuda_device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b72e5230-99b5-41ab-b848-02701320f74c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Check parameters ---\n",
      "print_flag: True check_memory_usage True time_flag: True window_size_percentage: False show_plots: False reset_kernel: False pre_configured_case: True case_id: 7 frequency_factor: 1 frequency_factor_change_alias True cuda_device 0\n"
     ]
    }
   ],
   "source": [
    "if check_parameters:\n",
    "    print(\"--- Check parameters ---\")\n",
    "    print(\n",
    "        \"print_flag:\", print_flag,\n",
    "        \"check_memory_usage\", check_memory_usage,\n",
    "        \"time_flag:\", time_flag,\n",
    "        \"window_size_percentage:\" , window_size_percentage,\n",
    "        \"show_plots:\",show_plots,\n",
    "        \"reset_kernel:\",reset_kernel,\n",
    "        \"pre_configured_case:\",pre_configured_case,\n",
    "        \"case_id:\",case_id,\n",
    "        \"frequency_factor:\", frequency_factor, \n",
    "        \"frequency_factor_change_alias\", frequency_factor_change_alias,\n",
    "        \"cuda_device\", cuda_device\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7b6c9b7-dd2a-4d74-bf5a-cedadcc9347f",
   "metadata": {},
   "source": [
    "# Encoder - MVP\n",
    "\n",
    "> Self supervised learning Masked Value Prediction (MVP) as a way to create the embeddings.\n",
    "Based on tsai's MVP"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03d63d7b-2b27-4180-9f43-ca9851300300",
   "metadata": {},
   "source": [
    "## Set-up\n",
    "Initial notebook setup and specific debugging and pre-configured cases selection.\n",
    "### VsCode update patch\n",
    "Initial notebook setup when using VSCode."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "185023c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "# This is only needed if the notebook is run in VSCode\n",
    "import sys\n",
    "import dvats.utils as ut\n",
    "if '--vscode' in sys.argv:\n",
    "    print(\"Executing inside vscode\")\n",
    "    ut.DisplayHandle.update = ut.update_patch"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbf364a8-70c8-4b35-b8b9-3b0c57c6c135",
   "metadata": {},
   "source": [
    "### Debugging variables\n",
    "\n",
    "- `print_flag`. If `True` it adds debbuging messages in those functions that allows so.\n",
    "- `reset_kernel`. If `True` it resets the kernel by the end of the execution. Use only in case that memory management is needed.\n",
    "- `check_memory_usage`. If `True`, it adds some lines for checking the GPU memmory ussage along the execution.\n",
    "- `time_flag`. If `True` it get the execution time along the notebook as well as inside those functions that allows so.\n",
    "- `window_size_percentage`. If `True`, MVP will be used directly with the proposed windows sizes. Otherwise, it will be asumed that they have been taken as absolute values and execution will be take that into account.\n",
    "- `show_plots`. If `True` all plots are shown within the execution of the notebook. Otherwise, none of them will be plotted."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7cc9958b-a998-430e-9a2f-cdec06815e82",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "##### ----- This cell should be substituted by input parameters ------ #####\n",
    "##### See _ploomber_engine_example_.ipynb\n",
    "##### Uncomment for direct Notebook execution\n",
    "#print_flag             = True\n",
    "#reset_kernel           = True\n",
    "#check_memory_usage     = True\n",
    "#time_flag              = True\n",
    "#window_size_percentage = True\n",
    "#show_plots             = True"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0393011d-2b66-463c-8607-1eddb975bf65",
   "metadata": {},
   "source": [
    "## Preconfigurated cases selection\n",
    "- `pre_configured_case`. If `True`, a preconfigured case will be selected, forcing the artifact to get the expected configuration based on the information in `config\\*.yml` and `utils\\config.py`.\n",
    "- `case_id`. If `preconfigured_case` is `True`, it forces to select the configuration of the `case_id` preconfigured samples. The available preconfigured samples are shown in the next cell.\n",
    "- `frequency_factor`. If `pre_configured_case` is `True`, frequency will be resampled by `config.freq*frequency_factor`\n",
    "  `frequency_factor_change_alias`. If `pre_configured_case` is `True` and `frequency_factor != 1` then the dataset alias will be modified for adding the new frequency as suffix."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "72ded847-f1d7-4f3d-a199-9602449299e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "import dvats.config as cfg_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "141be463",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Available datasets: \n",
      "0 - monash_australian_electricity_demand_0\n",
      "1 - monash_solar_4_seconds_0\n",
      "2 - wikipedia_0\n",
      "3 - traffic_san_francisco_0\n",
      "4 - monash_solar_10_minutes_0\n",
      "5 - etth1_0\n",
      "6 - stumpy_abp_0\n",
      "7 - stumpy_toy_0\n"
     ]
    }
   ],
   "source": [
    "#| hide\n",
    "cfg_.show_available_configs()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "505328e7-6162-4090-b17d-4b664d8ceef1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export \n",
    "##### ----- This cell should be substituted by input parameters ------ #####\n",
    "##### See _ploomber_engine_example_.ipynb\n",
    "##### Uncomment for direct Notebook execution\n",
    "#pre_configured_case = False\n",
    "#case_id = None\n",
    "#frequency_factor = 1\n",
    "#frequency_factor_change_alias = True"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54333729-4770-4315-9416-e1d8b17d8235",
   "metadata": {},
   "source": [
    "## Main code\n",
    "### Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4a511d12-df7f-420e-b570-f37bc13d1781",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[?2004l\n",
      "Octave is ready <oct2py.core.Oct2Py object at 0x7fb24c6efc70>\n",
      "\u001b[?2004l\n",
      "\u001b[?2004l\n",
      "\u001b[?2004l\n",
      "\u001b[?2004l\n",
      "\u001b[?2004l\n",
      "\u001b[?2004l\n",
      "\u001b[?2004l\n",
      "\u001b[?2004l\n",
      "\u001b[?2004l\n",
      "\u001b[?2004l\n",
      "\u001b[?2004l\n",
      "\u001b[?2004l\n",
      "\u001b[?2004l\n",
      "\u001b[?2004l\n",
      "\u001b[?2004l\n"
     ]
    }
   ],
   "source": [
    "#| export\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", module=\"umap\")\n",
    "import os\n",
    "import sys\n",
    "sys.path.append(os.path.abspath('..'))\n",
    "from dvats.all import *\n",
    "from fastcore.all import *\n",
    "from tsai.basics import *\n",
    "from tsai.models.InceptionTimePlus import *\n",
    "from tsai.callback.MVP import *\n",
    "import matplotlib.colors as colors\n",
    "from fastai.callback.wandb import WandbCallback\n",
    "from fastai.callback.progress import ShowGraphCallback\n",
    "from fastai.callback.schedule import *\n",
    "from fastai.callback.tracker import EarlyStoppingCallback\n",
    "import wandb"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42a0deb6-ffc2-44ce-aa19-b658a4640b63",
   "metadata": {},
   "source": [
    "### Initialize and Configurate Artifact"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ec3cf58a-8b57-4f6d-a577-f0643b66ee25",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "wandb_api = wandb.Api()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "991646a6-d976-4183-be76-8cf01c25b059",
   "metadata": {},
   "source": [
    "#### Setup CUDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "cb164924-13e2-4099-ba35-06e675035d34",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU | Used mem: 2\n",
      "GPU | Used mem: 24\n",
      "GPU | Memory Usage: [\u001b[90mâ–ˆ-------------------\u001b[0m] \u001b[90m8%\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "#| export\n",
    "device = torch.device(f'cuda:{cuda_device}' if torch.cuda.is_available() else 'cpu')\n",
    "torch.cuda.set_device(device)\n",
    "if check_memory_usage:\n",
    "    gpu_device = torch.cuda.current_device()\n",
    "    gpu_memory_status(gpu_device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28cb7848-0ac0-4f55-a6e6-49478d7cac25",
   "metadata": {},
   "source": [
    "### Get configutation from yml\n",
    "> This file used the configuration files './config/base.yml' and './config/02b_encoder_MVP.ipynb'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "5b845205-b133-4ee1-baaf-acc2ddd6533b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[93m\u001b[1martifact_name is missing in original dict | toy \u001b[0m\n",
      "mask_future: False\u001b[0m\n",
      "norm_by_sample: False\u001b[0m\n",
      "\u001b[93m\u001b[1mcsv_config is missing in original dict | {} \u001b[0m\n",
      "\u001b[94malias: S3\u001b[0m -> toy\u001b[0m\n",
      "\u001b[93m\u001b[1mtime_col is missing in original dict | None \u001b[0m\n",
      "r: 0.71\u001b[0m\n",
      "norm_use_single_batch: False\u001b[0m\n",
      "mask_sync: False\u001b[0m\n",
      "\u001b[94mmvp_ws: (25, 50)\u001b[0m -> [10, 30]\u001b[0m\n",
      "\u001b[94mbatch_size: 512\u001b[0m -> 32\u001b[0m\n",
      "valid_artifact: None\u001b[0m\n",
      "\u001b[94mstride: 9\u001b[0m -> 1\u001b[0m\n",
      "mask_stateful: True\u001b[0m\n",
      "valid_size: 0.2\u001b[0m\n",
      "\u001b[93m\u001b[1mfreq is missing in original dict | 1s \u001b[0m\n",
      "epochs: 100\u001b[0m\n",
      "use_wandb: True\u001b[0m\n",
      "\u001b[94mtrain_artifact: mi-santamaria/deepvats/S3:latest\u001b[0m -> mi-santamaria/deepvats/toy:latest\u001b[0m\n",
      "\u001b[93m\u001b[1mnorm_use_by_single_batch is missing in original dict | (False,) \u001b[0m\n",
      "analysis_mode: online\u001b[0m\n",
      "\u001b[93m\u001b[1mdata_fpath is missing in original dict | ~/data/toy.csv \u001b[0m\n",
      "\u001b[94mw: 50\u001b[0m -> 30\u001b[0m\n",
      "\u001b[93m\u001b[1mdata_cols is missing in original dict | [] \u001b[0m\n",
      "wandb_group: None\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "#| export\n",
    "user, project, version, data, config, job_type = cfg_.get_artifact_config_MVP(False)\n",
    "if pre_configured_case: \n",
    "    cfg_.force_artifact_config_mvp(\n",
    "        config = config,\n",
    "        id = case_id,\n",
    "        print_flag = print_flag, \n",
    "        both = print_flag,\n",
    "        frequency_factor = frequency_factor,\n",
    "        frequency_factor_change_alias = frequency_factor_change_alias\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71052bbf-f65b-45ea-aa8f-e3ee665f27ba",
   "metadata": {},
   "source": [
    "### Setup Weights & biases artiffact"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f30caa23",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "runname: 02a_encoder_MVP\n",
      "alias: toy\n",
      "analysis_mode: online\n",
      "batch_size: 32\n",
      "epochs: 100\n",
      "mask_future: False\n",
      "mask_stateful: True\n",
      "mask_sync: False\n",
      "mvp_ws: [10, 30]\n",
      "norm_by_sample: False\n",
      "norm_use_single_batch: False\n",
      "r: 0.71\n",
      "stride: 1\n",
      "train_artifact: mi-santamaria/deepvats/toy:latest\n",
      "valid_artifact: None\n",
      "use_wandb: True\n",
      "valid_size: 0.2\n",
      "w: 30\n",
      "wandb_group: None\n",
      "artifact_name: toy\n",
      "data_cols: []\n",
      "data_fpath: ~/data/toy.csv\n",
      "freq: 1s\n",
      "time_col: None\n",
      "csv_config: {}\n",
      "norm_use_by_single_batch: (False,)\n"
     ]
    }
   ],
   "source": [
    "#| export\n",
    "path = os.path.expanduser(\"~/work/nbs_pipeline/\")\n",
    "name=\"02a_encoder_MVP\"\n",
    "os.environ[\"WANDB_NOTEBOOK_NAME\"] = path+name+\".ipynb\"\n",
    "runname=name\n",
    "if print_flag: print(\"runname: \"+runname)\n",
    "if print_flag: cfg_.show_attrdict(config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4411368-d772-4381-9cc0-5c9b7ea5361a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m WANDB_NOTEBOOK_NAME should be a path to a notebook file, couldn't find /home/macu/work/nbs_pipeline/02a_encoder_MVP.ipynb.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--> Wandb init\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mmi-santamaria\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    }
   ],
   "source": [
    "#| export\n",
    "if print_flag: print(\"--> Wandb init\")\n",
    "run = wandb.init(\n",
    "    entity = user,\n",
    "    # work-nbs is a place to log draft runs\n",
    "    project=project,\n",
    "    group=config.wandb_group,\n",
    "    job_type=job_type,\n",
    "    allow_val_change=True,\n",
    "    mode=config.analysis_mode,\n",
    "    config=config,\n",
    "    # When use_wandb is false the run is not linked to a personal account\n",
    "    #NOTE: This is not working right now\n",
    "    anonymous = 'never' if config.use_wandb else 'must', \n",
    "    resume=False,\n",
    "    name = runname\n",
    ")\n",
    "if print_flag: print(\"Wandb init -->\")\n",
    "config = run.config  # Object for storing hyperparameters\n",
    "artifacts_gettr = run.use_artifact if config.use_wandb else wandb_api.artifact\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ad0515d-4f2a-4ba6-8c41-a6f480ff6f4b",
   "metadata": {},
   "source": [
    "## Split data using Sliding Window & Get training artiffact"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4a82ad4-45ca-4c9e-8d87-aa56f4d2fdd2",
   "metadata": {},
   "source": [
    "### Get W&B train artifact\n",
    "Build artifact selector\n",
    "Botch to use artifacts offline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78dced3c-8280-460e-bd11-8188495bf470",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "config = run.config  # Object for storing hyperparameters\n",
    "if print_flag: cfg_.show_attrdict(config)\n",
    "artifacts_gettr = run.use_artifact if config.use_wandb else wandb_api.artifact\n",
    "train_artifact = artifacts_gettr(config.train_artifact)\n",
    "if print_flag: print(\"---> W&B Train Artifact\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8acf714f-0fe1-4aed-8b57-23ccd31b22fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "df_train = train_artifact.to_df()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b10283f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "if print_flag: \n",
    "    print(df_train.shape)\n",
    "    display(df_train.head)\n",
    "    print(\"df_train ~ \", df_train.shape)\n",
    "    print(\"window_sizes = \", config.mvp_ws)\n",
    "    print(\"wlen = \", config.w)\n",
    "    df_train.head"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30e5e800-ace5-48e9-bb27-d288abfc108e",
   "metadata": {},
   "source": [
    "#### Get training set\n",
    "Once we have build the windows, we can apply strides in order to check have the same structure as when used via sliding window"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d25ab5a-b1e6-4eb7-8542-e4dc87f2a883",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "if print_flag: print(\"---> Sliding window | \", config.w,  \" | \", config.stride )\n",
    "sw = SlidingWindow(window_len=config.w, stride=config.stride, get_y=[])\n",
    "if print_flag: print(\" Sliding window | \", config.w,  \" | \", config.stride, \"---> | df_train ~ \", df_train.shape )\n",
    "X_train, _ = sw(df_train)\n",
    "if print_flag: print(\" sw_df_train | \", config.w,  \" | \", config.stride, \"--->\" )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "057fb5a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "if print_flag: \n",
    "    print(X_train.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8154ab5-1001-4b59-bf4a-99dfcc0c8913",
   "metadata": {},
   "source": [
    "### Split training set into training and test dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb1e270e-c6a2-4dc0-a54d-8f6fdc7565b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "assert config.analysis_mode in ['offline','online'], 'Invalid analysis mode'\n",
    "\n",
    "X = X_train\n",
    "if print_flag: print(\"len(X): \", len(X));\n",
    "if config.analysis_mode == 'online':\n",
    "    if print_flag: print(\"--> Split 1\")\n",
    "    splits = TimeSplitter(valid_size=0.2, show_plot=show_plots)(X)\n",
    "elif config.analysis_mode == 'offline':\n",
    "    if print_flag: print(\"--> Split 2\")\n",
    "    splits = get_splits(np.arange(len(X)), valid_size=config.valid_size, show_plot = show_plots)\n",
    "if print_flag: \n",
    "    print(\"Split -->\", len(splits[0]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59985ae2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "if print_flag: \n",
    "    print(X.shape)\n",
    "    display(splits)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2fb702b4-8b10-4164-8755-456ffd2759f9",
   "metadata": {},
   "source": [
    "## MVP - Encoder training\n",
    "> Train MVP with optional adaptable window sizes, to allow for inference with different\n",
    "window sizes, to provide an easier exploration of the embedding space through different\n",
    "ways of sliding the data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "156687d8-27b4-451c-b4ae-d5e6859fce25",
   "metadata": {},
   "source": [
    "### Set callback list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7c3cd99",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "if print_flag: print(\"--> About to set callbacks\")\n",
    "cbs = L(WandbCallback(log_preds=False)) if config.use_wandb else L()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31668027-6769-405d-8223-09699a4f1b7f",
   "metadata": {},
   "source": [
    "### Set transformations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b97038fe-116f-4d6c-8569-e9a9c015a434",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "if print_flag: print(\"--> About to set batch tfms\")\n",
    "tfms = [ToFloat(), None]\n",
    "batch_tfms = [TSStandardize(by_sample=config.norm_by_sample, \n",
    "               use_single_batch=config.norm_use_single_batch)]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "496ae849-6b83-4298-9132-b68746b982f8",
   "metadata": {},
   "source": [
    "### Get data loaders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "668e7b5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "dls = get_ts_dls(X, splits=splits, tfms=tfms, bs=config.batch_size, batch_tfms=batch_tfms)\n",
    "if print_flag: print(\"get dls -->\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48ad5f35",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "if show_plots: display(dls.show_at(0))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b997218-945b-49df-b48e-e83eff7f3463",
   "metadata": {},
   "source": [
    "### Build MVP TS Learner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a25dbba-1929-4333-8f15-2a7647cc0a37",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "if show_plots:\n",
    "    if print_flag: print(\"--> sgc\")\n",
    "    sgc = ShowGraphCallback2()\n",
    "    if print_flag: print(\"sgc -->\")\n",
    "    if print_flag: print(\"-->learn\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5f2b562-c1d8-4b01-aa69-6aa974ee959b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# + tags=[\"skip\"]\n",
    "#| hide\n",
    "if show_plots: \n",
    "    print(\"\\t learn | cbs + sgc + MVP\")\n",
    "    learn = ts_learner(\n",
    "        dls, \n",
    "        InceptionTimePlus, \n",
    "        cbs= cbs + sgc + MVP(\n",
    "            r = config.r, \n",
    "            window_size=config.mvp_ws, \n",
    "            future_mask = config.mask_future, \n",
    "            target_dir='./models', \n",
    "            sync = config.mask_sync, \n",
    "            stateful = config.mask_stateful,\n",
    "            fname=f'encoder_MVP'\n",
    "        ), y_range=[X.min(), X.max()])\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f17ebe25-b894-4674-aed5-32e9d8f284a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "if not show_plots: #When .py this is the only option that should be available. That's why this is not an 'else' but a exported cell\n",
    "    print(\"\\t learn | cbs + MVP\")\n",
    "    learn = ts_learner(\n",
    "        dls, \n",
    "        InceptionTimePlus, \n",
    "        cbs= cbs + MVP(\n",
    "            r = config.r, \n",
    "            window_size=config.mvp_ws, \n",
    "            future_mask = config.mask_future, \n",
    "            target_dir='./models', \n",
    "            sync = config.mask_sync, \n",
    "            stateful = config.mask_stateful,\n",
    "            fname=f'encoder_MVP'\n",
    "        ), y_range=[X.min(), X.max()])\n",
    "    \n",
    "if print_flag: print(\"learn -->\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "675240ed-a3b9-4a8d-b5cb-41c48b68909c",
   "metadata": {},
   "source": [
    "### Example mask"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a74c923f-31e8-49f2-b3d9-8b1fe370bcc6",
   "metadata": {},
   "source": [
    "#### Create mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb9dd304-6691-49b7-9ffc-f004757f3cd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "if config.mask_future:\n",
    "    example_mask = create_future_mask(torch.from_numpy(X[0]), config.r, sync=config.mask_sync)\n",
    "else:\n",
    "    example_mask = create_subsequence_mask(torch.from_numpy(X[0]), config.r, stateful=config.mask_stateful, sync=config.mask_sync)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e58d81f4-2d4a-484c-bf9b-88ccab1cd4d6",
   "metadata": {},
   "source": [
    "#### Show mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "563efbd4-bc93-4969-b7e8-bed4b191291e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "fig, ax = plt.subplots(figsize=(20, 2))\n",
    "plt.pcolormesh(example_mask[0], cmap=colors.ListedColormap(['whitesmoke', 'orchid']))\n",
    "plt.title(f'r={config.r},  future={config.mask_future},  stateful={config.mask_stateful},  sync={config.mask_sync}')\n",
    "ax.set_ylabel('variables')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ffb64be-3389-4f2b-997d-a8799e1a5469",
   "metadata": {},
   "source": [
    " ## Check window size configuration"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d63c043-6d89-47f6-a579-2f028980237e",
   "metadata": {},
   "source": [
    "### Check config attributes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab1d5cc8-fac5-4f9d-bbd9-4083c2c60d8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "expected_window_size = config.mvp_ws"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67e9ae29",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "if print_flag:\n",
    "    print(\"w\", config.w, \"mvp_ws\", config.mvp_ws)\n",
    "    print(\"expected \", expected_window_size)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21896f59-e2a0-434f-9437-aa958f90fb67",
   "metadata": {},
   "source": [
    "### Check obtained attributes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "385e5d4c-84de-440c-9572-8688951c2873",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "mvp_cb = learn.cbs.filter(lambda cb: isinstance(cb, MVP))[0]  # Encuentra el callback MVP\n",
    "obtained_window_size=mvp_cb.window_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ada45c85",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "if print_flag: \n",
    "    print(\"obtained \", obtained_window_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce3a3112-ba6b-4756-9ce1-e15e4c2af1fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "if (expected_window_size != obtained_window_size):\n",
    "    raise ValueError(\"Obtained window_size for MVP training different from expected window size. Check size, ws1 & ws2 parameters in '02b-encoder_MVP.yaml'\")\n",
    "else: \n",
    "    print(\"Obtained window size tuple is the expected one. Continue!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bcc784e8-59a1-45e9-8af1-b61ba01a9fc6",
   "metadata": {},
   "source": [
    "#### Check w1 < w2 for MVP random window size selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9272a132-9026-419c-81b0-d16d03894f70",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "if (obtained_window_size[1] < obtained_window_size[0]):\n",
    "    raise ValueError(\"Ws2 must be greater than Ws1 as they are the maximun and minimum window size respectively. Please ensure w2 > w1\")\n",
    "else: \n",
    "    w_sizes = np.random.randint(obtained_window_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67c07573",
   "metadata": {},
   "outputs": [],
   "source": [
    "# + tags=[\"skip\"]\n",
    "#| hide \n",
    "if print_flag: print(w_sizes)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f16a4a5f-23ba-46a0-abd4-f9854356c3a9",
   "metadata": {},
   "source": [
    "#### Check self.x.shape[-1] for np.random.randint(0, self.x.shape[-1] - ws) MVP calculus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "437a49d0-7ee1-4519-a871-b4f82f94c1a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "#Get data batch\n",
    "x = next(iter(dls.train))\n",
    "if print_flag: print(\"x\", x)\n",
    "x_data=x[0]\n",
    "if print_flag: print(\"Data shape: \" + str( x_data.shape))\n",
    "time_serie_len = x_data.shape[-1]\n",
    "if print_flag: print(\"Time serie len: \" + str( time_serie_len))\n",
    "#Just in case\n",
    "for ws in w_sizes:\n",
    "    diff = time_serie_len - ws\n",
    "    if print_flag: print(\"diff time serie len - ws\", diff)\n",
    "    result = np.random.randint(0, diff)\n",
    "    if print_flag: print(\"ws \", ws, \"diff\", diff, \"result\",  result)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05917f56-5e62-4e45-b546-5996a72106bd",
   "metadata": {},
   "source": [
    "### Train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "610dd97f-1cb2-4364-9748-db882ac6162a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "if print_flag: print(\"--> Train\")\n",
    "lr_valley, lr_steep = learn.lr_find(suggest_funcs=(valley, steep), show_plot=show_plots)\n",
    "learn.fit_one_cycle(n_epoch=config.epochs, lr_max=lr_valley,  cbs=[EarlyStoppingCallback(monitor='valid_loss', min_delta=0.000001, patience=10)])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ae82aae-70dd-40de-baf8-22a2bf3d99c0",
   "metadata": {},
   "source": [
    "#### Validate the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b546f8d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "if print_flag: print(\"Train -->\")\n",
    "learn.validate()\n",
    "if print_flag: print(\"Validate -->\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98db4834-1e28-4251-8f58-662cdf5f24bf",
   "metadata": {},
   "source": [
    "## Visualize predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfdf3667-a698-451a-9900-0ac1d6fa0cf5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "learn.MVP.show_preds(sharey=True, nrows=2) # error with nrows=1 or ncols=1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ad4ff29-1d59-4c1d-8499-a8e2b0b6c012",
   "metadata": {},
   "source": [
    "## Save artifact to W&B\n",
    "> Remove extra information and saving the learner object as an weight and biases artifact"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf3bf350-4f52-4a18-ad19-9d260bd060d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "# Remove the ShowGraphCallback2 callback to avoid errors in the frontend (TODO)\n",
    "if show_plots: \n",
    "    learn.remove_cb(sgc)\n",
    "    print(\"SGC callback removed\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9cc0de64-aced-433e-9c10-28fbcf4f9a91",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "# Log the learner without the datasets\n",
    "aux_learn = learn.export_and_get()\n",
    "if config.use_wandb: \n",
    "    run.log_artifact(\n",
    "        ReferenceArtifact(\n",
    "            aux_learn, \n",
    "            f'mvp', \n",
    "            type='learner', \n",
    "            metadata=dict(run.config)\n",
    "        ), \n",
    "        aliases=config.alias\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c97de068-dc91-4cfc-b0a0-2a52b52a9f80",
   "metadata": {},
   "source": [
    "## Close W&B"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ddfe12cd-6e5f-40eb-8f84-12d2db7a355b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "if print_flag: print(\"Artifact logged | About to finish run\")\n",
    "run.finish()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c0422ca-555a-42ab-8d37-6191ec9d6c82",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "if print_flag: print(\"Execution ended\")\n",
    "from dvats.imports import beep\n",
    "beep(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97be8af8-dd40-4e87-af14-e200b9740e36",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "if reset_kernel:\n",
    "    import os\n",
    "    os._exit(00)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
