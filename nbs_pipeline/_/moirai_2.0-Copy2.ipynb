{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "d8d7374a-16c4-409e-961d-02c667ac53f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "verbose                       = None\n",
    "check_memory_usage            = None\n",
    "time_flag                     = None\n",
    "window_size_percentage        = None\n",
    "show_plots                    = None\n",
    "reset_kernel                  = None\n",
    "pre_configured_case           = None\n",
    "case_id                       = None\n",
    "frequency_factor              = None\n",
    "frequency_factor_change_alias = None\n",
    "check_parameters              = True\n",
    "cuda_device                   = None\n",
    "remove_lambdas_flag           = True"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f5ade51-58bf-4cd2-aff6-7ad3be23a4e4",
   "metadata": {},
   "source": [
    "# Explained pre-trained module trial"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2e9ee0f-7af4-4f38-b5de-bffad59c31c1",
   "metadata": {},
   "source": [
    "## Instalation commands"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "13ae19aa-e2b9-4353-916a-0a8f3297e0c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#! git clone https://github.com/SalesforceAIResearch/uni2ts.git\n",
    "#! cd uni2ts\n",
    "#! pip install -e '.[notebook]' --no-warn-script-location\n",
    "#! conda install anaconda::gluonts"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e226f16-49d0-454e-9add-8c4752b08623",
   "metadata": {},
   "source": [
    "## Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "1c45abc3-18ca-4751-8d44-09ab90e0c547",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from gluonts.dataset.pandas import PandasDataset\n",
    "from gluonts.dataset.split import split\n",
    "from huggingface_hub import hf_hub_download\n",
    "\n",
    "from uni2ts.eval_util.plot import plot_single\n",
    "from uni2ts.model.moirai import MoiraiForecast, MoiraiModule"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "526d39ba-6822-4e44-a3cb-349cbe2c2bea",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dvats.all import *"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40ee47ab-44b4-421f-97ec-0d52606a668f",
   "metadata": {},
   "source": [
    "## Utilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "8e784320-0d41-4087-acc9-887d9b58f34a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "# This is only needed if the notebook is run in VSCode\n",
    "import sys\n",
    "import dvats.utils as ut\n",
    "if '--vscode' in sys.argv:\n",
    "    print(\"Executing inside vscode\")\n",
    "    ut.DisplayHandle.update = ut.update_patch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "9f1aeccd-4a3a-4707-b110-0af5215aa0d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import importlib\n",
    "def remove_lambdas(verbose = 0):\n",
    "    path = \"./uni2ts/src/uni2ts/distribution/mixture.py\"\n",
    "    if verbose > 0: print(f\"remove_lambdas | read file {path}\")\n",
    "    # Read the file\n",
    "    with open(path, 'r') as file:\n",
    "        lines = file.readlines()\n",
    "    # Check wether identity is defined or not\n",
    "    identity_defined = any(\"def identity(\" in line for line in lines)\n",
    "    if verbose > 0: print(f\"remove_lambdas | identity already defined? {identity_defined}\")\n",
    "    if not identity_defined: \n",
    "        if verbose > 0: print(\"remove_lambdas | Look for domain_map line\")\n",
    "        for i, line in enumerate(lines):\n",
    "            if \"@property\" in line and \"def domain_map\" in lines[i+1]:                \n",
    "                domain_map_property_index = i\n",
    "                break\n",
    "        if verbose > 0: print(f\"remove_lambdas | Domain map in line {i}\")\n",
    "        # Insert identity function\n",
    "        identity_code = \"\"\"\n",
    "    def identity(self, x): \n",
    "        return x\n",
    "\n",
    "\"\"\"\n",
    "        lines.insert(domain_map_property_index, identity_code)\n",
    "        # Modify weights_logits line \n",
    "        inside_domain_map = False\n",
    "        for i in range(domain_map_property_index, len(lines)):\n",
    "            if \"weights_logits\" in lines[i]:\n",
    "                # Reemplazar la línea para que use identity\n",
    "                lines[i] = \"            weights_logits = self.identity,\\n\"\n",
    "                break\n",
    "        # Write changes \n",
    "        with open(path, 'w') as file:\n",
    "            file.writelines(lines)\n",
    "        importlib.reload(uni2ts)\n",
    "    else:\n",
    "        if identity_defined:\n",
    "            print(\"Identity already defined\")    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fcfc741c-dbc7-4b46-bf88-8f233637bdab",
   "metadata": {},
   "source": [
    "### Ensure model is pickable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "7c481684-65d6-4874-ae70-1df191cd0d94",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "remove_lambdas | read file ./uni2ts/src/uni2ts/distribution/mixture.py\n",
      "remove_lambdas | identity already defined? True\n",
      "Identity already defined\n"
     ]
    }
   ],
   "source": [
    "if remove_lambdas_flag: remove_lambdas(verbose = 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb1b2f45-e08d-4255-81ef-a4221e7bcb9e",
   "metadata": {},
   "source": [
    "## Load dataset artifact"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "acf546f4-be65-4642-837c-a122ca2b17cc",
   "metadata": {},
   "source": [
    "### Check input parameters & set up default parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "93180bf5-e123-48d7-ae6b-84b1852b4f59",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "verbose                       = True  if verbose is None else verbose\n",
    "check_memory_usage            = True  if check_memory_usage is None else check_memory_usage\n",
    "time_flag                     = True  if time_flag is None else time_flag\n",
    "window_size_percentage        = False if window_size_percentage is None else window_size_percentage\n",
    "show_plots                    = True if show_plots is None else show_plots\n",
    "reset_kernel                  = False  if reset_kernel is None else reset_kernel\n",
    "pre_configured_case           = True if pre_configured_case is None else pre_configured_case\n",
    "case_id                       = 7 if case_id is None else case_id\n",
    "frequency_factor              = 1 if frequency_factor is None else frequency_factor\n",
    "frequency_factor_change_alias = True if frequency_factor_change_alias is None else frequency_factor_change_alias\n",
    "cuda_device                   = 1 if  cuda_device is None else cuda_device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "3c3f41eb-ee0a-4a85-8fdb-20ea22d30416",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Check parameters ---\n",
      "verbose: True check_memory_usage True time_flag: True window_size_percentage: False show_plots: True reset_kernel: False pre_configured_case: True case_id: 7 frequency_factor: 1 frequency_factor_change_alias True cuda_device 1\n"
     ]
    }
   ],
   "source": [
    "if check_parameters:\n",
    "    print(\"--- Check parameters ---\")\n",
    "    print(\n",
    "        \"verbose:\", verbose,\n",
    "        \"check_memory_usage\", check_memory_usage,\n",
    "        \"time_flag:\", time_flag,\n",
    "        \"window_size_percentage:\" , window_size_percentage,\n",
    "        \"show_plots:\",show_plots,\n",
    "        \"reset_kernel:\",reset_kernel,\n",
    "        \"pre_configured_case:\",pre_configured_case,\n",
    "        \"case_id:\",case_id,\n",
    "        \"frequency_factor:\", frequency_factor, \n",
    "        \"frequency_factor_change_alias\", frequency_factor_change_alias,\n",
    "        \"cuda_device\", cuda_device\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "f64138b8-e2c0-4ed3-ba9c-3b9a0e48675d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "import dvats.config as cfg_\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", module=\"umap\")\n",
    "import os\n",
    "import sys\n",
    "sys.path.append(os.path.abspath('..'))\n",
    "from dvats.all import *\n",
    "from fastcore.all import *\n",
    "from tsai.basics import *\n",
    "from tsai.models.InceptionTimePlus import *\n",
    "from tsai.callback.MVP import *\n",
    "import matplotlib.colors as colors\n",
    "from fastai.callback.wandb import WandbCallback\n",
    "from fastai.callback.progress import ShowGraphCallback\n",
    "from fastai.callback.schedule import *\n",
    "from fastai.callback.tracker import EarlyStoppingCallback\n",
    "import wandb\n",
    "\n",
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from gluonts.dataset.pandas import PandasDataset\n",
    "from gluonts.dataset.split import split\n",
    "from huggingface_hub import hf_hub_download\n",
    "\n",
    "import uni2ts\n",
    "from uni2ts.eval_util.plot import plot_single\n",
    "from uni2ts.model.moirai import MoiraiForecast, MoiraiModule\n",
    "from uni2ts.eval_util.plot import plot_next_multi\n",
    "import pyarrow.feather as ft"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "60ad4604-0887-4345-b075-c54e7b5a69d6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU | Used mem: 1\n",
      "GPU | Used mem: 24\n",
      "GPU | Memory Usage: [\u001b[90m--------------------\u001b[0m] \u001b[90m4%\u001b[0m\n",
      "\u001b[94mtrain_artifact: mi-santamaria/deepvats/PulsusParadoxus-SP02:latest\u001b[0m -> mi-santamaria/deepvats/toy:latest\u001b[0m\n",
      "\u001b[93m\u001b[1mcsv_config is missing in original dict | {} \u001b[0m\n",
      "norm_use_single_batch: False\u001b[0m\n",
      "\u001b[94malias: PulsusParadoxus-SP02\u001b[0m -> toy\u001b[0m\n",
      "analysis_mode: online\u001b[0m\n",
      "\u001b[94mw: 100\u001b[0m -> 30\u001b[0m\n",
      "\u001b[94mstride: 900\u001b[0m -> 1\u001b[0m\n",
      "\u001b[93m\u001b[1mdata_fpath is missing in original dict | ~/data/toy.csv \u001b[0m\n",
      "\u001b[94mmvp_ws: (15, 100)\u001b[0m -> [10, 30]\u001b[0m\n",
      "mask_future: False\u001b[0m\n",
      "\u001b[93m\u001b[1mfreq is missing in original dict | 1s \u001b[0m\n",
      "mask_stateful: True\u001b[0m\n",
      "mask_sync: False\u001b[0m\n",
      "use_wandb: True\u001b[0m\n",
      "valid_artifact: None\u001b[0m\n",
      "valid_size: 0.2\u001b[0m\n",
      "norm_by_sample: False\u001b[0m\n",
      "\u001b[93m\u001b[1mtime_col is missing in original dict | None \u001b[0m\n",
      "\u001b[93m\u001b[1mnorm_use_by_single_batch is missing in original dict | (False,) \u001b[0m\n",
      "\u001b[93m\u001b[1mdata_cols is missing in original dict | [] \u001b[0m\n",
      "epochs: 100\u001b[0m\n",
      "\u001b[93m\u001b[1martifact_name is missing in original dict | toy \u001b[0m\n",
      "r: 0.71\u001b[0m\n",
      "\u001b[94mbatch_size: 512\u001b[0m -> 32\u001b[0m\n",
      "wandb_group: None\u001b[0m\n",
      "runname: moirai_trial\n",
      "alias: toy\n",
      "analysis_mode: online\n",
      "batch_size: 32\n",
      "epochs: 100\n",
      "mask_future: False\n",
      "mask_stateful: True\n",
      "mask_sync: False\n",
      "mvp_ws: [10, 30]\n",
      "norm_by_sample: False\n",
      "norm_use_single_batch: False\n",
      "r: 0.71\n",
      "stride: 1\n",
      "train_artifact: mi-santamaria/deepvats/toy:latest\n",
      "valid_artifact: None\n",
      "use_wandb: True\n",
      "valid_size: 0.2\n",
      "w: 30\n",
      "wandb_group: None\n",
      "artifact_name: toy\n",
      "data_cols: []\n",
      "data_fpath: ~/data/toy.csv\n",
      "freq: 1s\n",
      "time_col: None\n",
      "csv_config: {}\n",
      "norm_use_by_single_batch: (False,)\n",
      "--> Wandb init\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Finishing last run (ID:n8lvs1jl) before initializing another..."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">moirai_trial</strong> at: <a href='https://wandb.ai/mi-santamaria/deepvats/runs/n8lvs1jl' target=\"_blank\">https://wandb.ai/mi-santamaria/deepvats/runs/n8lvs1jl</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>/home/macu/work/wandb/run-20241001_140017-n8lvs1jl/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Successfully finished last run (ID:n8lvs1jl). Initializing new run:<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dfb7d2e968f44755a81eec9a23a86c35",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='Waiting for wandb.init()...\\r'), FloatProgress(value=0.01666891435161233, max=1.0)…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.18.2 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.14.2"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/home/macu/work/wandb/run-20241001_144750-kjc372fy</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/mi-santamaria/deepvats/runs/kjc372fy' target=\"_blank\">moirai_trial</a></strong> to <a href='https://wandb.ai/mi-santamaria/deepvats' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/mi-santamaria/deepvats' target=\"_blank\">https://wandb.ai/mi-santamaria/deepvats</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/mi-santamaria/deepvats/runs/kjc372fy' target=\"_blank\">https://wandb.ai/mi-santamaria/deepvats/runs/kjc372fy</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wandb init -->\n",
      "alias: toy\n",
      "analysis_mode: online\n",
      "batch_size: 32\n",
      "epochs: 100\n",
      "mask_future: False\n",
      "mask_stateful: True\n",
      "mask_sync: False\n",
      "mvp_ws: [10, 30]\n",
      "norm_by_sample: False\n",
      "norm_use_single_batch: False\n",
      "r: 0.71\n",
      "stride: 1\n",
      "train_artifact: mi-santamaria/deepvats/toy:latest\n",
      "valid_artifact: None\n",
      "use_wandb: True\n",
      "valid_size: 0.2\n",
      "w: 30\n",
      "wandb_group: None\n",
      "artifact_name: toy\n",
      "data_cols: []\n",
      "data_fpath: ~/data/toy.csv\n",
      "freq: 1s\n",
      "time_col: None\n",
      "csv_config: {}\n",
      "norm_use_by_single_batch: [False]\n",
      "---> W&B Train Artifact\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m:   1 of 1 files downloaded.  \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(550, 3)"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#| export\n",
    "wandb_api = wandb.Api()\n",
    "device = torch.device(f'cuda:{cuda_device}' if torch.cuda.is_available() else 'cpu')\n",
    "torch.cuda.set_device(device)\n",
    "if check_memory_usage:\n",
    "    gpu_device = torch.cuda.current_device()\n",
    "    gpu_memory_status(gpu_device)\n",
    "user, project, version, data, config, job_type = cfg_.get_artifact_config_MVP(False)\n",
    "if pre_configured_case: \n",
    "    cfg_.force_artifact_config_mvp(\n",
    "        config = config,\n",
    "        id = case_id,\n",
    "        verbose = verbose, \n",
    "        both = verbose > 0,\n",
    "        frequency_factor = frequency_factor,\n",
    "        frequency_factor_change_alias = frequency_factor_change_alias\n",
    "    )\n",
    "path = os.path.expanduser(\"~/work/nbs_pipeline/\")\n",
    "name=\"moirai_trial\"\n",
    "os.environ[\"WANDB_NOTEBOOK_NAME\"] = path+name+\".ipynb\"\n",
    "runname=name\n",
    "if verbose > 0: print(\"runname: \"+runname)\n",
    "if verbose > 0: cfg_.show_attrdict(config)\n",
    "\n",
    "if verbose > 0: print(\"--> Wandb init\")\n",
    "run = wandb.init(\n",
    "    entity = user,\n",
    "    # work-nbs is a place to log draft runs\n",
    "    project=project,\n",
    "    group=config.wandb_group,\n",
    "    job_type=job_type,\n",
    "    allow_val_change=True,\n",
    "    mode=config.analysis_mode,\n",
    "    config=config,\n",
    "    # When use_wandb is false the run is not linked to a personal account\n",
    "    #NOTE: This is not working right now\n",
    "    anonymous = 'never' if config.use_wandb else 'must', \n",
    "    resume=False,\n",
    "    name = runname\n",
    ")\n",
    "if verbose > 0: print(\"Wandb init -->\")\n",
    "config = run.config  # Object for storing hyperparameters\n",
    "artifacts_gettr = run.use_artifact if config.use_wandb else wandb_api.artifact\n",
    "config = run.config  # Object for storing hyperparameters\n",
    "if verbose > 0: cfg_.show_attrdict(config)\n",
    "artifacts_gettr = run.use_artifact if config.use_wandb else wandb_api.artifact\n",
    "train_artifact = artifacts_gettr(config.train_artifact)\n",
    "if verbose > 0: print(\"---> W&B Train Artifact\")\n",
    "df_train = train_artifact.to_df()\n",
    "df_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "a74030b0-7661-42dd-868c-ad57cd98bed1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>T3</th>\n",
       "      <th>T2</th>\n",
       "      <th>T1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1970-01-01 00:00:00</th>\n",
       "      <td>0.741822</td>\n",
       "      <td>0.637180</td>\n",
       "      <td>0.565117</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1970-01-01 00:00:01</th>\n",
       "      <td>0.739731</td>\n",
       "      <td>0.629415</td>\n",
       "      <td>0.493513</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1970-01-01 00:00:02</th>\n",
       "      <td>0.718757</td>\n",
       "      <td>0.539220</td>\n",
       "      <td>0.469350</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1970-01-01 00:00:03</th>\n",
       "      <td>0.730169</td>\n",
       "      <td>0.577670</td>\n",
       "      <td>0.444100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1970-01-01 00:00:04</th>\n",
       "      <td>0.752406</td>\n",
       "      <td>0.570180</td>\n",
       "      <td>0.373008</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                           T3        T2        T1\n",
       "1970-01-01 00:00:00  0.741822  0.637180  0.565117\n",
       "1970-01-01 00:00:01  0.739731  0.629415  0.493513\n",
       "1970-01-01 00:00:02  0.718757  0.539220  0.469350\n",
       "1970-01-01 00:00:03  0.730169  0.577670  0.444100\n",
       "1970-01-01 00:00:04  0.752406  0.570180  0.373008"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(df_train.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d0f8b29-38a6-4658-81c8-b9ac4d8322a2",
   "metadata": {},
   "source": [
    "### Sliding windows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "94aadad1-8c27-4a6a-b398-6c070db00a36",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---> Sliding window |  30  |  1\n",
      " Sliding window |  30  |  1 ---> | df_train ~  (550, 3)\n",
      " sw_df_train |  30  |  1 --->\n"
     ]
    }
   ],
   "source": [
    "#| export\n",
    "if verbose > 0: print(\"---> Sliding window | \", config.w,  \" | \", config.stride )\n",
    "sw = SlidingWindow(window_len=config.w, stride=config.stride, get_y=[])\n",
    "if verbose > 0: print(\" Sliding window | \", config.w,  \" | \", config.stride, \"---> | df_train ~ \", df_train.shape )\n",
    "X_train, _ = sw(df_train)\n",
    "if verbose > 0: print(\" sw_df_train | \", config.w,  \" | \", config.stride, \"--->\" )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "3e0bb9a4-a0f0-4896-9d1b-3b2fb04323bb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(521, 3, 30)\n"
     ]
    }
   ],
   "source": [
    "#| hide\n",
    "if verbose > 0: \n",
    "    print(X_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "ff7d914c-f9a8-4dc5-9707-f7b309615ba6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "len(X):  521\n",
      "--> Split 1\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAABZcAAABmCAYAAAC3Bq+HAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjguMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/SrBM8AAAACXBIWXMAAA9hAAAPYQGoP6dpAAAa1klEQVR4nO3de1xUdf7H8fcgwwByKRAZJkHELK2QFiijy0qpuZpaubnrli1tm9oqKqZbmv0Ci9TFNS8V9WirxS6ul01t08eWlEq2dDGTVNZYa/HSCpG2CqhcHM7vj5apCS8cdQaQ1/PxmMdjzvd853w/Z/Ij+vHb51gMwzAEAAAAAAAAAIAJPi0dAAAAAAAAAACg7aG4DAAAAAAAAAAwjeIyAAAAAAAAAMA0issAAAAAAAAAANMoLgMAAAAAAAAATKO4DAAAAAAAAAAwjeIyAAAAAAAAAMA0issAAAAAAAAAANMoLgMAAAAAAAAATKO4DAAA8D8fffSRbr/9dsXExMhmsykyMlIpKSmaMmXKGV1v9+7dslgsysvLc43l5eXJYrFo9+7drrElS5ZowYIFZxe8pNjYWN1zzz2u440bN8pisWjjxo2mrpObm+sWc3OcaK177rlHQUFBpq5zOoWFhcrKytKhQ4eanEtNTVVqauo5XQ8AAADAyVFcBgAAkLR27Vpde+21qqysVE5OjtatW6eFCxfquuuu07Jly87ZOrfccos++OADRUVFucbOVXH5xxITE/XBBx8oMTHR1OfOpLh8pmuZVVhYqJkzZ56wuJybm6vc3FyPrg8AAADge74tHQAAAEBrkJOTo27duuntt9+Wr+/3f0QaOXKkcnJyztk6ERERioiIOGfXO5WQkBBdc801Hl2jvr5eFovFK2udzmWXXdai6wMAAADtDTuXAQAAJB08eFCdOnVyKyw38vFx/yNTbGyshgwZolWrVql3797y9/dXXFycFi1adNp1ftwWIzU1VWvXrtWePXtksVhcr1Opr6/Xgw8+KLvdrsDAQF1//fX6+OOPm8w7UauKf//73xo5cqQcDoer9Ue/fv1UVFTkurfi4mIVFBS4YomNjXW73iuvvKIpU6booosuks1m0xdffHHKFhzFxcXq16+fOnbsqIiICKWnp+vo0aOu8ydqH9LIYrEoKytLkpSVlaXf//73kqRu3bq54mtc80RtMb799luNGzdOF110kfz8/BQXF6cZM2aotra2yTrp6el65ZVX1KtXLwUGBiohIUFr1qw5+X8IAAAAoJ1j5zIAAICklJQUvfDCC5o4caLuuusuJSYmymq1nnR+UVGRMjIylJWVJbvdrtdee02TJk1SXV2dpk6d2ux1c3NzNWbMGH355ZdatWpVsz4zevRovfzyy5o6daoGDBigHTt2aPjw4aqqqjrtZwcPHiyn06mcnBzFxMTowIEDKiwsdLWZWLVqle644w6Fhoa6WkzYbDa3a0yfPl0pKSl67rnn5OPjo86dO6u8vPyE69XX12vw4MEaO3aspk2bpsLCQmVnZ2vPnj168803m3W/je677z59++23euqpp7Ry5UpXa5GT7ViuqanRjTfeqC+//FIzZ85U7969tWnTJs2ePVtFRUVau3at2/y1a9dq8+bNeuyxxxQUFKScnBzdfvvtKikpUVxcnKlYAQAAgPaA4jIAAICkOXPm6PPPP9dTTz2lp556SlarVVdddZWGDh2q9PT0Jg+m279/v7Zu3aqEhARJ0qBBg1RRUaHHH39c48aNU2BgYLPWveyyy3TBBRfIZrM1q63E559/rsWLF2vy5Mmudh0DBgxQZGSk7rrrrlN+9uDBgyopKdGCBQs0atQo1/jw4cNd73/yk58oICDglG0uunfvrhUrVjTn9lRXV6cpU6Zo4sSJrlitVqtmzJihf/zjH7ruuuuadR1J6tKli2JiYlxxNu6oPpnFixdr27ZtWr58uUaMGOFaPygoSA899JDy8/M1YMAA1/xjx47pnXfeUXBwsKTv+kg7HA4tX75c06ZNa3acAAAAQHtBWwwAAABJ4eHh2rRpkzZv3qw5c+bo1ltv1b/+9S9Nnz5d8fHxOnDggNv8yy+/3FVYbnTnnXeqsrJSn376qcfi3LBhgyQ1KST/4he/OGFLjx8KCwtT9+7dNXfuXD355JPaunWrGhoaTMfw85//3NT8H8d65513Svr+Xjxl/fr16tixo+644w638XvuuUeS9O6777qN33jjja7CsiRFRkaqc+fO2rNnj0fjBAAAANoqissAAAA/kJycrIceekgrVqzQ/v37NXnyZO3evbvJQ/3sdnuTzzaOHTx40GPxNV77x+v7+voqPDz8lJ+1WCx69913NXDgQOXk5CgxMVERERGaOHFis1pqNGpsR9EcJ4rLG99T4/XtdnuTHtadO3eWr69vk/VP9P3ZbDYdO3bMo3ECAAAAbRXFZQAAgJOwWq3KzMyUJO3YscPt3Il6DDeOna7IezYar/3j9Y8fP96sYm3Xrl314osvqry8XCUlJZo8ebJyc3NdD8prjtM9cPB0cf34e/L395ekJg/ZO9vic3h4uL7++msZhuE2XlFRoePHj6tTp05ndX0AAACgvaO4DAAAIKmsrOyE4zt37pQkORwOt/Hi4mJ99tlnbmNLlixRcHCwEhMTTa1tZndsamqqJOm1115zG1++fLmOHz9uat1LLrlEjzzyiOLj491aeZzr3bo/jnXJkiWSvr+XyMhI+fv7a9u2bW7z3njjjSbXany4YHPi69evn6qrq7V69Wq38Zdfftl1HgAAAMCZ44F+AAAAkgYOHKguXbpo6NCh6tmzpxoaGlRUVKR58+YpKChIkyZNcpvvcDg0bNgwZWVlKSoqSq+++qry8/P1hz/8odkP82sUHx+vlStX6tlnn1VSUpJ8fHyUnJx8wrm9evXSqFGjtGDBAlmtVvXv3187duzQH//4R4WEhJxynW3btik9PV0jRoxQjx495Ofnp/Xr12vbtm1uD6yLj4/X0qVLtWzZMsXFxcnf31/x8fGm7qmRn5+f5s2bp+rqal111VUqLCxUdna2Bg0apOuvv17SdzuhR40apZdeekndu3dXQkKCPv74Y1cR+sfflSQtXLhQaWlpslqtuvTSS916JTf69a9/rWeeeUZpaWnavXu34uPj9f7772vWrFkaPHiw+vfvf0b3BAAAAOA7FJcBAAAkPfLII3rjjTc0f/58lZWVqba2VlFRUerfv7+mT5+uXr16uc2/8sor9Zvf/EaZmZnatWuXHA6HnnzySU2ePNn02pMmTVJxcbEefvhhHT58WIZhNGnl8EMvvviiIiMjlZeXp0WLFunKK6/U66+/rpEjR55yHbvdru7duys3N1f79u2TxWJRXFyc5s2bpwkTJrjmzZw5U2VlZRo9erSqqqrUtWtX7d692/R9Sd+1FlmzZo0mTpyo7OxsBQQEaPTo0Zo7d67bvHnz5kmScnJyVF1drZtuuklr1qxRbGys27zU1FRNnz5dixcv1p/+9Cc1NDRow4YNrl3QP+Tv768NGzZoxowZmjt3rr755htddNFFmjp1qqvdCQAAAIAzZzFO9TcXAAAANBEbG6srrrhCa9asaelQAAAAAKDF0HMZAAAAAAAAAGAaxWUAAAAAAAAAgGm0xQAAAAAAAAAAmMbOZQAAAAAAAACAaRSXAQAAAAAAAACmUVwGAAAAAAAAAJjm6+0FGxoatH//fgUHB8tisXh7eQAAAAAAAKBNMwxDVVVVcjgc8vFh7yhajteLy/v371d0dLS3lwUAAAAAAADOK/v27VOXLl1aOgy0Y14vLgcHB//v3T5JId5eHgAAAACAdiOh4KctHQIAD3AecWrH4B0/qLMBLcPrxeXvW2GEiOIyAAAAAACe0yGoQ0uHAMCDaDmLlkZTFgAAAAAAAACAaRSXAQAAAAAAAACmUVwGAAAAAAAAAJjm9Z7LAAAAAAAAAOAJTqdT9fX1LR1Gm9WhQwf5+vo2u583xWUAAAAAAAAAbV51dbW++uorGYbR0qG0aYGBgYqKipKfn99p51JcBgAAAAAAANCmOZ1OffXVVwoMDFRERESzd97ie4ZhqK6uTt98841KS0vVo0cP+ficuqsyxWUAAAAAAAAAbVp9fb0Mw1BERIQCAgJaOpw2KyAgQFarVXv27FFdXZ38/f1POZ8H+gEAAAAAAAA4L7Bj+eydbrey21wPxgEAAAAAAAAAOE9RXAYAAAAAAAAAmEZxGQAAAAAAAADOE6mpqcrIyPDKWjzQDwAAAAAAAMB5ydstmA2j+XNP1x86LS1NeXl5pmNYuXKlrFar6c+dCdM7l9977z0NHTpUDodDFotFq1ev9kBYAAAAAAAAAHD+Kisrc70WLFigkJAQt7GFCxe6za+vr2/WdcPCwhQcHOyJkJswXVw+cuSIEhIS9PTTT3siHgAAAAAAAAA479ntdtcrNDRUFovFdVxTU6MLLrhAy5cvV2pqqvz9/fXqq6/q4MGD+tWvfqUuXbooMDBQ8fHx+stf/uJ23R+3xYiNjdWsWbN07733Kjg4WDExMXr++efPyT2YLi4PGjRI2dnZGj58+DkJAAAAAAAAAADQ1EMPPaSJEydq586dGjhwoGpqapSUlKQ1a9Zox44dGjNmjO6++2599NFHp7zOvHnzlJycrK1bt2rcuHH63e9+p88///ys4/N4z+Xa2lrV1ta6jisrKz29JAAAAAAAAAC0eRkZGU02+U6dOtX1fsKECXrrrbe0YsUK9enT56TXGTx4sMaNGyfpu4L1/PnztXHjRvXs2fOs4jO9c9ms2bNnKzQ01PWKjo729JIAAAAAAAAA0OYlJye7HTudTj3xxBPq3bu3wsPDFRQUpHXr1mnv3r2nvE7v3r1d7xvbb1RUVJx1fB4vLk+fPl2HDx92vfbt2+fpJQEAAAAAAACgzevYsaPb8bx58zR//nw9+OCDWr9+vYqKijRw4EDV1dWd8jpWq9Xt2GKxqKGh4azj83hbDJvNJpvN5ullAAAAAAAAAOC8tmnTJt16660aNWqUJKmhoUG7du1Sr169WiQej+9cBgAAAAAAAACcvYsvvlj5+fkqLCzUzp07NXbsWJWXl7dYPKZ3LldXV+uLL75wHZeWlqqoqEhhYWGKiYk5p8EBAAAAAAAAwJkyjJaO4Nz6v//7P5WWlmrgwIEKDAzUmDFjdNttt+nw4cMtEo/FMMx9xRs3btSNN97YZDwtLU15eXmn/XxlZaVCQ0MlHZYUYmZpAAAAAABgQuKWpJYOAYAHOKud+qzvZzp8+LBCQqivSVJNTY1KS0vVrVs3+fv7t3Q4bZqZ79L0zuXU1FSZrEcDAAAAAAAAAM4z9FwGAAAAAAAAAJhGcRkAAAAAAAAAYBrFZQAAAAAAAACAaRSXAQAAAAAAAACmUVwGAAAAAAAAAJhGcRkAAAAAAAAAYBrFZQAAAAAAAACAaRSXAQAAAAAAAACmUVwGAAAAAAAAAJjm29IBAAAAAAAAAIAnJH2a5NX1tiRuafZci8VyyvNpaWnKy8s7ozhiY2OVkZGhjIyMM/p8c1FcBgAAAAAAAAAvKysrc71ftmyZHn30UZWUlLjGAgICWiIsU7xeXDYM43/vKr29NAAAAAAA7Yqz2tnSIQDwAOeR73L7+zob2iK73e56HxoaKovF4jb25ptvKisrS8XFxXI4HEpLS9OMGTPk6/tdSTcrK0svvfSSvv76a4WHh+uOO+7QokWLlJqaqj179mjy5MmaPHmyJM/9WvF6cfngwYP/exft7aUBAAAAAGhXPuvb0hEA8KSqqiqFhoa2dBjwgLffflujRo3SokWLdMMNN+jLL7/UmDFjJEmZmZn661//qvnz52vp0qW6/PLLVV5ers8++0yStHLlSiUkJGjMmDEaPXq0R+P0enE5LCxMkrR3715+8QNtRGVlpaKjo7Vv3z6FhIS0dDgAmoG8Bdoe8hZoe8hboO05X/LWMAxVVVXJ4XC0dCjwkCeeeELTpk1TWlqaJCkuLk6PP/64HnzwQWVmZmrv3r2y2+3q37+/rFarYmJidPXVV0v6rv7aoUMHBQcHu+2E9gSvF5d9fHwkfbfVuy0nMdAehYSEkLdAG0PeAm0PeQu0PeQt0PacD3nLps3z25YtW7R582Y98cQTrjGn06mamhodPXpUI0aM0IIFCxQXF6ef/exnGjx4sIYOHepqmeEtPNAPAAAAAAAAAFqRhoYGzZw5U8OHD29yzt/fX9HR0SopKVF+fr7eeecdjRs3TnPnzlVBQYGsVqvX4qS4DAAAAAAAAACtSGJiokpKSnTxxRefdE5AQICGDRumYcOGafz48erZs6e2b9+uxMRE+fn5yen0/ENdvV5cttlsyszMlM1m8/bSAM4QeQu0PeQt0PaQt0DbQ94CbQ95i7bi0Ucf1ZAhQxQdHa0RI0bIx8dH27Zt0/bt25Wdna28vDw5nU716dNHgYGBeuWVVxQQEKCuXbtKkmJjY/Xee+9p5MiRstls6tSpk0fitBiGYXjkygAAAAAAAADgBTU1NSotLVW3bt3k7+/f0uGYlpeXp4yMDB06dMg19vbbb+uxxx7T1q1bZbVa1bNnT913330aPXq0Vq9erTlz5mjnzp1yOp2Kj49Xdna2+vXrJ0n68MMPNXbsWJWUlKi2tlZmSsBmvkuKywAAAAAAAADatLZeXG5NzHyXPl6KCQAAAAAAAABwHqG4DAAAAAAAAAAwjeIyAAAAAAAAAMA0issAAAAAAAAAANO8WlzOzc11NYJOSkrSpk2bvLk8gB947733NHToUDkcDlksFq1evdrtvGEYysrKksPhUEBAgFJTU1VcXOw2p7a2VhMmTFCnTp3UsWNHDRs2TF999ZUX7wJoP2bPnq2rrrpKwcHB6ty5s2677TaVlJS4zSFvgdbl2WefVe/evRUSEqKQkBClpKTo73//u+s8OQu0frNnz5bFYlFGRoZrjNwFWpesrCxZLBa3l91ud50nZ9sfwzBaOoQ2z8x36LXi8rJly5SRkaEZM2Zo69atuuGGGzRo0CDt3bvXWyEA+IEjR44oISFBTz/99AnP5+Tk6Mknn9TTTz+tzZs3y263a8CAAaqqqnLNycjI0KpVq7R06VK9//77qq6u1pAhQ+R0Or11G0C7UVBQoPHjx+vDDz9Ufn6+jh8/rptvvllHjhxxzSFvgdalS5cumjNnjj755BN98sknuummm3Trrbe6/kJLzgKt2+bNm/X888+rd+/ebuPkLtD6XH755SorK3O9tm/f7jpHzrYfHTp0kCTV1dW1cCRt39GjRyVJVqv19JMNL7n66quN+++/322sZ8+exrRp07wVAoCTkGSsWrXKddzQ0GDY7XZjzpw5rrGamhojNDTUeO655wzDMIxDhw4ZVqvVWLp0qWvOf/7zH8PHx8d46623vBY70F5VVFQYkoyCggLDMMhboK248MILjRdeeIGcBVq5qqoqo0ePHkZ+fr7Rt29fY9KkSYZh8PMWaI0yMzONhISEE54jZ9uXhoYGY/fu3cauXbuMI0eOGMeOHeNl8nX06FHjwIEDxj//+U9j//79zfrefT1a5v6furo6bdmyRdOmTXMbv/nmm1VYWOiNEACYUFpaqvLyct18882uMZvNpr59+6qwsFBjx47Vli1bVF9f7zbH4XDoiiuuUGFhoQYOHNgSoQPtxuHDhyVJYWFhkshboLVzOp1asWKFjhw5opSUFHIWaOXGjx+vW265Rf3791d2drZrnNwFWqddu3bJ4XDIZrOpT58+mjVrluLi4sjZdsZisSgqKkqlpaXas2dPS4fTpl1wwQVu7WVOxSvF5QMHDsjpdCoyMtJtPDIyUuXl5d4IAYAJjXl5opxt/A26vLxcfn5+uvDCC5vMIa8BzzIMQw888ICuv/56XXHFFZLIW6C12r59u1JSUlRTU6OgoCCtWrVKl112mWuDBTkLtD5Lly7Vp59+qs2bNzc5x89boPXp06ePXn75ZV1yySX6+uuvlZ2drWuvvVbFxcXkbDvk5+enHj160BrjLFitVleLkebwSnG5kcVicTs2DKPJGIDW40xylrwGPC89PV3btm3T+++/3+QceQu0LpdeeqmKiop06NAhvf7660pLS1NBQYHrPDkLtC779u3TpEmTtG7dOvn7+590HrkLtB6DBg1yvY+Pj1dKSoq6d++uxYsX65prrpFEzrY3Pj4+p/w9HOeWVx7o16lTJ3Xo0KHJv/hUVFQ0+dcjAC2v8X99OFXO2u121dXV6b///e9J5wA49yZMmKC//e1v2rBhg7p06eIaJ2+B1snPz08XX3yxkpOTNXv2bCUkJGjhwoXkLNBKbdmyRRUVFUpKSpKvr698fX1VUFCgRYsWydfX15V75C7QenXs2FHx8fHatWsXP28BL/BKcdnPz09JSUnKz893G8/Pz9e1117rjRAAmNCtWzfZ7Xa3nK2rq1NBQYErZ5OSkmS1Wt3mlJWVaceOHeQ14AGGYSg9PV0rV67U+vXr1a1bN7fz5C3QNhiGodraWnIWaKX69eun7du3q6ioyPVKTk7WXXfdpaKiIsXFxZG7QCtXW1urnTt3Kioqip+3gBd4rS3GAw88oLvvvlvJyclKSUnR888/r7179+r+++/3VggAfqC6ulpffPGF67i0tFRFRUUKCwtTTEyMMjIyNGvWLPXo0UM9evTQrFmzFBgYqDvvvFOSFBoaqt/+9reaMmWKwsPDFRYWpqlTpyo+Pl79+/dvqdsCzlvjx4/XkiVL9MYbbyg4ONi1+yI0NFQBAQGyWCzkLdDKPPzwwxo0aJCio6NVVVWlpUuXauPGjXrrrbfIWaCVCg4Odj3PoFHHjh0VHh7uGid3gdZl6tSpGjp0qGJiYlRRUaHs7GxVVlYqLS2Nn7eANxhe9Mwzzxhdu3Y1/Pz8jMTERKOgoMCbywP4gQ0bNhiSmrzS0tIMwzCMhoYGIzMz07Db7YbNZjN++tOfGtu3b3e7xrFjx4z09HQjLCzMCAgIMIYMGWLs3bu3Be4GOP+dKF8lGX/+859dc8hboHW59957XX/2jYiIMPr162esW7fOdZ6cBdqGvn37GpMmTXIdk7tA6/LLX/7SiIqKMqxWq+FwOIzhw4cbxcXFrvPkLOBZFsMwjBaqawMAAAAAAAAA2iiv9FwGAAAAAAAAAJxfKC4DAAAAAAAAAEyjuAwAAAAAAAAAMI3iMgAAAAAAAADANIrLAAAAAAAAAADTKC4DAAAAAAAAAEyjuAwAAAAAAAAAMI3iMgAAAAAAAADANIrLAAAAAAAAAADTKC4DAAAAAAAAAEyjuAwAAAAAAAAAMO3/AaSMuZ2t8yZ7AAAAAElFTkSuQmCC",
      "text/plain": [
       "<Figure size 1600x50 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Split --> 417\n"
     ]
    }
   ],
   "source": [
    "#| export\n",
    "assert config.analysis_mode in ['offline','online'], 'Invalid analysis mode'\n",
    "\n",
    "X = X_train\n",
    "if verbose > 0: print(\"len(X): \", len(X));\n",
    "if config.analysis_mode == 'online':\n",
    "    if verbose > 0: print(\"--> Split 1\")\n",
    "    splits = TimeSplitter(valid_size=0.2, show_plot=show_plots)(X)\n",
    "elif config.analysis_mode == 'offline':\n",
    "    if verbose > 0: print(\"--> Split 2\")\n",
    "    splits = get_splits(np.arange(len(X)), valid_size=config.valid_size, show_plot = show_plots)\n",
    "if verbose > 0: \n",
    "    print(\"Split -->\", len(splits[0]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "072b6522-bcaa-46ae-bf32-31f31dae4bf6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(521, 3, 30)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "((#417) [0,1,2,3,4,5,6,7,8,9...],\n",
       " (#104) [417,418,419,420,421,422,423,424,425,426...])"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#| hide\n",
    "if verbose > 0: \n",
    "    print(X.shape)\n",
    "    display(splits)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1183ff9a-fb49-4381-9125-dc08b36aa7ab",
   "metadata": {},
   "source": [
    "## Load & get embeddings from moirai module"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "e1b6b2be-a055-4618-ab99-7d171b5834ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_variate_id(\n",
    "    batch_size, \n",
    "    seq_len, \n",
    "    num_variates\n",
    "):\n",
    "    # Crear un tensor de variate_id con tamaño (batch_size, seq_len, num_variates)\n",
    "    variate_id = torch.arange(num_variates).unsqueeze(0).unsqueeze(0).repeat(batch_size, seq_len, 1)\n",
    "    return variate_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "1176e835-f851-4e03-af55-73bdb2b9d211",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size, num_variates, seq_len = X.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39243d9a-d4e0-4d59-9423-d3ddf2eb46bc",
   "metadata": {},
   "source": [
    "Aquí tendremos que seleccionar cualquiera de los modelos preentrenados en Moirai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "1231eef3-f10d-41ee-9c60-439bed9a92c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#model_size = 'large'\n",
    "model_size = 'small'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9bcbdbc-8459-43c6-8437-b0866e20f546",
   "metadata": {},
   "source": [
    "Nuestro X tiene tamaño \n",
    "num_ventanas x num_variables x tamaño_ventana\n",
    "\n",
    "El target que recibe Moirai tiene tamaño \n",
    "num_ventanas x tamaño_ventana x num_variables\n",
    "\n",
    "Permutamos para ajustar la entrada correctamente"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "042b0780-5775-4c84-9ee6-003c4b32f905",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([521, 30, 3])"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create target ~ ( batch , seq_length , max_patch )\n",
    "target = torch.randn(batch_size, seq_len, num_variates)\n",
    "target.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "952c780d-4e43-42ca-a09a-8507d641a145",
   "metadata": {},
   "source": [
    "Como todos los valores son observados, hacemos que el observed mask esté a 1\n",
    "Como el tamaño es el mismo que el del target, usamos torch.ones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "2d2c7f90-6d22-4168-8ede-f6f7fc2aec07",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(521, 3, 30)"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "97aec840-b37d-4a72-912d-45495376ea87",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_windows, num_variates, window_len = X.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da37749e-bbbc-4b63-a6d6-155d2e3b03a0",
   "metadata": {},
   "source": [
    "---> Me hubiera gustado coger patch_size 8  para que tuviera sentido para toy que la ventana tiene tamaño 30, pero parece ser que el modelo está pre-entrenado con tamaño 128 y eso nos da problemas. Igual podemos paddear a 0 también de manera individual cada token (a modo de ñapa)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "id": "3c95eb6a-a38c-4b77-8725-6405e3b25dbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = num_windows\n",
    "seq_len = window_len * num_variates\n",
    "patch_size = 8 \n",
    "#patch_size = 128\n",
    "max_patch = patch_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "id": "a7f611aa-0172-4ce4-88be-c843d0911c3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "auxiliar = MoiraiForecast(\n",
    "    module=MoiraiModule.from_pretrained(f\"Salesforce/moirai-1.0-R-{model_size}\"),\n",
    "    prediction_length=window_len, # No puede ser 0 porque falla el predictor... Pongo window len que es lo más parecido que tengo a \"aprender mismos tamaños\"\n",
    "    context_length=target.shape[2],\n",
    "    patch_size=patch_size,\n",
    "    num_samples=100,\n",
    "    target_dim=1,\n",
    "    feat_dynamic_real_dim = 0,\n",
    "    past_feat_dynamic_real_dim = 0\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "id": "edc4e3ac-8e97-4e3c-854c-e279fea784ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "#( \n",
    " #   target_, \n",
    " #   observed_mask_, \n",
    " #   sample_id_,\n",
    " #   time_id_,\n",
    " #   variate_id_, \n",
    " #   prediction_mask_\n",
    "#)  = auxiliar._convert(\n",
    " #   patch_size  = patch_size, \n",
    " #   past_target = target,\n",
    " #   past_observed_target = torch.ones_like(target), \n",
    " #   past_is_pad = observed_mask\n",
    "#)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "id": "0080cdd7-f005-4af1-9dfb-3991ce2e4541",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictor = auxiliar.create_predictor(batch_size = batch_size)\n",
    "forecasts = predictor.predict(target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "id": "eeeb7a99-8716-4969-8165-bca698d46b42",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_transform =  auxiliar.get_default_transform()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "id": "c78060b2-c6c5-459e-b37c-bb8cec44c713",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Chain(transformations=[gluonts.transform.convert.AsNumpyArray(dtype=<class 'numpy.float32'>, expected_ndim=1, field='target'), gluonts.transform.convert.ExpandDimArray(axis=0, field='target'), gluonts.transform.feature.AddObservedValuesIndicator(dtype=<class 'bool'>, imputation_method=gluonts.transform.feature.DummyValueImputation(dummy_value=0.0), output_field='observed_target', target_field='target')])"
      ]
     },
     "execution_count": 158,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_transform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "id": "243c71c0-85e1-4375-9dda-8cfcb697b330",
   "metadata": {},
   "outputs": [],
   "source": [
    "from gluonts.transform.split import TFTInstanceSplitter\n",
    "from gluonts.transform.sampler import TestSplitSampler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "id": "00dc0a5d-2fe9-4a50-90be-73bc339c640d",
   "metadata": {},
   "outputs": [],
   "source": [
    "instance_splitter = TFTInstanceSplitter(\n",
    "    instance_sampler=TestSplitSampler(),\n",
    "    past_length=target.shape[2],\n",
    "    future_length=window_len, #No permite 0\n",
    "    observed_value_field=\"observed_target\",\n",
    "    time_series_fields=[],\n",
    "    past_time_series_fields=[],\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "id": "22f30fcd-fae8-43ed-b75e-4597492831a3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "gluonts.transform.split.TFTInstanceSplitter(dummy_value=0.0, forecast_start_field='forecast_start', future_length=30, instance_sampler=PredictionSplitSampler(axis=-1, min_past=0, min_future=0, allow_empty_interval=False), is_pad_field='is_pad', lead_time=0, observed_value_field='observed_target', output_NTC=True, past_length=8, past_time_series_fields=[], start_field='start', target_field='target', time_series_fields=[])"
      ]
     },
     "execution_count": 147,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "instance_splitter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "id": "c78274b9-53fb-49f3-87d0-0f1495b10793",
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "einsum(): subscript b has size 8 for operand 1 which does not broadcast with previously seen size 128",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[161], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m res \u001b[38;5;241m=\u001b[39m \u001b[43mauxiliar\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodule\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m      2\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtarget\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mtarget\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfloat\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      3\u001b[0m \u001b[43m    \u001b[49m\u001b[43mobserved_mask\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mobserved_mask\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfloat\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      4\u001b[0m \u001b[43m    \u001b[49m\u001b[43msample_id\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43msample_id\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      5\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtime_id\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mtime_id\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      6\u001b[0m \u001b[43m    \u001b[49m\u001b[43mvariate_id\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mvariate_id\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      7\u001b[0m \u001b[43m    \u001b[49m\u001b[43mprediction_mask\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mprediction_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      8\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpatch_size\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mpatch_size_tensor\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfloat\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      9\u001b[0m \u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/torch/nn/modules/module.py:1553\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1551\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1552\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1553\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/torch/nn/modules/module.py:1562\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1557\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1558\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1559\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1560\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1561\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1562\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1564\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1565\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/work/nbs_pipeline/uni2ts/src/uni2ts/model/moirai/module.py:168\u001b[0m, in \u001b[0;36mMoiraiModule.forward\u001b[0;34m(self, target, observed_mask, sample_id, time_id, variate_id, prediction_mask, patch_size)\u001b[0m\n\u001b[1;32m    161\u001b[0m loc, scale \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mscaler(\n\u001b[1;32m    162\u001b[0m     target,\n\u001b[1;32m    163\u001b[0m     observed_mask \u001b[38;5;241m*\u001b[39m \u001b[38;5;241m~\u001b[39mprediction_mask\u001b[38;5;241m.\u001b[39munsqueeze(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m),\n\u001b[1;32m    164\u001b[0m     sample_id,\n\u001b[1;32m    165\u001b[0m     variate_id,\n\u001b[1;32m    166\u001b[0m )\n\u001b[1;32m    167\u001b[0m scaled_target \u001b[38;5;241m=\u001b[39m (target \u001b[38;5;241m-\u001b[39m loc) \u001b[38;5;241m/\u001b[39m scale\n\u001b[0;32m--> 168\u001b[0m reprs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43min_proj\u001b[49m\u001b[43m(\u001b[49m\u001b[43mscaled_target\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpatch_size\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    169\u001b[0m masked_reprs \u001b[38;5;241m=\u001b[39m mask_fill(reprs, prediction_mask, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmask_encoding\u001b[38;5;241m.\u001b[39mweight)\n\u001b[1;32m    170\u001b[0m reprs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mencoder(\n\u001b[1;32m    171\u001b[0m     masked_reprs,\n\u001b[1;32m    172\u001b[0m     packed_attention_mask(sample_id),\n\u001b[1;32m    173\u001b[0m     time_id\u001b[38;5;241m=\u001b[39mtime_id,\n\u001b[1;32m    174\u001b[0m     var_id\u001b[38;5;241m=\u001b[39mvariate_id,\n\u001b[1;32m    175\u001b[0m )\n",
      "File \u001b[0;32m/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/torch/nn/modules/module.py:1553\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1551\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1552\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1553\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/torch/nn/modules/module.py:1562\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1557\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1558\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1559\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1560\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1561\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1562\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1564\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1565\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/work/nbs_pipeline/uni2ts/src/uni2ts/module/ts_embed.py:100\u001b[0m, in \u001b[0;36mMultiInSizeLinear.forward\u001b[0;34m(self, x, in_feat_size)\u001b[0m\n\u001b[1;32m     96\u001b[0m     weight \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mweight[idx] \u001b[38;5;241m*\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmask[idx]\n\u001b[1;32m     97\u001b[0m     bias \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbias[idx] \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbias \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;241m0\u001b[39m\n\u001b[1;32m     98\u001b[0m     out \u001b[38;5;241m=\u001b[39m out \u001b[38;5;241m+\u001b[39m (\n\u001b[1;32m     99\u001b[0m         torch\u001b[38;5;241m.\u001b[39meq(in_feat_size, feat_size)\u001b[38;5;241m.\u001b[39munsqueeze(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[0;32m--> 100\u001b[0m         \u001b[38;5;241m*\u001b[39m (\u001b[43meinsum\u001b[49m\u001b[43m(\u001b[49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mout inp, ... inp -> ... out\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m \u001b[38;5;241m+\u001b[39m bias)\n\u001b[1;32m    101\u001b[0m     )\n\u001b[1;32m    102\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m out\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/einops/einops.py:901\u001b[0m, in \u001b[0;36meinsum\u001b[0;34m(*tensors_and_pattern)\u001b[0m\n\u001b[1;32m    899\u001b[0m tensors \u001b[38;5;241m=\u001b[39m tensors_and_pattern[:\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m]\n\u001b[1;32m    900\u001b[0m pattern \u001b[38;5;241m=\u001b[39m _compactify_pattern_for_einsum(pattern)\n\u001b[0;32m--> 901\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mget_backend\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtensors\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43meinsum\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpattern\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mtensors\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/einops/_backends.py:287\u001b[0m, in \u001b[0;36mTorchBackend.einsum\u001b[0;34m(self, pattern, *x)\u001b[0m\n\u001b[1;32m    286\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21meinsum\u001b[39m(\u001b[38;5;28mself\u001b[39m, pattern, \u001b[38;5;241m*\u001b[39mx):\n\u001b[0;32m--> 287\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43meinsum\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpattern\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/torch/functional.py:386\u001b[0m, in \u001b[0;36meinsum\u001b[0;34m(*args)\u001b[0m\n\u001b[1;32m    381\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m einsum(equation, \u001b[38;5;241m*\u001b[39m_operands)\n\u001b[1;32m    383\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(operands) \u001b[38;5;241m<\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m2\u001b[39m \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m opt_einsum\u001b[38;5;241m.\u001b[39menabled:\n\u001b[1;32m    384\u001b[0m     \u001b[38;5;66;03m# the path for contracting 0 or 1 time(s) is already optimized\u001b[39;00m\n\u001b[1;32m    385\u001b[0m     \u001b[38;5;66;03m# or the user has disabled using opt_einsum\u001b[39;00m\n\u001b[0;32m--> 386\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_VF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43meinsum\u001b[49m\u001b[43m(\u001b[49m\u001b[43mequation\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moperands\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# type: ignore[attr-defined]\u001b[39;00m\n\u001b[1;32m    388\u001b[0m path \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    389\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m opt_einsum\u001b[38;5;241m.\u001b[39mis_available():\n",
      "\u001b[0;31mRuntimeError\u001b[0m: einsum(): subscript b has size 8 for operand 1 which does not broadcast with previously seen size 128"
     ]
    }
   ],
   "source": [
    "res = auxiliar.module(\n",
    "    target = target.float(),\n",
    "    observed_mask = observed_mask.float(),\n",
    "    sample_id = sample_id,\n",
    "    time_id = time_id,\n",
    "    variate_id = variate_id,\n",
    "    prediction_mask = prediction_mask,\n",
    "    patch_size = patch_size_tensor.float()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "id": "10f886f7-3b8f-414e-8d5b-410bd96a1124",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([521, 12, 8])\n"
     ]
    }
   ],
   "source": [
    "print(target.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "id": "8054403a-8aa2-44e8-b5bc-f58d4ebd4f6e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8\n"
     ]
    }
   ],
   "source": [
    "print(patch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "id": "7d1b5f33-d895-4c89-af70-54c859684148",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "30\n",
      "521\n"
     ]
    }
   ],
   "source": [
    "print(window_len)\n",
    "print(batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "4a66dd80-8a60-4e82-8d0f-4cddf23bd673",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001b[0;31mSignature:\u001b[0m  \u001b[0mauxiliar\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcreate_predictor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mstr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'auto'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mgluonts\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredictor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mPyTorchPredictor\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
       "\u001b[0;31mDocstring:\u001b[0m <no docstring>\n",
       "\u001b[0;31mSource:\u001b[0m   \n",
       "    \u001b[0;32mdef\u001b[0m \u001b[0mcreate_predictor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m        \u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m        \u001b[0mbatch_size\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m        \u001b[0mdevice\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mstr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"auto\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mPyTorchPredictor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m        \u001b[0mts_fields\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m        \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhparams\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfeat_dynamic_real_dim\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m            \u001b[0mts_fields\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"feat_dynamic_real\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m            \u001b[0mts_fields\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"observed_feat_dynamic_real\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m        \u001b[0mpast_ts_fields\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m        \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhparams\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpast_feat_dynamic_real_dim\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m            \u001b[0mpast_ts_fields\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"past_feat_dynamic_real\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m            \u001b[0mpast_ts_fields\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"past_observed_feat_dynamic_real\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m        \u001b[0minstance_splitter\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTFTInstanceSplitter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m            \u001b[0minstance_sampler\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mTestSplitSampler\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m            \u001b[0mpast_length\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpast_length\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m            \u001b[0mfuture_length\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhparams\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprediction_length\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m            \u001b[0mobserved_value_field\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"observed_target\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m            \u001b[0mtime_series_fields\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mts_fields\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m            \u001b[0mpast_time_series_fields\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpast_ts_fields\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m        \u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m        \u001b[0;32mreturn\u001b[0m \u001b[0mPyTorchPredictor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m            \u001b[0minput_names\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprediction_input_names\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m            \u001b[0mprediction_net\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m            \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m            \u001b[0mprediction_length\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhparams\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprediction_length\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m            \u001b[0minput_transform\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_default_transform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0minstance_splitter\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m            \u001b[0mdevice\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m        \u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
       "\u001b[0;31mFile:\u001b[0m      ~/work/nbs_pipeline/uni2ts/src/uni2ts/model/moirai/forecast.py\n",
       "\u001b[0;31mType:\u001b[0m      method"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "?? auxiliar.create_predictor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "964d2a92-6524-4749-9093-51743570675f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_and_pad(X, patch_size):\n",
    "    # X tiene forma (bs, n variables, longitud)\n",
    "    bs, n_vars, length = X.shape\n",
    "    \n",
    "    # Calculamos el número de patches\n",
    "    n_patches = int(np.ceil(length / patch_size))\n",
    "    \n",
    "    # Creamos un array con ceros que tenga el tamaño del nuevo array dividido en patches\n",
    "    padded_length = n_patches * patch_size\n",
    "    X_padded = np.zeros((bs, n_vars, padded_length))\n",
    "    \n",
    "    # Rellenamos X_padded con los valores originales de X\n",
    "    X_padded[:, :, :length] = X\n",
    "    \n",
    "    # Ahora dividimos X_padded en bloques de tamaño patch_size\n",
    "    X_patches = X_padded.reshape(bs, n_vars, n_patches, patch_size)\n",
    "    \n",
    "    X_flat = X_patches.transpose(0, 2, 1, 3).reshape(bs, n_patches * n_vars, patch_size)\n",
    "\n",
    "    # Transformamos a un tensor de PyTorch\n",
    "    X_patches_torch = torch.tensor(X_flat)\n",
    "    \n",
    "    return X_patches_torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "54f7305c-afb0-43c5-9af3-4c4f23691131",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4.0"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n_patches = np.ceil(window_len/patch_size)\n",
    "n_patches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "3554c072-7cdd-41c5-9742-d1fbe1cdc010",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "12.0"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.ceil(window_len/patch_size)*num_variates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "dfaad26c-8a6d-4401-8e00-87625f2a5afc",
   "metadata": {},
   "outputs": [],
   "source": [
    "target = split_and_pad(X, patch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "899e2d6d-f57b-4138-96ee-894d78380bf8",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size, seq_len, max_patch = target.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "3388d823-5f01-4b54-b8ef-51f083435295",
   "metadata": {},
   "outputs": [],
   "source": [
    "observed_mask = torch.zeros_like(target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "b12a2fb2-86b3-4838-9f26-70972585088b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_sample_id(X_patches_torch):\n",
    "    batch_size, seq_len, _ = X_patches_torch.shape\n",
    "    # Generamos un tensor que comienza en 0 y va incrementando de 1 en 1 hasta seq_len * batch_size - 1\n",
    "    return torch.arange(batch_size * seq_len).view(batch_size, seq_len)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "3aeb7506-c95f-49cc-b4a7-ab8219ffff30",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([521, 12])\n",
      "tensor([[   0,    1,    2,  ...,    9,   10,   11],\n",
      "        [  12,   13,   14,  ...,   21,   22,   23],\n",
      "        [  24,   25,   26,  ...,   33,   34,   35],\n",
      "        ...,\n",
      "        [6216, 6217, 6218,  ..., 6225, 6226, 6227],\n",
      "        [6228, 6229, 6230,  ..., 6237, 6238, 6239],\n",
      "        [6240, 6241, 6242,  ..., 6249, 6250, 6251]])\n"
     ]
    }
   ],
   "source": [
    "sample_id = get_sample_id(target)\n",
    "print(sample_id.shape)\n",
    "print(sample_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "57320b93-ae0e-4e1e-8e5d-d76a69dbe886",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_variate_id(batch_size, seq_len, n_vars, patches_per_var):\n",
    "    patches_per_var = int(patches_per_var)\n",
    "    # Creamos un tensor que repite cada ID de variable patches_per_var veces\n",
    "    var_ids = torch.arange(n_vars).repeat_interleave(patches_per_var)\n",
    "    # Repetimos este patrón para cada muestra en el batch\n",
    "    return var_ids.unsqueeze(0).repeat(batch_size, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "468aca3d-dfb9-4e64-a461-395c81554006",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch_size 521, \n",
      " seq_len 12, \n",
      " n_vars 3, \n",
      "  patches_per_var 4.0\n"
     ]
    }
   ],
   "source": [
    "print(f\"batch_size {batch_size}, \\n seq_len {seq_len}, \\n n_vars {num_variates}, \\n  patches_per_var {n_patches}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "b0cce1a3-06a2-4a99-91b8-e2bdf881a956",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([521, 12])\n",
      "tensor([[0, 0, 0,  ..., 2, 2, 2],\n",
      "        [0, 0, 0,  ..., 2, 2, 2],\n",
      "        [0, 0, 0,  ..., 2, 2, 2],\n",
      "        ...,\n",
      "        [0, 0, 0,  ..., 2, 2, 2],\n",
      "        [0, 0, 0,  ..., 2, 2, 2],\n",
      "        [0, 0, 0,  ..., 2, 2, 2]])\n"
     ]
    }
   ],
   "source": [
    "variate_id = get_variate_id(\n",
    "    batch_size = batch_size, \n",
    "    seq_len = seq_len, \n",
    "    n_vars = num_variates, \n",
    "    patches_per_var = n_patches\n",
    ")\n",
    "print(variate_id.shape)\n",
    "print(variate_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "3fa6ddfa-119f-4821-9f0d-061a3af91040",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_time_id(batch_size, seq_len, patches_per_var):\n",
    "    patches_per_var = int (patches_per_var)\n",
    "    # Creamos un tensor que repite una secuencia de 0 a patches_per_var-1\n",
    "    time_ids = torch.arange(patches_per_var).repeat(seq_len // patches_per_var + 1)[:seq_len]\n",
    "    # Repetimos este patrón para cada muestra en el batch\n",
    "    return time_ids.unsqueeze(0).repeat(batch_size, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "35424515-3594-49d9-b564-906cb9e8671a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([521, 12])\n",
      "tensor([[0, 1, 2,  ..., 1, 2, 3],\n",
      "        [0, 1, 2,  ..., 1, 2, 3],\n",
      "        [0, 1, 2,  ..., 1, 2, 3],\n",
      "        ...,\n",
      "        [0, 1, 2,  ..., 1, 2, 3],\n",
      "        [0, 1, 2,  ..., 1, 2, 3],\n",
      "        [0, 1, 2,  ..., 1, 2, 3]])\n"
     ]
    }
   ],
   "source": [
    "time_id = get_time_id(batch_size, seq_len, n_patches)\n",
    "print(time_id.shape)\n",
    "print(time_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "a4a8da4f-ed4c-4249-98cd-6d028ee5ddc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get pre-trained module\n",
    "module = MoiraiModule.from_pretrained(f\"Salesforce/moirai-1.0-R-{model_size}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "0f026196-0bfa-4c1f-a3e4-97d3c1dae97a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "384"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "module.d_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "f9782b10-3048-4618-9273-706bbdf0f953",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<bound method Module.named_modules of MoiraiModule(\n",
       "  (mask_encoding): Embedding(1, 384)\n",
       "  (scaler): PackedStdScaler()\n",
       "  (in_proj): MultiInSizeLinear(in_features_ls=[8, 16, 32, 64, 128], out_features=384, bias=True, dtype=torch.float32)\n",
       "  (encoder): TransformerEncoder(\n",
       "    (layers): ModuleList(\n",
       "      (0-5): 6 x TransformerEncoderLayer(\n",
       "        (self_attn): GroupedQueryAttention(\n",
       "          (var_attn_bias): BinaryAttentionBias(\n",
       "            (emb): Embedding(2, 6)\n",
       "          )\n",
       "          (time_qk_proj): QueryKeyProjection(\n",
       "            (query_proj): RotaryProjection()\n",
       "            (key_proj): RotaryProjection()\n",
       "          )\n",
       "          (q_proj): Linear(in_features=384, out_features=384, bias=False)\n",
       "          (k_proj): Linear(in_features=384, out_features=384, bias=False)\n",
       "          (v_proj): Linear(in_features=384, out_features=384, bias=False)\n",
       "          (q_norm): RMSNorm(normalized_shape=(64,), eps=1e-05, weight=True)\n",
       "          (k_norm): RMSNorm(normalized_shape=(64,), eps=1e-05, weight=True)\n",
       "          (out_proj): Linear(in_features=384, out_features=384, bias=False)\n",
       "        )\n",
       "        (ffn): GatedLinearUnitFeedForward(\n",
       "          (fc1): Linear(in_features=384, out_features=1024, bias=False)\n",
       "          (fc2): Linear(in_features=1024, out_features=384, bias=False)\n",
       "          (dropout1): Dropout(p=0.0, inplace=False)\n",
       "          (dropout2): Dropout(p=0.0, inplace=False)\n",
       "          (fc_gate): Linear(in_features=384, out_features=1024, bias=False)\n",
       "        )\n",
       "        (norm1): RMSNorm(normalized_shape=(384,), eps=1e-05, weight=True)\n",
       "        (norm2): RMSNorm(normalized_shape=(384,), eps=1e-05, weight=True)\n",
       "        (dropout): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "    )\n",
       "    (norm): RMSNorm(normalized_shape=(384,), eps=1e-05, weight=True)\n",
       "  )\n",
       "  (param_proj): DistrParamProj(\n",
       "    (proj): ModuleDict(\n",
       "      (weights_logits): MultiOutSizeLinear(in_features=384, out_features_ls=(32, 64, 128, 256, 512), bias=True, dtype=torch.float32)\n",
       "      (components): ModuleList(\n",
       "        (0): ModuleDict(\n",
       "          (df): MultiOutSizeLinear(in_features=384, out_features_ls=(8, 16, 32, 64, 128), bias=True, dtype=torch.float32)\n",
       "          (loc): MultiOutSizeLinear(in_features=384, out_features_ls=(8, 16, 32, 64, 128), bias=True, dtype=torch.float32)\n",
       "          (scale): MultiOutSizeLinear(in_features=384, out_features_ls=(8, 16, 32, 64, 128), bias=True, dtype=torch.float32)\n",
       "        )\n",
       "        (1): ModuleDict(\n",
       "          (loc): MultiOutSizeLinear(in_features=384, out_features_ls=(8, 16, 32, 64, 128), bias=True, dtype=torch.float32)\n",
       "        )\n",
       "        (2): ModuleDict(\n",
       "          (total_count): MultiOutSizeLinear(in_features=384, out_features_ls=(8, 16, 32, 64, 128), bias=True, dtype=torch.float32)\n",
       "          (logits): MultiOutSizeLinear(in_features=384, out_features_ls=(8, 16, 32, 64, 128), bias=True, dtype=torch.float32)\n",
       "        )\n",
       "        (3): ModuleDict(\n",
       "          (loc): MultiOutSizeLinear(in_features=384, out_features_ls=(8, 16, 32, 64, 128), bias=True, dtype=torch.float32)\n",
       "          (scale): MultiOutSizeLinear(in_features=384, out_features_ls=(8, 16, 32, 64, 128), bias=True, dtype=torch.float32)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       ")>"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "module.named_modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "db4d0cbf-01ec-406a-9013-97eeebadc842",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1024"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "2**10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "1651022f-cf52-4926-9de6-05487dd58181",
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction_mask = torch.zeros((batch_size, seq_len), dtype=torch.bool)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "6691097d-206e-4aa2-883e-08604b297c25",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([521, 8])"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "patch_size_tensor = torch.zeros((batch_size, patch_size))+patch_size\n",
    "patch_size_tensor.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "8c48d2b8-d5e3-46ce-b6f4-901e95fd5462",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001b[0;31mSignature:\u001b[0m\n",
       " \u001b[0mmodule\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mtarget\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mjaxtyping\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mFloat\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'*batch seq_len max_patch'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mobserved_mask\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mjaxtyping\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mBool\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'*batch seq_len max_patch'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0msample_id\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mjaxtyping\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mInt\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'*batch seq_len'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mtime_id\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mjaxtyping\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mInt\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'*batch seq_len'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mvariate_id\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mjaxtyping\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mInt\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'*batch seq_len'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mprediction_mask\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mjaxtyping\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mBool\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'*batch seq_len'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mpatch_size\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mjaxtyping\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mInt\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'*batch seq_len'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdistributions\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdistribution\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDistribution\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
       "\u001b[0;31mDocstring:\u001b[0m\n",
       "Defines the forward pass of MoiraiModule.\n",
       "This method expects processed inputs.\n",
       "\n",
       "1. Apply scaling to observations\n",
       "2. Project from observations to representations\n",
       "3. Replace prediction window with learnable mask\n",
       "4. Apply transformer layers\n",
       "5. Project from representations to distribution parameters\n",
       "6. Return distribution object\n",
       "\n",
       ":param target: input data\n",
       ":param observed_mask: binary mask for missing values, 1 if observed, 0 otherwise\n",
       ":param sample_id: indices indicating the sample index (for packing)\n",
       ":param time_id: indices indicating the time index\n",
       ":param variate_id: indices indicating the variate index\n",
       ":param prediction_mask: binary mask for prediction horizon, 1 if part of the horizon, 0 otherwise\n",
       ":param patch_size: patch size for each token\n",
       ":return: predictive distribution\n",
       "\u001b[0;31mFile:\u001b[0m      ~/work/nbs_pipeline/uni2ts/src/uni2ts/model/moirai/module.py\n",
       "\u001b[0;31mType:\u001b[0m      method"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "? module.forward"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "205f1297-8c80-427a-b664-d4a2a6ec5a11",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "target ~ torch.Size([521, 12, 8])\n",
      "observed_mask ~ torch.Size([521, 12, 8])\n",
      "sample_id ~ torch.Size([521, 12])\n",
      "time_id ~ torch.Size([521, 12])\n",
      "variate_id ~ torch.Size([521, 12])\n",
      "prediction_mask ~ torch.Size([521, 12])\n",
      "patch_size_tensor ~ torch.Size([521, 8])\n"
     ]
    }
   ],
   "source": [
    "print(f\"target ~ {target.shape}\")\n",
    "print(f\"observed_mask ~ {observed_mask.shape}\")\n",
    "print(f\"sample_id ~ {sample_id.shape}\")\n",
    "print(f\"time_id ~ {time_id.shape}\")\n",
    "print(f\"variate_id ~ {variate_id.shape}\")\n",
    "print(f\"prediction_mask ~ {prediction_mask.shape}\")\n",
    "print(f\"patch_size_tensor ~ {patch_size_tensor.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "a3f850f8-94b7-40e3-b92a-378e1ce4a31e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([521, 12, 8])"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "d5dfebc1-9178-47a7-95d3-7418bc89d3c8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001b[0;31mSignature:\u001b[0m       \u001b[0mmodule\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
       "\u001b[0;31mType:\u001b[0m           MoiraiModule\n",
       "\u001b[0;31mString form:\u001b[0m   \n",
       "MoiraiModule(\n",
       "           (mask_encoding): Embedding(1, 384)\n",
       "           (scaler): PackedStdScaler()\n",
       "           (in_proj): Mul <...> t_features_ls=(8, 16, 32, 64, 128), bias=True, dtype=torch.float32)\n",
       "           )\n",
       "           )\n",
       "           )\n",
       "           )\n",
       "           )\n",
       "\u001b[0;31mFile:\u001b[0m           ~/work/nbs_pipeline/uni2ts/src/uni2ts/model/moirai/module.py\n",
       "\u001b[0;31mDocstring:\u001b[0m     \n",
       "Contains components of Moirai, to ensure implementation is identical across models.\n",
       "Subclasses huggingface_hub.PyTorchModelHubMixin to support loading from HuggingFace Hub.\n",
       "\u001b[0;31mInit docstring:\u001b[0m\n",
       ":param distr_output: distribution output object\n",
       ":param d_model: model hidden dimensions\n",
       ":param num_layers: number of transformer layers\n",
       ":param patch_sizes: sequence of patch sizes\n",
       ":param max_seq_len: maximum sequence length for inputs\n",
       ":param attn_dropout_p: dropout probability for attention layers\n",
       ":param dropout_p: dropout probability for all other layers\n",
       ":param scaling: whether to apply scaling (standardization)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "? module"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "c162f127-9249-4211-afce-a05bcb96bca2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<bound method Module.named_modules of MoiraiModule(\n",
       "  (mask_encoding): Embedding(1, 384)\n",
       "  (scaler): PackedStdScaler()\n",
       "  (in_proj): MultiInSizeLinear(in_features_ls=[8, 16, 32, 64, 128], out_features=384, bias=True, dtype=torch.float32)\n",
       "  (encoder): TransformerEncoder(\n",
       "    (layers): ModuleList(\n",
       "      (0-5): 6 x TransformerEncoderLayer(\n",
       "        (self_attn): GroupedQueryAttention(\n",
       "          (var_attn_bias): BinaryAttentionBias(\n",
       "            (emb): Embedding(2, 6)\n",
       "          )\n",
       "          (time_qk_proj): QueryKeyProjection(\n",
       "            (query_proj): RotaryProjection()\n",
       "            (key_proj): RotaryProjection()\n",
       "          )\n",
       "          (q_proj): Linear(in_features=384, out_features=384, bias=False)\n",
       "          (k_proj): Linear(in_features=384, out_features=384, bias=False)\n",
       "          (v_proj): Linear(in_features=384, out_features=384, bias=False)\n",
       "          (q_norm): RMSNorm(normalized_shape=(64,), eps=1e-05, weight=True)\n",
       "          (k_norm): RMSNorm(normalized_shape=(64,), eps=1e-05, weight=True)\n",
       "          (out_proj): Linear(in_features=384, out_features=384, bias=False)\n",
       "        )\n",
       "        (ffn): GatedLinearUnitFeedForward(\n",
       "          (fc1): Linear(in_features=384, out_features=1024, bias=False)\n",
       "          (fc2): Linear(in_features=1024, out_features=384, bias=False)\n",
       "          (dropout1): Dropout(p=0.0, inplace=False)\n",
       "          (dropout2): Dropout(p=0.0, inplace=False)\n",
       "          (fc_gate): Linear(in_features=384, out_features=1024, bias=False)\n",
       "        )\n",
       "        (norm1): RMSNorm(normalized_shape=(384,), eps=1e-05, weight=True)\n",
       "        (norm2): RMSNorm(normalized_shape=(384,), eps=1e-05, weight=True)\n",
       "        (dropout): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "    )\n",
       "    (norm): RMSNorm(normalized_shape=(384,), eps=1e-05, weight=True)\n",
       "  )\n",
       "  (param_proj): DistrParamProj(\n",
       "    (proj): ModuleDict(\n",
       "      (weights_logits): MultiOutSizeLinear(in_features=384, out_features_ls=(32, 64, 128, 256, 512), bias=True, dtype=torch.float32)\n",
       "      (components): ModuleList(\n",
       "        (0): ModuleDict(\n",
       "          (df): MultiOutSizeLinear(in_features=384, out_features_ls=(8, 16, 32, 64, 128), bias=True, dtype=torch.float32)\n",
       "          (loc): MultiOutSizeLinear(in_features=384, out_features_ls=(8, 16, 32, 64, 128), bias=True, dtype=torch.float32)\n",
       "          (scale): MultiOutSizeLinear(in_features=384, out_features_ls=(8, 16, 32, 64, 128), bias=True, dtype=torch.float32)\n",
       "        )\n",
       "        (1): ModuleDict(\n",
       "          (loc): MultiOutSizeLinear(in_features=384, out_features_ls=(8, 16, 32, 64, 128), bias=True, dtype=torch.float32)\n",
       "        )\n",
       "        (2): ModuleDict(\n",
       "          (total_count): MultiOutSizeLinear(in_features=384, out_features_ls=(8, 16, 32, 64, 128), bias=True, dtype=torch.float32)\n",
       "          (logits): MultiOutSizeLinear(in_features=384, out_features_ls=(8, 16, 32, 64, 128), bias=True, dtype=torch.float32)\n",
       "        )\n",
       "        (3): ModuleDict(\n",
       "          (loc): MultiOutSizeLinear(in_features=384, out_features_ls=(8, 16, 32, 64, 128), bias=True, dtype=torch.float32)\n",
       "          (scale): MultiOutSizeLinear(in_features=384, out_features_ls=(8, 16, 32, 64, 128), bias=True, dtype=torch.float32)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       ")>"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "module.named_modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "43fd1568-304f-412e-9de9-d8e3633c8ca4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Object ` uni2ts._convert` not found.\n"
     ]
    }
   ],
   "source": [
    "? uni2ts._convert"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a84fdf73-757d-4244-af96-e2387e219ea9",
   "metadata": {},
   "outputs": [],
   "source": [
    "res = module(\n",
    "    target = target.float(),\n",
    "    observed_mask = observed_mask.float(),\n",
    "    sample_id = sample_id,\n",
    "    time_id = time_id,\n",
    "    variate_id = variate_id,\n",
    "    prediction_mask = prediction_mask,\n",
    "    patch_size = patch_size_tensor.float()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "911e92f3-628e-45c1-9fcc-241311a4384e",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(patch_size_tensor.shape)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
