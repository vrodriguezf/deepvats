{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'timecluster_extension'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 8\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mpd\u001b[39;00m\n\u001b[1;32m      7\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mnumpy\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mnp\u001b[39;00m\n\u001b[0;32m----> 8\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtimecluster_extension\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mload\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;241m*\u001b[39m\n\u001b[1;32m      9\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtimecluster_extension\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdr\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;241m*\u001b[39m\n\u001b[1;32m     10\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtimecluster_extension\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mvisualization\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;241m*\u001b[39m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'timecluster_extension'"
     ]
    }
   ],
   "source": [
    "from fastcore.all import *\n",
    "import sys\n",
    "sys.path.append(\"..\")\n",
    "import wandb\n",
    "from fastcore import test\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from timecluster_extension.load import *\n",
    "from timecluster_extension.dr import *\n",
    "from timecluster_extension.visualization import *\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "import wandb\n",
    "from wandb.keras import WandbCallback\n",
    "from yaml import load, FullLoader\n",
    "from fastcore.utils import Path\n",
    "from datetime import datetime\n",
    "import pickle\n",
    "import matplotlib.pyplot as plt\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Comparison between datasets\n",
    "\n",
    "> This notebook tries to show the statistical differences between datasets used during training, validation and testing of models in this project.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load a wandb run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "run_wandb = wandb.init(entity = \"pacmel\",\n",
    "                      project=\"timecluster-extension\",\n",
    "                      job_type='train_DCAE',\n",
    "                      allow_val_change=True,\n",
    "                      resume=False)\n",
    "config = wandb.config "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load artifacts:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "artifact_train = 'JNK:train_18days'\n",
    "artifact_validation = 'JNK:validation_2days'\n",
    "artifact_test = 'JNK:test_2days'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get data as artifact\n",
    "ds_train_artifact = run_wandb.use_artifact(artifact_train)\n",
    "ds_validation_artifact = run_wandb.use_artifact(artifact_validation)\n",
    "ds_test_artifact = run_wandb.use_artifact(artifact_test)\n",
    "# Get data as Pandas Dataframe\n",
    "df_train = ds_train_artifact.to_df()\n",
    "df_validation = ds_validation_artifact.to_df()\n",
    "df_test = ds_test_artifact.to_df()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Code taken from \n",
    "def show_heatmap(data, plot_title, figsize=(5,5)):\n",
    "    \"Function to plot correlation between variables. Code taken from \\\n",
    "     https://keras.io/examples/timeseries/timeseries_weather_forecasting\"\n",
    "    plt.figure(figsize=(figsize[0],figsize[1]))\n",
    "    plt.matshow(data.corr(), fignum=1)\n",
    "    plt.xticks(range(data.shape[1]), data.columns, fontsize=14, rotation=90)\n",
    "    plt.gca().xaxis.tick_bottom()\n",
    "    plt.yticks(range(data.shape[1]), data.columns, fontsize=14)\n",
    "\n",
    "    cb = plt.colorbar()\n",
    "    cb.ax.tick_params(labelsize=14)\n",
    "    plt.title(plot_title, fontsize=14)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Correlation between variables of dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_heatmap(df_train, plot_title = \"Train dataset\", figsize=(7,7))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_heatmap(df_validation, plot_title = \"Validation dataset\", figsize=(7,7))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_heatmap(df_test, plot_title = \"Test dataset\", figsize=(7,7))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import kruskal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kruskal(df_test[\"RCD_BearingTemperature\"],df_validation[\"RCD_BearingTemperature\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "sns.distplot( df_test[\"RCD_BearingTemperature\"] , color=\"red\", label=\"Sepal Width\")\n",
    "sns.plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.distplot( df_validation[\"RCD_BearingTemperature\"] , color=\"skyblue\", label=\"Sepal Length\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Mean and std of non-normalized artifacts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_validation_artifact = ds_validation_artifact.to_df()\n",
    "df_test_artifact= ds_test_artifact.to_df()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_TS(df_validation_artifact,figsize=(25,25))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_TS(df_test_artifact,figsize=(25,25))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stats_test = df_test_artifact.agg([np.mean, np.std]).T\n",
    "stats_validation = df_validation_artifact.agg([np.mean, np.std]).T\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stats_validation.plot(kind = \"barh\", y = \"mean\", legend = False,  \n",
    "          xerr = \"std\", title = \"plot\", color='green')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ax = stats_validation.plot(kind = \"barh\", y = \"mean\", legend = False,  \n",
    "          xerr = \"std\", title = \"plot\", color='green')\n",
    "stats_test.plot(ax=ax,kind = \"barh\", y = \"mean\", legend = False,  \n",
    "          xerr = \"std\", title = \"plot\", color='red' )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure()\n",
    "\n",
    "for frame in [stats_validation, newdf2, newdf3, newdf4, newdf5]:\n",
    "    plt.plot(frame['Time'], frame['Data'])\n",
    "\n",
    "plt.xlim(0,18000)\n",
    "plt.ylim(0,30)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Transform to pandas dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train_artifact = ds_train_artifact.to_df()\n",
    "df_validation_artifact_norm = normalize_artifact(ds_validation_artifact, ds_train_artifact)\n",
    "df_test_artifact_norm = normalize_artifact(ds_test_artifact, ds_train_artifact)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stats_train = df_train_artifact.agg([np.mean, np.std]).T\n",
    "stats_validation_norm = df_validation_artifact_norm.agg([np.mean, np.std]).T\n",
    "stats_test_norm = df_test_artifact_norm.agg([np.mean, np.std]).T\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stats_validation.plot()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
