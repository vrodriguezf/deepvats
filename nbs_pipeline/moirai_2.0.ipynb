{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d8d7374a-16c4-409e-961d-02c667ac53f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "verbose                       = None\n",
    "check_memory_usage            = None\n",
    "time_flag                     = None\n",
    "window_size_percentage        = None\n",
    "show_plots                    = None\n",
    "reset_kernel                  = None\n",
    "pre_configured_case           = None\n",
    "case_id                       = None\n",
    "frequency_factor              = None\n",
    "frequency_factor_change_alias = None\n",
    "check_parameters              = True\n",
    "cuda_device                   = None\n",
    "remove_lambdas_flag           = True"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f5ade51-58bf-4cd2-aff6-7ad3be23a4e4",
   "metadata": {},
   "source": [
    "# Explained pre-trained module trial"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2e9ee0f-7af4-4f38-b5de-bffad59c31c1",
   "metadata": {},
   "source": [
    "## Instalation commands"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13ae19aa-e2b9-4353-916a-0a8f3297e0c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#! git clone https://github.com/SalesforceAIResearch/uni2ts.git\n",
    "#! cd uni2ts\n",
    "#! pip install -e '.[notebook]' --no-warn-script-location\n",
    "#! conda install anaconda::gluonts"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e226f16-49d0-454e-9add-8c4752b08623",
   "metadata": {},
   "source": [
    "## Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1c45abc3-18ca-4751-8d44-09ab90e0c547",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from gluonts.dataset.pandas import PandasDataset\n",
    "from gluonts.dataset.split import split\n",
    "from huggingface_hub import hf_hub_download\n",
    "\n",
    "from uni2ts.eval_util.plot import plot_single\n",
    "from uni2ts.model.moirai import MoiraiForecast, MoiraiModule"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "526d39ba-6822-4e44-a3cb-349cbe2c2bea",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<frozen importlib._bootstrap>:241: RuntimeWarning: pyarrow.lib.IpcWriteOptions size changed, may indicate binary incompatibility. Expected 72 from C header, got 88 from PyObject\n",
      "<frozen importlib._bootstrap>:241: RuntimeWarning: pyarrow.lib.IpcReadOptions size changed, may indicate binary incompatibility. Expected 96 from C header, got 104 from PyObject\n",
      "<frozen importlib._bootstrap>:241: RuntimeWarning: pyarrow.lib.Tensor size changed, may indicate binary incompatibility. Expected 64 from C header, got 80 from PyObject\n",
      "<frozen importlib._bootstrap>:241: RuntimeWarning: pyarrow.lib.NativeFile size changed, may indicate binary incompatibility. Expected 96 from C header, got 104 from PyObject\n",
      "<frozen importlib._bootstrap>:241: RuntimeWarning: pyarrow.lib.BufferedInputStream size changed, may indicate binary incompatibility. Expected 96 from C header, got 104 from PyObject\n",
      "<frozen importlib._bootstrap>:241: RuntimeWarning: pyarrow.lib.BufferedOutputStream size changed, may indicate binary incompatibility. Expected 96 from C header, got 104 from PyObject\n",
      "<frozen importlib._bootstrap>:241: RuntimeWarning: pyarrow.lib.CompressedInputStream size changed, may indicate binary incompatibility. Expected 96 from C header, got 104 from PyObject\n",
      "<frozen importlib._bootstrap>:241: RuntimeWarning: pyarrow.lib.CompressedOutputStream size changed, may indicate binary incompatibility. Expected 96 from C header, got 104 from PyObject\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[?2004l\n",
      "Octave is ready <oct2py.core.Oct2Py object at 0x7f01575145e0>\n",
      "\u001b[?2004l\n",
      "\u001b[?2004l\n",
      "\u001b[?2004l\n",
      "\u001b[?2004l\n",
      "\u001b[?2004l\n",
      "\u001b[?2004l\n",
      "\u001b[?2004l\n",
      "\u001b[?2004l\n",
      "\u001b[?2004l\n",
      "\u001b[?2004l\n",
      "\u001b[?2004l\n",
      "\u001b[?2004l\n",
      "\u001b[?2004l\n",
      "\u001b[?2004l\n",
      "\u001b[?2004l\n"
     ]
    }
   ],
   "source": [
    "from dvats.all import *"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40ee47ab-44b4-421f-97ec-0d52606a668f",
   "metadata": {},
   "source": [
    "## Utilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8e784320-0d41-4087-acc9-887d9b58f34a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "# This is only needed if the notebook is run in VSCode\n",
    "import sys\n",
    "import dvats.utils as ut\n",
    "if '--vscode' in sys.argv:\n",
    "    print(\"Executing inside vscode\")\n",
    "    ut.DisplayHandle.update = ut.update_patch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9f1aeccd-4a3a-4707-b110-0af5215aa0d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import importlib\n",
    "def remove_lambdas(verbose = 0):\n",
    "    path = \"./uni2ts/src/uni2ts/distribution/mixture.py\"\n",
    "    if verbose > 0: print(f\"remove_lambdas | read file {path}\")\n",
    "    # Read the file\n",
    "    with open(path, 'r') as file:\n",
    "        lines = file.readlines()\n",
    "    # Check wether identity is defined or not\n",
    "    identity_defined = any(\"def identity(\" in line for line in lines)\n",
    "    if verbose > 0: print(f\"remove_lambdas | identity already defined? {identity_defined}\")\n",
    "    if not identity_defined: \n",
    "        if verbose > 0: print(\"remove_lambdas | Look for domain_map line\")\n",
    "        for i, line in enumerate(lines):\n",
    "            if \"@property\" in line and \"def domain_map\" in lines[i+1]:                \n",
    "                domain_map_property_index = i\n",
    "                break\n",
    "        if verbose > 0: print(f\"remove_lambdas | Domain map in line {i}\")\n",
    "        # Insert identity function\n",
    "        identity_code = \"\"\"\n",
    "    def identity(self, x): \n",
    "        return x\n",
    "\n",
    "\"\"\"\n",
    "        lines.insert(domain_map_property_index, identity_code)\n",
    "        # Modify weights_logits line \n",
    "        inside_domain_map = False\n",
    "        for i in range(domain_map_property_index, len(lines)):\n",
    "            if \"weights_logits\" in lines[i]:\n",
    "                # Reemplazar la línea para que use identity\n",
    "                lines[i] = \"            weights_logits = self.identity,\\n\"\n",
    "                break\n",
    "        # Write changes \n",
    "        with open(path, 'w') as file:\n",
    "            file.writelines(lines)\n",
    "        importlib.reload(uni2ts)\n",
    "    else:\n",
    "        if identity_defined:\n",
    "            print(\"Identity already defined\")    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fcfc741c-dbc7-4b46-bf88-8f233637bdab",
   "metadata": {},
   "source": [
    "### Ensure model is pickable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7c481684-65d6-4874-ae70-1df191cd0d94",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "remove_lambdas | read file ./uni2ts/src/uni2ts/distribution/mixture.py\n",
      "remove_lambdas | identity already defined? True\n",
      "Identity already defined\n"
     ]
    }
   ],
   "source": [
    "if remove_lambdas_flag: remove_lambdas(verbose = 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb1b2f45-e08d-4255-81ef-a4221e7bcb9e",
   "metadata": {},
   "source": [
    "## Load dataset artifact"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "acf546f4-be65-4642-837c-a122ca2b17cc",
   "metadata": {},
   "source": [
    "### Check input parameters & set up default parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "93180bf5-e123-48d7-ae6b-84b1852b4f59",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "verbose                       = True  if verbose is None else verbose\n",
    "check_memory_usage            = True  if check_memory_usage is None else check_memory_usage\n",
    "time_flag                     = True  if time_flag is None else time_flag\n",
    "window_size_percentage        = False if window_size_percentage is None else window_size_percentage\n",
    "show_plots                    = True if show_plots is None else show_plots\n",
    "reset_kernel                  = False  if reset_kernel is None else reset_kernel\n",
    "pre_configured_case           = True if pre_configured_case is None else pre_configured_case\n",
    "case_id                       = 7 if case_id is None else case_id\n",
    "frequency_factor              = 1 if frequency_factor is None else frequency_factor\n",
    "frequency_factor_change_alias = True if frequency_factor_change_alias is None else frequency_factor_change_alias\n",
    "cuda_device                   = 1 if  cuda_device is None else cuda_device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3c3f41eb-ee0a-4a85-8fdb-20ea22d30416",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Check parameters ---\n",
      "verbose: True check_memory_usage True time_flag: True window_size_percentage: False show_plots: True reset_kernel: False pre_configured_case: True case_id: 7 frequency_factor: 1 frequency_factor_change_alias True cuda_device 1\n"
     ]
    }
   ],
   "source": [
    "if check_parameters:\n",
    "    print(\"--- Check parameters ---\")\n",
    "    print(\n",
    "        \"verbose:\", verbose,\n",
    "        \"check_memory_usage\", check_memory_usage,\n",
    "        \"time_flag:\", time_flag,\n",
    "        \"window_size_percentage:\" , window_size_percentage,\n",
    "        \"show_plots:\",show_plots,\n",
    "        \"reset_kernel:\",reset_kernel,\n",
    "        \"pre_configured_case:\",pre_configured_case,\n",
    "        \"case_id:\",case_id,\n",
    "        \"frequency_factor:\", frequency_factor, \n",
    "        \"frequency_factor_change_alias\", frequency_factor_change_alias,\n",
    "        \"cuda_device\", cuda_device\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f64138b8-e2c0-4ed3-ba9c-3b9a0e48675d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "import dvats.config as cfg_\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", module=\"umap\")\n",
    "import os\n",
    "import sys\n",
    "sys.path.append(os.path.abspath('..'))\n",
    "from dvats.all import *\n",
    "from fastcore.all import *\n",
    "from tsai.basics import *\n",
    "from tsai.models.InceptionTimePlus import *\n",
    "from tsai.callback.MVP import *\n",
    "import matplotlib.colors as colors\n",
    "from fastai.callback.wandb import WandbCallback\n",
    "from fastai.callback.progress import ShowGraphCallback\n",
    "from fastai.callback.schedule import *\n",
    "from fastai.callback.tracker import EarlyStoppingCallback\n",
    "import wandb\n",
    "\n",
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from gluonts.dataset.pandas import PandasDataset\n",
    "from gluonts.dataset.split import split\n",
    "from huggingface_hub import hf_hub_download\n",
    "\n",
    "from uni2ts.eval_util.plot import plot_single\n",
    "from uni2ts.model.moirai import MoiraiForecast, MoiraiModule\n",
    "from uni2ts.eval_util.plot import plot_next_multi\n",
    "import pyarrow.feather as ft"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "60ad4604-0887-4345-b075-c54e7b5a69d6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m WANDB_NOTEBOOK_NAME should be a path to a notebook file, couldn't find /home/macu/work/nbs_pipeline/moirai_trial.ipynb.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU | Used mem: 7\n",
      "GPU | Used mem: 24\n",
      "GPU | Memory Usage: [\u001b[94m█████---------------\u001b[0m] \u001b[94m29%\u001b[0m\n",
      "valid_size: 0.2\u001b[0m\n",
      "\u001b[94mtrain_artifact: mi-santamaria/deepvats/PulsusParadoxus-SP02:latest\u001b[0m -> mi-santamaria/deepvats/toy:latest\u001b[0m\n",
      "\u001b[94malias: PulsusParadoxus-SP02\u001b[0m -> toy\u001b[0m\n",
      "use_wandb: True\u001b[0m\n",
      "r: 0.71\u001b[0m\n",
      "mask_future: False\u001b[0m\n",
      "valid_artifact: None\u001b[0m\n",
      "\u001b[94mbatch_size: 512\u001b[0m -> 32\u001b[0m\n",
      "\u001b[93m\u001b[1mdata_fpath is missing in original dict | ~/data/toy.csv \u001b[0m\n",
      "\u001b[93m\u001b[1mdata_cols is missing in original dict | [] \u001b[0m\n",
      "\u001b[94mw: 100\u001b[0m -> 30\u001b[0m\n",
      "analysis_mode: online\u001b[0m\n",
      "\u001b[94mstride: 900\u001b[0m -> 1\u001b[0m\n",
      "\u001b[94mmvp_ws: (15, 100)\u001b[0m -> [10, 30]\u001b[0m\n",
      "\u001b[93m\u001b[1mnorm_use_by_single_batch is missing in original dict | (False,) \u001b[0m\n",
      "mask_stateful: True\u001b[0m\n",
      "wandb_group: None\u001b[0m\n",
      "epochs: 100\u001b[0m\n",
      "mask_sync: False\u001b[0m\n",
      "\u001b[93m\u001b[1mtime_col is missing in original dict | None \u001b[0m\n",
      "norm_by_sample: False\u001b[0m\n",
      "\u001b[93m\u001b[1mfreq is missing in original dict | 1s \u001b[0m\n",
      "\u001b[93m\u001b[1martifact_name is missing in original dict | toy \u001b[0m\n",
      "norm_use_single_batch: False\u001b[0m\n",
      "\u001b[93m\u001b[1mcsv_config is missing in original dict | {} \u001b[0m\n",
      "runname: moirai_trial\n",
      "alias: toy\n",
      "analysis_mode: online\n",
      "batch_size: 32\n",
      "epochs: 100\n",
      "mask_future: False\n",
      "mask_stateful: True\n",
      "mask_sync: False\n",
      "mvp_ws: [10, 30]\n",
      "norm_by_sample: False\n",
      "norm_use_single_batch: False\n",
      "r: 0.71\n",
      "stride: 1\n",
      "train_artifact: mi-santamaria/deepvats/toy:latest\n",
      "valid_artifact: None\n",
      "use_wandb: True\n",
      "valid_size: 0.2\n",
      "w: 30\n",
      "wandb_group: None\n",
      "artifact_name: toy\n",
      "data_cols: []\n",
      "data_fpath: ~/data/toy.csv\n",
      "freq: 1s\n",
      "time_col: None\n",
      "csv_config: {}\n",
      "norm_use_by_single_batch: (False,)\n",
      "--> Wandb init\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mmi-santamaria\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.18.1 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.14.2"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/home/macu/work/wandb/run-20240927_093857-8nuql3kx</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/mi-santamaria/deepvats/runs/8nuql3kx' target=\"_blank\">moirai_trial</a></strong> to <a href='https://wandb.ai/mi-santamaria/deepvats' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/mi-santamaria/deepvats' target=\"_blank\">https://wandb.ai/mi-santamaria/deepvats</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/mi-santamaria/deepvats/runs/8nuql3kx' target=\"_blank\">https://wandb.ai/mi-santamaria/deepvats/runs/8nuql3kx</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wandb init -->\n",
      "alias: toy\n",
      "analysis_mode: online\n",
      "batch_size: 32\n",
      "epochs: 100\n",
      "mask_future: False\n",
      "mask_stateful: True\n",
      "mask_sync: False\n",
      "mvp_ws: [10, 30]\n",
      "norm_by_sample: False\n",
      "norm_use_single_batch: False\n",
      "r: 0.71\n",
      "stride: 1\n",
      "train_artifact: mi-santamaria/deepvats/toy:latest\n",
      "valid_artifact: None\n",
      "use_wandb: True\n",
      "valid_size: 0.2\n",
      "w: 30\n",
      "wandb_group: None\n",
      "artifact_name: toy\n",
      "data_cols: []\n",
      "data_fpath: ~/data/toy.csv\n",
      "freq: 1s\n",
      "time_col: None\n",
      "csv_config: {}\n",
      "norm_use_by_single_batch: [False]\n",
      "---> W&B Train Artifact\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m:   1 of 1 files downloaded.  \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(550, 3)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#| export\n",
    "wandb_api = wandb.Api()\n",
    "device = torch.device(f'cuda:{cuda_device}' if torch.cuda.is_available() else 'cpu')\n",
    "torch.cuda.set_device(device)\n",
    "if check_memory_usage:\n",
    "    gpu_device = torch.cuda.current_device()\n",
    "    gpu_memory_status(gpu_device)\n",
    "user, project, version, data, config, job_type = cfg_.get_artifact_config_MVP(False)\n",
    "if pre_configured_case: \n",
    "    cfg_.force_artifact_config_mvp(\n",
    "        config = config,\n",
    "        id = case_id,\n",
    "        verbose = verbose, \n",
    "        both = verbose > 0,\n",
    "        frequency_factor = frequency_factor,\n",
    "        frequency_factor_change_alias = frequency_factor_change_alias\n",
    "    )\n",
    "path = os.path.expanduser(\"~/work/nbs_pipeline/\")\n",
    "name=\"moirai_trial\"\n",
    "os.environ[\"WANDB_NOTEBOOK_NAME\"] = path+name+\".ipynb\"\n",
    "runname=name\n",
    "if verbose > 0: print(\"runname: \"+runname)\n",
    "if verbose > 0: cfg_.show_attrdict(config)\n",
    "\n",
    "if verbose > 0: print(\"--> Wandb init\")\n",
    "run = wandb.init(\n",
    "    entity = user,\n",
    "    # work-nbs is a place to log draft runs\n",
    "    project=project,\n",
    "    group=config.wandb_group,\n",
    "    job_type=job_type,\n",
    "    allow_val_change=True,\n",
    "    mode=config.analysis_mode,\n",
    "    config=config,\n",
    "    # When use_wandb is false the run is not linked to a personal account\n",
    "    #NOTE: This is not working right now\n",
    "    anonymous = 'never' if config.use_wandb else 'must', \n",
    "    resume=False,\n",
    "    name = runname\n",
    ")\n",
    "if verbose > 0: print(\"Wandb init -->\")\n",
    "config = run.config  # Object for storing hyperparameters\n",
    "artifacts_gettr = run.use_artifact if config.use_wandb else wandb_api.artifact\n",
    "config = run.config  # Object for storing hyperparameters\n",
    "if verbose > 0: cfg_.show_attrdict(config)\n",
    "artifacts_gettr = run.use_artifact if config.use_wandb else wandb_api.artifact\n",
    "train_artifact = artifacts_gettr(config.train_artifact)\n",
    "if verbose > 0: print(\"---> W&B Train Artifact\")\n",
    "df_train = train_artifact.to_df()\n",
    "df_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a74030b0-7661-42dd-868c-ad57cd98bed1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>T3</th>\n",
       "      <th>T2</th>\n",
       "      <th>T1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1970-01-01 00:00:00</th>\n",
       "      <td>0.741822</td>\n",
       "      <td>0.637180</td>\n",
       "      <td>0.565117</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1970-01-01 00:00:01</th>\n",
       "      <td>0.739731</td>\n",
       "      <td>0.629415</td>\n",
       "      <td>0.493513</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1970-01-01 00:00:02</th>\n",
       "      <td>0.718757</td>\n",
       "      <td>0.539220</td>\n",
       "      <td>0.469350</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1970-01-01 00:00:03</th>\n",
       "      <td>0.730169</td>\n",
       "      <td>0.577670</td>\n",
       "      <td>0.444100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1970-01-01 00:00:04</th>\n",
       "      <td>0.752406</td>\n",
       "      <td>0.570180</td>\n",
       "      <td>0.373008</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                           T3        T2        T1\n",
       "1970-01-01 00:00:00  0.741822  0.637180  0.565117\n",
       "1970-01-01 00:00:01  0.739731  0.629415  0.493513\n",
       "1970-01-01 00:00:02  0.718757  0.539220  0.469350\n",
       "1970-01-01 00:00:03  0.730169  0.577670  0.444100\n",
       "1970-01-01 00:00:04  0.752406  0.570180  0.373008"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(df_train.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d0f8b29-38a6-4658-81c8-b9ac4d8322a2",
   "metadata": {},
   "source": [
    "### Sliding windows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "94aadad1-8c27-4a6a-b398-6c070db00a36",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---> Sliding window |  30  |  1\n",
      " Sliding window |  30  |  1 ---> | df_train ~  (550, 3)\n",
      " sw_df_train |  30  |  1 --->\n"
     ]
    }
   ],
   "source": [
    "#| export\n",
    "if verbose > 0: print(\"---> Sliding window | \", config.w,  \" | \", config.stride )\n",
    "sw = SlidingWindow(window_len=config.w, stride=config.stride, get_y=[])\n",
    "if verbose > 0: print(\" Sliding window | \", config.w,  \" | \", config.stride, \"---> | df_train ~ \", df_train.shape )\n",
    "X_train, _ = sw(df_train)\n",
    "if verbose > 0: print(\" sw_df_train | \", config.w,  \" | \", config.stride, \"--->\" )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "3e0bb9a4-a0f0-4896-9d1b-3b2fb04323bb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(521, 3, 30)\n"
     ]
    }
   ],
   "source": [
    "#| hide\n",
    "if verbose > 0: \n",
    "    print(X_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "ff7d914c-f9a8-4dc5-9707-f7b309615ba6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "len(X):  521\n",
      "--> Split 1\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1600x50 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Split --> 417\n"
     ]
    }
   ],
   "source": [
    "#| export\n",
    "assert config.analysis_mode in ['offline','online'], 'Invalid analysis mode'\n",
    "\n",
    "X = X_train\n",
    "if verbose > 0: print(\"len(X): \", len(X));\n",
    "if config.analysis_mode == 'online':\n",
    "    if verbose > 0: print(\"--> Split 1\")\n",
    "    splits = TimeSplitter(valid_size=0.2, show_plot=show_plots)(X)\n",
    "elif config.analysis_mode == 'offline':\n",
    "    if verbose > 0: print(\"--> Split 2\")\n",
    "    splits = get_splits(np.arange(len(X)), valid_size=config.valid_size, show_plot = show_plots)\n",
    "if verbose > 0: \n",
    "    print(\"Split -->\", len(splits[0]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "072b6522-bcaa-46ae-bf32-31f31dae4bf6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(521, 3, 30)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "((#417) [0,1,2,3,4,5,6,7,8,9...],\n",
       " (#104) [417,418,419,420,421,422,423,424,425,426...])"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#| hide\n",
    "if verbose > 0: \n",
    "    print(X.shape)\n",
    "    display(splits)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1183ff9a-fb49-4381-9125-dc08b36aa7ab",
   "metadata": {},
   "source": [
    "## Load & get embeddings from moirai module"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "e1b6b2be-a055-4618-ab99-7d171b5834ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_variate_id(\n",
    "    batch_size, \n",
    "    seq_len, \n",
    "    num_variates\n",
    "):\n",
    "    # Crear un tensor de variate_id con tamaño (batch_size, seq_len, num_variates)\n",
    "    variate_id = torch.arange(num_variates).unsqueeze(0).unsqueeze(0).repeat(batch_size, seq_len, 1)\n",
    "    return variate_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "1176e835-f851-4e03-af55-73bdb2b9d211",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size, num_variates, seq_len = X.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39243d9a-d4e0-4d59-9423-d3ddf2eb46bc",
   "metadata": {},
   "source": [
    "Aquí tendremos que seleccionar cualquiera de los modelos preentrenados en Moirai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1231eef3-f10d-41ee-9c60-439bed9a92c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_size = 'small'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9bcbdbc-8459-43c6-8437-b0866e20f546",
   "metadata": {},
   "source": [
    "Nuestro X tiene tamaño \n",
    "num_ventanas x num_variables x tamaño_ventana\n",
    "\n",
    "El target que recibe Moirai tiene tamaño \n",
    "num_ventanas x tamaño_ventana x num_variables\n",
    "\n",
    "Permutamos para ajustar la entrada correctamente"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "042b0780-5775-4c84-9ee6-003c4b32f905",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([521, 30, 3])"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create target ~ ( batch , seq_length , max_patch )\n",
    "target = torch.randn(batch_size, seq_len, num_variates)\n",
    "target.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "952c780d-4e43-42ca-a09a-8507d641a145",
   "metadata": {},
   "source": [
    "Como todos los valores son observados, hacemos que el observed mask esté a 1\n",
    "Como el tamaño es el mismo que el del target, usamos torch.ones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "b505aa02-7677-4296-99f8-c535102eb0cf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([521, 30, 3])"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# observed_mask ~ (batch , seq_len , max_patch )\n",
    "observed_mask = torch.ones(target.shape)\n",
    "observed_mask.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9bd2d50-9e2c-4788-bf6a-03725ba2af85",
   "metadata": {},
   "source": [
    "MoiraiModule necesita un id para cada muestra\n",
    "Creamos un índice numérico para cada sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "6b0c670d-86bf-47c9-a46a-d8393de42c8f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([521, 30])"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# sample ~ ( batch, seq_len )\n",
    "sample_id = torch.arange(batch_size).unsqueeze(1).repeat(1, seq_len)\n",
    "sample_id.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "9e032adb-b6fd-4f7e-b520-b4ed7c207f64",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[0, 1, 2]]])\n"
     ]
    }
   ],
   "source": [
    "variate_ids = torch.arange(num_variates).unsqueeze(0).unsqueeze(0) \n",
    "print(variate_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "f3660299-5436-40ed-940a-f4ee34b5d698",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([521, 30, 3])\n",
      "tensor([0, 1, 2])\n"
     ]
    }
   ],
   "source": [
    "variate_id_tensor = variate_ids.repeat(batch_size, seq_len, 1)\n",
    "print(variate_id_tensor.shape)\n",
    "print(variate_id_tensor[0][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "14a6f5f8-a37f-4dbb-8267-615ba35204c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "variate_id_tensor = variate_id_tensor.permute(0, 2, 1).reshape(batch_size, seq_len * num_variates)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "4e705369-e10a-472b-8bd4-be575c8093f3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([521, 90])"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "variate_id_tensor.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34bd0e93-44ae-419d-9a10-e79f6157c14b",
   "metadata": {},
   "source": [
    "También necesita un índice de tiempo (que no es el propio timestamp porque tiene que ser numérico)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "479ba6af-2f6b-4536-9850-2456794046fa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,\n",
      "        18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29])\n",
      "tensor([[ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,\n",
      "         18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29]])\n",
      "tensor([[ 0,  1,  2,  ..., 27, 28, 29],\n",
      "        [ 0,  1,  2,  ..., 27, 28, 29],\n",
      "        [ 0,  1,  2,  ..., 27, 28, 29],\n",
      "        ...,\n",
      "        [ 0,  1,  2,  ..., 27, 28, 29],\n",
      "        [ 0,  1,  2,  ..., 27, 28, 29],\n",
      "        [ 0,  1,  2,  ..., 27, 28, 29]])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "torch.Size([521, 30])"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# time_id ~ ( batch , seq_len )\n",
    "time_id = torch.arange(seq_len) # [0 .. seq_len-1 ]]\n",
    "print(time_id) \n",
    "time_id = time_id.unsqueeze(0) # [[0..seq_len -1]]\n",
    "print(time_id)\n",
    "time_id = time_id.repeat(batch_size, 1) # [[ 0 .. seq_len-1 ] , ..., [0, .., seq_len-1]]\n",
    "print(time_id)\n",
    "time_id.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "50e2f6e4-1280-49b4-bf7c-241fecbe5a90",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([521, 30, 3])"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# variate = feature = channel\n",
    "# Indices for the variates\n",
    "# variate_id ~ (batch x seq_len ) \n",
    "variate_id = torch.arange(num_variates).unsqueeze(0).unsqueeze(0).repeat(batch_size, seq_len, 1)\n",
    "variate_id.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "91bdaedc-9428-4fc7-99cd-0449eec6fe3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "variate_id = None # batch x seq_len\n",
    "prediction_mask = None # batch x seq_len \n",
    "# Tamaño de cada patch\n",
    "patch_size = None # batch x seq_len "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18267cff-c410-457b-9f2d-c682f75dd4eb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "972f3fa1-0026-43a2-9183-b6124389336b",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "variate_id = create_variate_id (\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "72f79920-4db2-4d39-9337-243f18e9a82f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get pre-trained module\n",
    "module = MoiraiModule.from_pretrained(f\"Salesforce/moirai-1.0-R-{model_size}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f94eb14-01a3-488c-8a0d-b3189ebd55f9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b841aa7c-9142-4e32-8cf0-598b44338810",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d0eefee-5ab9-47e3-9510-3518b4172bbd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d6e023f-c079-4bae-aaab-00a73708c801",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "239a6061-d58e-4164-94a0-c3785f87f534",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "ffa44f14-3a37-4d84-9997-a573aa44d183",
   "metadata": {},
   "source": [
    "#### Segundo intento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "51b8d722-f089-44ba-85fe-7c53aded39c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size, num_variates, seq_len  = X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "098f2289-01c0-40d5-8a66-cd2a8dfc0981",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([521, 30, 3])"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target = torch.from_numpy(X).permute(0, 2, 1)\n",
    "target.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "47a76d61-8cca-4e73-ba63-08a83ce7c688",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([521, 30, 3])"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "observed_mask = torch.ones(batch_size, seq_len, num_variates, dtype=torch.bool)\n",
    "observed_mask.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "406866c6-c8e1-425b-9a85-30e1a5004930",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([521, 30])"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_id = torch.arange(seq_len).unsqueeze(0).repeat(batch_size, 1)\n",
    "sample_id.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "9e851c1a-094c-4959-8ec4-8e7f491551e2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([521, 30])"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "time_id = torch.arange(seq_len).unsqueeze(0).repeat(batch_size, 1)\n",
    "time_id.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "ee3fe70a-58cf-423c-917e-3223956e5fc7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([521, 30, 3])"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "variate_ids = torch.arange(num_variates).unsqueeze(0).repeat(batch_size, seq_len, 1)\n",
    "variate_ids.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2f50d66-8149-4180-a381-75046ee6596e",
   "metadata": {},
   "source": [
    "sé que tiene sentido, porque además dicen que aplanan las variables en la primera capa del modelo, pero esque en todas partes de la documentación indican batch x seq_len"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "27eb7a0c-0dbb-42d5-a589-7c5ef53f9b5d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([521, 90])"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "variate_id = variate_ids.permute(0, 2, 1).reshape(batch_size, seq_len * num_variates)\n",
    "variate_id.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "61ee3887-934e-479e-b1c9-5e1ba38b5541",
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction_mask = torch.ones(batch_size, seq_len, dtype=torch.bool)\n",
    "patch_size_tensor = torch.full((batch_size, seq_len), patch_size, dtype=torch.int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "c7763490-c011-4d9b-80bb-f6397c648576",
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "The size of tensor a (30) must match the size of tensor b (90) at non-singleton dimension 2",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[99], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m output \u001b[38;5;241m=\u001b[39m \u001b[43mmodule\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mforward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m      2\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtarget\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtarget\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      3\u001b[0m \u001b[43m    \u001b[49m\u001b[43mobserved_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mobserved_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      4\u001b[0m \u001b[43m    \u001b[49m\u001b[43msample_id\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msample_id\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      5\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtime_id\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtime_id\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      6\u001b[0m \u001b[43m    \u001b[49m\u001b[43mvariate_id\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mvariate_id\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      7\u001b[0m \u001b[43m    \u001b[49m\u001b[43mprediction_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mprediction_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      8\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpatch_size_tensor\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      9\u001b[0m \u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/work/nbs_pipeline/uni2ts/src/uni2ts/model/moirai/module.py:161\u001b[0m, in \u001b[0;36mMoiraiModule.forward\u001b[0;34m(self, target, observed_mask, sample_id, time_id, variate_id, prediction_mask, patch_size)\u001b[0m\n\u001b[1;32m    131\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\n\u001b[1;32m    132\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m    133\u001b[0m     target: Float[torch\u001b[38;5;241m.\u001b[39mTensor, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m*batch seq_len max_patch\u001b[39m\u001b[38;5;124m\"\u001b[39m],\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    139\u001b[0m     patch_size: Int[torch\u001b[38;5;241m.\u001b[39mTensor, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m*batch seq_len\u001b[39m\u001b[38;5;124m\"\u001b[39m],\n\u001b[1;32m    140\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Distribution:\n\u001b[1;32m    141\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    142\u001b[0m \u001b[38;5;124;03m    Defines the forward pass of MoiraiModule.\u001b[39;00m\n\u001b[1;32m    143\u001b[0m \u001b[38;5;124;03m    This method expects processed inputs.\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    159\u001b[0m \u001b[38;5;124;03m    :return: predictive distribution\u001b[39;00m\n\u001b[1;32m    160\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 161\u001b[0m     loc, scale \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mscaler\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    162\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtarget\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    163\u001b[0m \u001b[43m        \u001b[49m\u001b[43mobserved_mask\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m~\u001b[39;49m\u001b[43mprediction_mask\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43munsqueeze\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    164\u001b[0m \u001b[43m        \u001b[49m\u001b[43msample_id\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    165\u001b[0m \u001b[43m        \u001b[49m\u001b[43mvariate_id\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    166\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    167\u001b[0m     scaled_target \u001b[38;5;241m=\u001b[39m (target \u001b[38;5;241m-\u001b[39m loc) \u001b[38;5;241m/\u001b[39m scale\n\u001b[1;32m    168\u001b[0m     reprs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39min_proj(scaled_target, patch_size)\n",
      "File \u001b[0;32m/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/torch/nn/modules/module.py:1553\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1551\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1552\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1553\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/torch/nn/modules/module.py:1562\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1557\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1558\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1559\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1560\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1561\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1562\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1564\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1565\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/work/nbs_pipeline/uni2ts/src/uni2ts/module/packed_scaler.py:45\u001b[0m, in \u001b[0;36mPackedScaler.forward\u001b[0;34m(self, target, observed_mask, sample_id, variate_id)\u001b[0m\n\u001b[1;32m     40\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m variate_id \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m     41\u001b[0m     variate_id \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mzeros(\n\u001b[1;32m     42\u001b[0m         target\u001b[38;5;241m.\u001b[39mshape[:\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m], dtype\u001b[38;5;241m=\u001b[39mtorch\u001b[38;5;241m.\u001b[39mlong, device\u001b[38;5;241m=\u001b[39mtarget\u001b[38;5;241m.\u001b[39mdevice\n\u001b[1;32m     43\u001b[0m     )\n\u001b[0;32m---> 45\u001b[0m loc, scale \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_loc_scale\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     46\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtarget\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdouble\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mobserved_mask\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msample_id\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvariate_id\u001b[49m\n\u001b[1;32m     47\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     48\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m loc\u001b[38;5;241m.\u001b[39mfloat(), scale\u001b[38;5;241m.\u001b[39mfloat()\n",
      "File \u001b[0;32m~/work/nbs_pipeline/uni2ts/src/uni2ts/module/packed_scaler.py:93\u001b[0m, in \u001b[0;36mPackedStdScaler._get_loc_scale\u001b[0;34m(self, target, observed_mask, sample_id, variate_id)\u001b[0m\n\u001b[1;32m     84\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_get_loc_scale\u001b[39m(\n\u001b[1;32m     85\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m     86\u001b[0m     target: Float[torch\u001b[38;5;241m.\u001b[39mTensor, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m*batch seq_len #dim\u001b[39m\u001b[38;5;124m\"\u001b[39m],\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     91\u001b[0m     Float[torch\u001b[38;5;241m.\u001b[39mTensor, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m*batch 1 #dim\u001b[39m\u001b[38;5;124m\"\u001b[39m], Float[torch\u001b[38;5;241m.\u001b[39mTensor, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m*batch 1 #dim\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[1;32m     92\u001b[0m ]:\n\u001b[0;32m---> 93\u001b[0m     id_mask \u001b[38;5;241m=\u001b[39m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlogical_and\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     94\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43meq\u001b[49m\u001b[43m(\u001b[49m\u001b[43msample_id\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43munsqueeze\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msample_id\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43munsqueeze\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     95\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43meq\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvariate_id\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43munsqueeze\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvariate_id\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43munsqueeze\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     96\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     97\u001b[0m     tobs \u001b[38;5;241m=\u001b[39m reduce(\n\u001b[1;32m     98\u001b[0m         id_mask \u001b[38;5;241m*\u001b[39m reduce(observed_mask, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m... seq dim -> ... 1 seq\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msum\u001b[39m\u001b[38;5;124m\"\u001b[39m),\n\u001b[1;32m     99\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m... seq1 seq2 -> ... seq1 1\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    100\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msum\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    101\u001b[0m     )\n\u001b[1;32m    102\u001b[0m     loc \u001b[38;5;241m=\u001b[39m reduce(\n\u001b[1;32m    103\u001b[0m         id_mask \u001b[38;5;241m*\u001b[39m reduce(target \u001b[38;5;241m*\u001b[39m observed_mask, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m... seq dim -> ... 1 seq\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msum\u001b[39m\u001b[38;5;124m\"\u001b[39m),\n\u001b[1;32m    104\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m... seq1 seq2 -> ... seq1 1\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    105\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msum\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    106\u001b[0m     )\n",
      "\u001b[0;31mRuntimeError\u001b[0m: The size of tensor a (30) must match the size of tensor b (90) at non-singleton dimension 2"
     ]
    }
   ],
   "source": [
    "output = module.forward(\n",
    "    target=target,\n",
    "    observed_mask=observed_mask,\n",
    "    sample_id=sample_id,\n",
    "    time_id=time_id,\n",
    "    variate_id=variate_id,\n",
    "    prediction_mask=prediction_mask,\n",
    "    patch_size=patch_size_tensor,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd272204-8d3f-438a-ae87-b10af622fdd7",
   "metadata": {},
   "source": [
    "Tercer intento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "2d2c7f90-6d22-4168-8ede-f6f7fc2aec07",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(521, 3, 30)"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "97aec840-b37d-4a72-912d-45495376ea87",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_windows, num_variates, window_len = X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "edf84db7-a88b-40cf-ad46-a87573c70827",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(521, 90)"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target = X.reshape(521, -1)\n",
    "target.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "3c95eb6a-a38c-4b77-8725-6405e3b25dbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = num_windows\n",
    "seq_len = window_len * num_variates\n",
    "patch_size = 64\n",
    "max_patch = patch_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "e898fca0-9039-42c7-b8b6-d4e807ca6716",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([521, 90, 64])"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "observed_mask = torch.ones(batch_size, seq_len, max_patch, dtype=torch.bool)\n",
    "observed_mask.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "0f2bb5d4-9a7a-4c26-afbc-278c03d1c622",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([521, 90])"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_id = torch.arange(seq_len).unsqueeze(0).repeat(batch_size, 1)\n",
    "sample_id.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "3dfa73c5-1132-40a1-b951-41d34fded013",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([521, 90])"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "time_id = torch.arange(seq_len).unsqueeze(0).repeat(batch_size, 1)\n",
    "time_id.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfaad26c-8a6d-4401-8e00-87625f2a5afc",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
