{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fa093821-a793-49fd-a8c2-32cacdbdc964",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| default_exp encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6f6adb50-be0c-4f0b-9beb-38d4e78c5e03",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "#%load_ext autoreload --> Not working TODO:REVISAR\n",
    "# %autoreload 2 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "67bedfb7-6a74-4f6c-a769-cc79fe37686c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "from dvats.memory import *"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e6a4a02-5015-4a3e-9a64-6089de4e9532",
   "metadata": {},
   "source": [
    "# Encoder\n",
    "\n",
    "> Architectures and functions for creating encoders that create the embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b014a18f-8538-4ed7-98ee-ddb165692553",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from fastcore.all import *\n",
    "from tsai.callback.MVP import *\n",
    "from tsai.imports import *\n",
    "from tsai.models.InceptionTimePlus import InceptionTimePlus\n",
    "from tsai.models.explainability import get_acts_and_grads\n",
    "from tsai.models.layers import *\n",
    "from tsai.data.validation import combine_split_data\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "33c94f65",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "from tsai.all import *"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04637a46",
   "metadata": {},
   "source": [
    "### Architectures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c036898b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#|export \n",
    "class DCAE_torch(Module):\n",
    "    def __init__(self, c_in, seq_len, delta, nfs=[64, 32, 12], kss=[10, 5, 5],\n",
    "                 pool_szs=[2,2,3], output_fsz=10):\n",
    "        \"\"\"\n",
    "        Create a Deep Convolutional Autoencoder for multivariate time series of `d` dimensions,\n",
    "        sliced with a window size of `w`. The parameter `delta` sets the number of latent features that will be\n",
    "        contained in the Dense layer of the network. The the number of features\n",
    "        maps (filters), the filter size and the pool size can also be adjusted.\"\n",
    "        \"\"\"\n",
    "        assert all_equal([len(x) for x in [nfs, kss, pool_szs]], np.repeat(len(nfs), 3)), \\\n",
    "            'nfs, kss, and pool_szs must have the same length'\n",
    "        assert np.prod(pool_szs) == nfs[-1], \\\n",
    "            'The number of filters in the last conv layer must be equal to the product of pool sizes'\n",
    "        assert seq_len % np.prod(pool_szs) == 0, \\\n",
    "            'The product of pool sizes must be a divisor of the window size'\n",
    "        layers = []\n",
    "        for i in range_of(kss):\n",
    "            layers += [Conv1d(ni=nfs[i-1] if i>0 else c_in, nf=nfs[i], ks=kss[i]),\n",
    "                       nn.MaxPool1d(kernel_size=pool_szs[i])]\n",
    "        self.downsample = nn.Sequential(*layers)\n",
    "        self.bottleneck = nn.Sequential(OrderedDict([\n",
    "            ('flatten', nn.Flatten()),\n",
    "            ('latent_in', nn.Linear(seq_len, delta)),\n",
    "            ('latent_out', nn.Linear(delta, seq_len)),\n",
    "            ('reshape', Reshape(nfs[-1], seq_len // np.prod(pool_szs)))\n",
    "        ]))\n",
    "        layers = []\n",
    "        for i in reversed(range_of(kss)):\n",
    "            layers += [Conv1d(ni=nfs[i+1] if i != (len(nfs)-1) else nfs[-1],\n",
    "                              nf=nfs[i], ks=kss[i]),\n",
    "                       nn.Upsample(scale_factor=pool_szs[i])]\n",
    "        layers += [Conv1d(ni=nfs[0], nf=c_in, kernel_size=output_fsz)]\n",
    "        self.upsample = nn.Sequential(*layers)\n",
    "\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.downsample(x)\n",
    "        x = self.bottleneck(x)\n",
    "        x = self.upsample(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e59aa6e7-36df-4697-993e-60f737bb0f94",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3, 1, 48])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#| hide\n",
    "foo = torch.rand(3, 1, 48)\n",
    "m = DCAE_torch(c_in=foo.shape[1], seq_len=foo.shape[2], delta=12)\n",
    "m(foo).shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c1a4a1d-389c-481a-a54d-3f86cd2115f5",
   "metadata": {},
   "source": [
    "### Dictionary to get the default backbone modules to get the embeddings from"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3eb9f1b6-ae45-4b6e-b535-c7f121208721",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "ENCODER_EMBS_MODULE_NAME = {\n",
    "    InceptionTimePlus: 'backbone', # for mvp based models\n",
    "    DCAE_torch: 'bottleneck.latent_in'\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "268a268f-8b4e-4432-b203-79263a247c4c",
   "metadata": {},
   "source": [
    "### Getting the embeddings (activations) from the encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "65c66ae6-3178-49dc-bd16-64c082012e0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def get_enc_embs(X, enc_learn, module=None, cpu=False, average_seq_dim=True, to_numpy=True):\n",
    "    \"\"\"\n",
    "        Get the embeddings of X from an encoder, passed in `enc_learn as a fastai\n",
    "        learner. By default, the embeddings are obtained from the last layer\n",
    "        before the model head, although any layer can be passed to `model`.\n",
    "        Input\n",
    "        - `cpu`: Whether to do the model inference in cpu of gpu (GPU recommended)\n",
    "        - `average_seq_dim`: Whether to aggregate the embeddings in the sequence dimensions\n",
    "        - `to_numpy`: Whether to return the result as a numpy array (if false returns a tensor)\n",
    "    \"\"\"\n",
    "    print(\"--> Check CUDA\")\n",
    "    if cpu:\n",
    "        print(\"--> Get enc embs CPU\")\n",
    "        enc_learn.dls.cpu()\n",
    "        enc_learn.cpu()\n",
    "    else:\n",
    "        print(\"--> Ensure empty cache\")\n",
    "        torch.cuda.empty_cache()\n",
    "        print(\"--> Use CUDA |Get enc embs GPU \")\n",
    "        enc_learn.dls.cuda()\n",
    "        enc_learn.cuda()\n",
    "        if torch.cuda.is_available():\n",
    "            print(\"CUDA está disponible\")\n",
    "            print(\"Dispositivo CUDA actual: \", torch.cuda.current_device())\n",
    "            print(\"Nombre del dispositivo CUDA actual: \", torch.cuda.get_device_name(torch.cuda.current_device()))\n",
    "            \n",
    "        else:\n",
    "            print(\"CUDA no está disponible \")\n",
    "            print(\"Use CUDA -->\")\n",
    "    if enc_learn.dls.bs == 0: enc_learn.dls.bs = 64\n",
    "    \n",
    "    print(\"--> Set dataset from X (enc_learn does not contain dls)\")\n",
    "    aux_dl = enc_learn.dls.valid.new_dl(X=X)\n",
    "    aux_dl.bs = enc_learn.dls.bs if enc_learn.dls.bs>0 else 64\n",
    "    print(\"--> Get module\")\n",
    "    module = nested_attr(enc_learn.model,ENCODER_EMBS_MODULE_NAME[type(enc_learn.model)]) if module is None else module\n",
    "    \n",
    "    print(\"--> Get enc embs bs: \", aux_dl.bs)\n",
    "    embs = [\n",
    "        get_acts_and_grads(\n",
    "            model=enc_learn.model,\n",
    "            modules=module,\n",
    "            x=xb[0], \n",
    "            cpu=cpu\n",
    "        )[0] \n",
    "        for xb in aux_dl\n",
    "    ]\n",
    "    print(\"--> Concat\")\n",
    "    if not cpu:\n",
    "        total_emb_size = sum([emb.element_size() * emb.nelement() for emb in embs])\n",
    "        free_memory = torch.cuda.get_device_properties(0).total_memory - torch.cuda.memory_allocated()\n",
    "        if (total_emb_size < free_memory):\n",
    "            print(\"Fit in GPU\")\n",
    "            embs=[emb.cuda() for emb in embs]\n",
    "        else:\n",
    "            print(\"Dont fit in GPU --> Go to CPU\")\n",
    "            embs=[emb.cpu() for emb in embs]\n",
    "    embs = to_concat(embs)\n",
    "    print(\"--> reduce\")\n",
    "    if embs.ndim == 3 and average_seq_dim: embs = embs.mean(axis=2)\n",
    "    print(\"--> 2 numpy\")\n",
    "    if to_numpy: embs = embs.numpy() if cpu else embs.cpu().numpy()\n",
    "    return embs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "51ad3b28-43c0-4df3-be57-3eecb76b17d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "\n",
    "def get_enc_embs_set_stride_set_batch_size(\n",
    "    X, enc_learn, stride, batch_size, module=None, cpu=False, average_seq_dim=True, to_numpy=True, \n",
    "    print_flag = False, time_flag=False, chunk_size = 0, check_memory_usage = False\n",
    "):\n",
    "    \"\"\"\n",
    "        Get the embeddings of X from an encoder, passed in `enc_learn as a fastai\n",
    "        learner. By default, the embeddings are obtained from the last layer\n",
    "        before the model head, although any layer can be passed to `model`.\n",
    "        Input\n",
    "        - `cpu`: Whether to do the model inference in cpu of gpu (GPU recommended)\n",
    "        - `average_seq_dim`: Whether to aggregate the embeddings in the sequence dimensions\n",
    "        - `to_numpy`: Whether to return the result as a numpy array (if false returns a tensor)\n",
    "    \"\"\"\n",
    "    if time_flag:\n",
    "        t_start = time.time()\n",
    "    if print_flag:\n",
    "        print(\"--> get_enc_embs_set_stride_set_batch_size\")\n",
    "    if check_memory_usage: gpu_memory_status()\n",
    "        #print(\"get_enc_embs_set_stride_set_batch_size | Check versions\")\n",
    "        #import sys\n",
    "        #print(\"get_enc_embs_set_stride_set_batch_size | Check versions | Python version\", sys.version)\n",
    "        #print(\"get_enc_embs_set_stride_set_batch_size | Check versions | PyTorch version\", torch.__version__)\n",
    "        #print(\"get_enc_embs_set_stride_set_batch_size | Check versions | CUDA version\", torch.version.cuda)\n",
    "        #print(\"get_enc_embs_set_stride_set_batch_size | Apply stride & batch size\")\n",
    "    \n",
    "    X = X[::stride]\n",
    "    enc_learn.dls.bs = batch_size \n",
    "    \n",
    "    if (print_flag): print(\"get_enc_embs_set_stride_set_batch_size | Check CUDA | X ~ \", X.shape[0])\n",
    "    if cpu:\n",
    "        if (print_flag): print(\"get_enc_embs_set_stride_set_batch_size | Get enc embs CPU\")\n",
    "        enc_learn.dls.cpu()\n",
    "        enc_learn.cpu()\n",
    "    else:\n",
    "        if torch.cuda.is_available():\n",
    "            if (print_flag): \n",
    "                print(\"get_enc_embs_set_stride_set_batch_size | CUDA device id:\", torch.cuda.current_device())\n",
    "                print(\"get_enc_embs_set_stride_set_batch_size | CUDA device name: \", torch.cuda.get_device_name(torch.cuda.current_device()))\n",
    "                print(\"get_enc_embs_set_stride_set_batch_size | Ensure empty cache & move 2 GPU\")\n",
    "            torch.cuda.empty_cache()\n",
    "            enc_learn.dls.cuda()\n",
    "            enc_learn.cuda()\n",
    "        else:\n",
    "            if (print_flag): print(\"get_enc_embs_set_stride_set_batch_size | No cuda available. Set CPU = true\")\n",
    "            cpu = True\n",
    "    \n",
    "    if enc_learn.dls.bs is None or enc_learn.dls.bs == 0: enc_learn.dls.bs = 64\n",
    "\n",
    "    if (print_flag): print(\"get_enc_embs_set_stride_set_batch_size | Set dataset from X (enc_learn does not contain dls)\")\n",
    "    aux_dl = enc_learn.dls.valid.new_dl(X=X)\n",
    "    aux_dl.bs = enc_learn.dls.bs if enc_learn.dls.bs>0 else 64\n",
    "    if (print_flag): print(\"get_enc_embs_set_stride_set_batch_size | Get module\")\n",
    "    module = nested_attr(enc_learn.model,ENCODER_EMBS_MODULE_NAME[type(enc_learn.model)]) if module is None else module\n",
    "    \n",
    "    if (print_flag): \n",
    "        #print(\"get_enc_embs_set_stride_set_batch_size | Get acts and grads | module \", module)\n",
    "        print(\"get_enc_embs_set_stride_set_batch_size | Get acts and grads | aux_dl len\", len(aux_dl))\n",
    "        print(\"get_enc_embs_set_stride_set_batch_size | Get acts and grads | aux_dl.batch_len \", len(next(iter(aux_dl))))\n",
    "        print(\"get_enc_embs_set_stride_set_batch_size | Get acts and grads | aux_dl.bs \", aux_dl.bs)\n",
    "        if (not cpu):\n",
    "            total = torch.cuda.get_device_properties(device).total_memory\n",
    "            used = torch.cuda.memory_allocated(torch.cuda.current_device())\n",
    "            reserved = torch.cuda.memory_reserved(torch.cuda.current_device())\n",
    "            print(\"get_enc_embs_set_stride_set_batch_size | Get acts and grads | total_mem \", total)\n",
    "            print(\"get_enc_embs_set_stride_set_batch_size | Get acts and grads | used_mem \", used)\n",
    "            print(\"get_enc_embs_set_stride_set_batch_size | Get acts and grads | reserved_mem \", reserved)\n",
    "            print(\"get_enc_embs_set_stride_set_batch_size | Get acts and grads | available_mem \", total-reserved)\n",
    "            sys.stdout.flush()\n",
    "                                              \n",
    "    if (cpu or ( chunk_size == 0 )):\n",
    "        embs = [\n",
    "            get_acts_and_grads(\n",
    "                model=enc_learn.model,\n",
    "                modules=module, \n",
    "                x=xb[0], \n",
    "                cpu=cpu\n",
    "            )[0] \n",
    "            for xb in aux_dl\n",
    "        ]\n",
    "        if not cpu: embs=[emb.cpu() for emb in embs]\n",
    "    else:\n",
    "        embs = []\n",
    "        total_chunks=max(1,round(len(X)/chunk_size))\n",
    "        if print_flag: print(\"get_enc_embs_set_stride_set_batch_size | Get acts and grads | aux_dl len | \" + str(len(X)) + \" chunk size: \" + str(chunk_size) + \" => \" + str(total_chunks) + \" chunks\")\n",
    "        for i in range(0, total_chunks):\n",
    "            if print_flag: \n",
    "                print(\"get_enc_embs_set_stride_set_batch_size | Get acts and grads | Chunk [ \" + str(i) + \"/\"+str(total_chunks)+\"] => \" + str(round(i*100/total_chunks)) + \"%\")\n",
    "                sys.stdout.flush()\n",
    "            chunk = [batch for (n, batch) in enumerate(aux_dl) if (chunk_size*i <= n  and chunk_size*(i+1) > n) ]\n",
    "            chunk_embs = [\n",
    "                get_acts_and_grads(\n",
    "                    model=enc_learn.model,\n",
    "                    modules=module,\n",
    "                    x=xb[0], \n",
    "                    cpu=cpu\n",
    "                )[0]\n",
    "                for xb in chunk\n",
    "            ]\n",
    "            # Mueve los embeddings del bloque a la CPU\n",
    "            chunk_embs = [emb.cpu() for emb in chunk_embs]\n",
    "            embs.extend(chunk_embs)\n",
    "            torch.cuda.empty_cache()\n",
    "        if print_flag: \n",
    "            print(\"get_enc_embs_set_stride_set_batch_size | Get acts and grads | 100%\")\n",
    "            sys.stdout.flush()\n",
    "    \n",
    "    if print_flag: print(\"get_enc_embs_set_stride_set_batch_size | concat embeddings\")\n",
    "    \n",
    "    embs = to_concat(embs)\n",
    "    \n",
    "    if print_flag: print(\"get_enc_embs_set_stride_set_batch_size | Reduce\")\n",
    "    \n",
    "    if embs.ndim == 3 and average_seq_dim: embs = embs.mean(axis=2)\n",
    "    \n",
    "    if print_flag: print(\"get_enc_embs_set_stride_set_batch_size | Convert to numpy\")\n",
    "    \n",
    "    if to_numpy: \n",
    "        if cpu or chunk_size > 0:\n",
    "            embs = embs.numpy() \n",
    "        else: \n",
    "            embs = embs.cpu().numpy()\n",
    "            torch.cuda.empty_cache()\n",
    "    if time_flag:\n",
    "        t = time.time()-t_start\n",
    "        if print_flag:\n",
    "            print(\"get_enc_embs_set_stride_set_batch_size \" + str(t) + \" seconds -->\")\n",
    "        else:\n",
    "            print(\"get_enc_embs_set_stride_set_batch_size \" + str(t) + \" seconds\")\n",
    "    if check_memory_usage: gpu_memory_status()\n",
    "    if print_flag: \n",
    "        print(\"get_enc_embs_set_stride_set_batch_size -->\")\n",
    "    return embs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a5c9b646-2a6c-460b-bf56-e10fb740ac17",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "import wandb\n",
    "from dvats.utils import *\n",
    "wandb_api = wandb.Api()\n",
    "#enc_artifact = wandb_api.artifact('deepvats/mvp-SWV:latest')\n",
    "#enc_learner = enc_artifact.to_obj()\n",
    "#X = torch.rand(9, 1, 48)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8101184-0680-416f-a378-998c8fd00502",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "#%time\n",
    "#embs = get_enc_embs(X, enc_learner, cpu=True)\n",
    "#test_eq(embs.shape[0], X.shape[0])\n",
    "#embs.shape, embs.__class__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e04ade89-a3ad-4358-960d-5d21806ba01a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "#%%time #TODO dont work with nb2py\n",
    "#embs = get_enc_embs(X, enc_learner, cpu=False, to_numpy=False)\n",
    "#test_eq(embs.shape[0], X.shape[0])\n",
    "#embs.shape, embs.__class__, embs.device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83e63662-c5d3-47ea-a43f-5db9a2437745",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide \n",
    "#%%time #TODO --> dont works with nb2py\n",
    "#embs = get_enc_embs(X, enc_learner, cpu=False, to_numpy=True)\n",
    "#test_eq(embs.shape[0], X.shape[0])\n",
    "#embs.shape, embs.__class__"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
