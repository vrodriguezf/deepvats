{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dimensionality reduction\n",
    "\n",
    "> This notebook gets the embeddings (or latent space) from a multivariate time series \n",
    "given by a encoder (e.g., autoencoder) and uses them as input for a \n",
    "dimensionality reduction algorithm, to generate projectsion of the embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tsai.imports import *\n",
    "from tsai.data.preparation import SlidingWindow\n",
    "from fastcore.all import *\n",
    "from dvats.all import *\n",
    "import wandb\n",
    "from yaml import load, FullLoader\n",
    "import hdbscan\n",
    "#import shap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "check_memory_usage = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU | Used mem: 20\n",
      "GPU | Used mem: 24\n",
      "GPU | Memory Usage: [\u001b[91m████████████████----\u001b[0m] \u001b[91m83%\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "if check_memory_usage:\n",
    "    gpu_device = torch.cuda.current_device()\n",
    "    gpu_memory_status(gpu_device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Config parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get W&B API\n",
    "api = wandb.Api()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Put here everything that could be needed if this notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current: /home/macu/work/nbs_pipeline\n",
      "yml: ./config/04-dimensionality_reduction.yaml\n",
      "Getting content./config/04-dimensionality_reduction.yaml\n",
      "... About to replace includes with content\n",
      "Load content./config/04-dimensionality_reduction.yaml\n",
      "enc_artifact: mi-santamaria/deepvats/mvp-SWV:latest\n"
     ]
    }
   ],
   "source": [
    "config, job_type = get_artifact_config_dimensionality_reduction(True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "use_wandb: True\n",
      "wandb_group: None\n",
      "wandb_entity: mi-santamaria\n",
      "wandb_project: deepvats\n",
      "valid_artifact: None\n",
      "train_artifact: mi-santamaria/deepvats/mvp-SWV:latest\n",
      "dr_artifact: None\n",
      "n_neighbors: 15\n",
      "min_dist: 0.1\n",
      "random_state: 1234\n",
      "metric: euclidean\n",
      "cpu_flag: False\n"
     ]
    }
   ],
   "source": [
    "for key, value in config.items():\n",
    "    print(f\"{key}: {value}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Ñapa a arreglar\n",
    "config.cpu = False\n",
    "config.train_artifact = 'mi-santamaria/deepvats/mvp:latest'\n",
    "config.enc_artifact = 'mi-santamaria/deepvats/mvp:latest'\n",
    "config.dr_artifact_name = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "use_wandb: True\n",
      "wandb_group: None\n",
      "wandb_entity: mi-santamaria\n",
      "wandb_project: deepvats\n",
      "valid_artifact: None\n",
      "train_artifact: mi-santamaria/deepvats/mvp:latest\n",
      "dr_artifact: None\n",
      "n_neighbors: 15\n",
      "min_dist: 0.1\n",
      "random_state: 1234\n",
      "metric: euclidean\n",
      "cpu_flag: False\n",
      "cpu: False\n",
      "enc_artifact: mi-santamaria/deepvats/mvp:latest\n",
      "dr_artifact_name: None\n"
     ]
    }
   ],
   "source": [
    "for key, value in config.items():\n",
    "    print(f\"{key}: {value}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This model needs to restore the encoder model fitted in the notebook `02x`, as well as the data and configuration"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "path = os.path.expanduser(\"~/work/nbs_pipeline/\")\n",
    "name=\"04_dimensionality_reduction\"\n",
    "os.environ[\"WANDB_NOTEBOOK_NAME\"] = path+name+\".ipynb\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m WANDB_NOTEBOOK_NAME should be a path to a notebook file, couldn't find /home/macu/work/nbs_pipeline/04_dimensionality_reduction.ipynb.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Runname: 04_dimensionality_reduction | train: mi-santamaria/deepvats/mvp:latest | valid: None\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mmi-santamaria\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.17.8 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.14.2"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/home/macu/work/wandb/run-20240903_145056-cqc1bcmq</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/mi-santamaria/deepvats/runs/cqc1bcmq' target=\"_blank\">04_dimensionality_reduction | train: mi-santamaria/deepvats/mvp:latest | valid: None</a></strong> to <a href='https://wandb.ai/mi-santamaria/deepvats' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/mi-santamaria/deepvats' target=\"_blank\">https://wandb.ai/mi-santamaria/deepvats</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/mi-santamaria/deepvats/runs/cqc1bcmq' target=\"_blank\">https://wandb.ai/mi-santamaria/deepvats/runs/cqc1bcmq</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "if config.valid_artifact is not None:\n",
    "    runname=\"04_dimensionality_reduction | train: \"+ config.train_artifact + \" | valid: \"+config.valid_artifact\n",
    "else:\n",
    "    runname=\"04_dimensionality_reduction | train: \"+ config.train_artifact + \" | valid: None\"\n",
    "    \n",
    "    \n",
    "print(\"Runname: \"+ runname)\n",
    "run_dr = wandb.init(\n",
    "    entity              = config.wandb_entity,\n",
    "    project             = config.wandb_project if config.use_wandb else 'work-nbs', \n",
    "    group               = config.wandb_group,\n",
    "    allow_val_change    = True, \n",
    "    job_type            = job_type, \n",
    "    mode                = 'online' if config.use_wandb else 'disabled',\n",
    "    anonymous           = 'never' if config.use_wandb else 'must',\n",
    "    config              = config,\n",
    "    resume              = False,\n",
    "    name                = runname\n",
    ")\n",
    "config_dr = wandb.config # Object for storing hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Botch to use artifacts offline\n",
    "artifacts_gettr = run_dr.use_artifact if config_dr.use_wandb else api.artifact"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Restore the encoder model and its associated configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'r': 0.71,\n",
       " 'w': 30,\n",
       " 'MVP': {'r': 0.71,\n",
       "  'lm': 3.0,\n",
       "  'crit': None,\n",
       "  'sync': False,\n",
       "  'fname': 'encoder_MVP',\n",
       "  'dropout': 0.1,\n",
       "  'verbose': False,\n",
       "  'stateful': True,\n",
       "  'save_best': True,\n",
       "  'nan_to_num': 0,\n",
       "  'custom_mask': None,\n",
       "  'future_mask': False,\n",
       "  'weights_path': None,\n",
       "  'variable_mask': False,\n",
       "  'subsequence_mask': True},\n",
       " 'ref': {'hash': '-4091920695254897660',\n",
       "  'type': \"<class 'fastai.learner.Learner'>\"},\n",
       " 'freq': '1s',\n",
       " 'alias': 'toy',\n",
       " 'n_inp': 1,\n",
       " 'device': 'cuda',\n",
       " 'epochs': 100,\n",
       " 'frozen': False,\n",
       " 'mvp_ws': [10, 30],\n",
       " 'stride': 1,\n",
       " 'Learner': {'lr': 0.001,\n",
       "  'wd': None,\n",
       "  'arch': 'tsai.models.InceptionTimePlus.InceptionTimePlus',\n",
       "  'moms': [0.95, 0.85, 0.95],\n",
       "  'path': '.',\n",
       "  '_name': '<fastai.learner.Learner object at 0x7d3ab6f7a440>',\n",
       "  'metrics': None,\n",
       "  'opt_func': 'fastai.optimizer.Adam',\n",
       "  'splitter': 'tsai.models.utils.ts_splitter',\n",
       "  'train_bn': True,\n",
       "  'loss_func': {'axis': -1,\n",
       "   '_name': {'axis': -1,\n",
       "    '_name': 'FlattenedLoss of MSELoss()',\n",
       "    'is_2d': False,\n",
       "    'flatten': True,\n",
       "    'floatify': True},\n",
       "   'is_2d': False,\n",
       "   'flatten': True,\n",
       "   'floatify': True},\n",
       "  'model_dir': 'models',\n",
       "  'wd_bn_bias': False,\n",
       "  'default_cbs': True},\n",
       " 'Recorder': {'add_time': True, 'train_metrics': False, 'valid_metrics': True},\n",
       " 'time_col': None,\n",
       " 'data_cols': [],\n",
       " 'mask_sync': False,\n",
       " 'use_wandb': True,\n",
       " 'batch size': 417,\n",
       " 'batch_size': 512,\n",
       " 'csv_config': {},\n",
       " 'data_fpath': '~/data/toy.csv',\n",
       " 'frozen idx': 0,\n",
       " 'valid_size': 0.2,\n",
       " 'mask_future': False,\n",
       " 'wandb_group': None,\n",
       " 'CastToTensor': True,\n",
       " 'dataset.tfms': '[ToFloat:\\nencodes: (Tensor,object) -> encodes\\n(object,object) -> encodes\\ndecodes: (object,object) -> decodes\\n, None]',\n",
       " 'WandbCallback': {'log': None,\n",
       "  'seed': 12345,\n",
       "  'n_preds': 36,\n",
       "  'reorder': True,\n",
       "  'valid_dl': None,\n",
       "  'log_model': False,\n",
       "  'log_preds': False,\n",
       "  'model_name': None,\n",
       "  'log_dataset': False,\n",
       "  'dataset_name': None,\n",
       "  'log_preds_every_epoch': False},\n",
       " 'analysis_mode': 'online',\n",
       " 'artifact_name': 'toy',\n",
       " 'input 1 dim 1': 104,\n",
       " 'input 1 dim 2': 3,\n",
       " 'input 1 dim 3': 30,\n",
       " 'mask_stateful': True,\n",
       " 'ParamScheduler': True,\n",
       " 'dls.after_item': 'Pipeline: ',\n",
       " 'norm_by_sample': False,\n",
       " 'train_artifact': 'mi-santamaria/deepvats/toy:latest',\n",
       " 'valid_artifact': None,\n",
       " 'batch per epoch': 1,\n",
       " 'dls.after_batch': 'Pipeline: TSStandardize',\n",
       " 'ProgressCallback': True,\n",
       " 'dls.before_batch': 'Pipeline: ',\n",
       " 'model parameters': 455619,\n",
       " 'TrainEvalCallback': True,\n",
       " 'EarlyStoppingCallback': True,\n",
       " 'norm_use_single_batch': False,\n",
       " 'norm_use_by_single_batch': [False]}"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "enc_artifact = artifacts_gettr(config.train_artifact, type='learner')\n",
    "enc_artifact.metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Local file reference: Failed to find file at path /home/macu/data/wandb_artifacts/-4091920695254897660",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[15], line 3\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m----> 3\u001b[0m     enc_learner \u001b[38;5;241m=\u001b[39m \u001b[43menc_artifact\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto_obj\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m:\n",
      "File \u001b[0;32m~/work/dvats/utils.py:73\u001b[0m, in \u001b[0;36mto_obj\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     72\u001b[0m original_path \u001b[38;5;241m=\u001b[39m ReferenceArtifact\u001b[38;5;241m.\u001b[39mdefault_storage_path\u001b[38;5;241m/\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmetadata[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mref\u001b[39m\u001b[38;5;124m'\u001b[39m][\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mhash\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[0;32m---> 73\u001b[0m path \u001b[38;5;241m=\u001b[39m original_path \u001b[38;5;28;01mif\u001b[39;00m original_path\u001b[38;5;241m.\u001b[39mexists() \u001b[38;5;28;01melse\u001b[39;00m Path(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdownload\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m)\u001b[38;5;241m.\u001b[39mls()[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m     74\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mopen\u001b[39m(path, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mrb\u001b[39m\u001b[38;5;124m'\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m f:\n",
      "File \u001b[0;32m/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/wandb/apis/public.py:4753\u001b[0m, in \u001b[0;36mArtifact.download\u001b[0;34m(self, root, recursive)\u001b[0m\n\u001b[1;32m   4752\u001b[0m pool \u001b[38;5;241m=\u001b[39m multiprocessing\u001b[38;5;241m.\u001b[39mdummy\u001b[38;5;241m.\u001b[39mPool(\u001b[38;5;241m32\u001b[39m)\n\u001b[0;32m-> 4753\u001b[0m \u001b[43mpool\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmap\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   4754\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpartial\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_download_file\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mroot\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdirpath\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdownload_logger\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdownload_logger\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   4755\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmanifest\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mentries\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   4756\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   4757\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m recursive:\n",
      "File \u001b[0;32m/usr/local/share/miniconda3/envs/env/lib/python3.10/multiprocessing/pool.py:367\u001b[0m, in \u001b[0;36mPool.map\u001b[0;34m(self, func, iterable, chunksize)\u001b[0m\n\u001b[1;32m    363\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m'''\u001b[39;00m\n\u001b[1;32m    364\u001b[0m \u001b[38;5;124;03mApply `func` to each element in `iterable`, collecting the results\u001b[39;00m\n\u001b[1;32m    365\u001b[0m \u001b[38;5;124;03min a list that is returned.\u001b[39;00m\n\u001b[1;32m    366\u001b[0m \u001b[38;5;124;03m'''\u001b[39;00m\n\u001b[0;32m--> 367\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_map_async\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43miterable\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmapstar\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mchunksize\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/local/share/miniconda3/envs/env/lib/python3.10/multiprocessing/pool.py:774\u001b[0m, in \u001b[0;36mApplyResult.get\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    773\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 774\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_value\n",
      "File \u001b[0;32m/usr/local/share/miniconda3/envs/env/lib/python3.10/multiprocessing/pool.py:125\u001b[0m, in \u001b[0;36mworker\u001b[0;34m(inqueue, outqueue, initializer, initargs, maxtasks, wrap_exception)\u001b[0m\n\u001b[1;32m    124\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 125\u001b[0m     result \u001b[38;5;241m=\u001b[39m (\u001b[38;5;28;01mTrue\u001b[39;00m, \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[1;32m    126\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "File \u001b[0;32m/usr/local/share/miniconda3/envs/env/lib/python3.10/multiprocessing/pool.py:48\u001b[0m, in \u001b[0;36mmapstar\u001b[0;34m(args)\u001b[0m\n\u001b[1;32m     47\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mmapstar\u001b[39m(args):\n\u001b[0;32m---> 48\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mmap\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/wandb/apis/public.py:4848\u001b[0m, in \u001b[0;36mArtifact._download_file\u001b[0;34m(self, name, root, download_logger)\u001b[0m\n\u001b[1;32m   4844\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_download_file\u001b[39m(\n\u001b[1;32m   4845\u001b[0m     \u001b[38;5;28mself\u001b[39m, name, root, download_logger: Optional[_ArtifactDownloadLogger] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   4846\u001b[0m ):\n\u001b[1;32m   4847\u001b[0m     \u001b[38;5;66;03m# download file into cache and copy to target dir\u001b[39;00m\n\u001b[0;32m-> 4848\u001b[0m     downloaded_path \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_path\u001b[49m\u001b[43m(\u001b[49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdownload\u001b[49m\u001b[43m(\u001b[49m\u001b[43mroot\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   4849\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m download_logger \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[0;32m/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/wandb/apis/public.py:4154\u001b[0m, in \u001b[0;36m_DownloadedArtifactEntry.download\u001b[0;34m(self, root)\u001b[0m\n\u001b[1;32m   4153\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mref \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m-> 4154\u001b[0m     cache_path \u001b[38;5;241m=\u001b[39m \u001b[43mmanifest\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstorage_policy\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload_reference\u001b[49m\u001b[43m(\u001b[49m\u001b[43mentry\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlocal\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m   4155\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "File \u001b[0;32m/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/wandb/sdk/wandb_artifacts.py:910\u001b[0m, in \u001b[0;36mWandbStoragePolicy.load_reference\u001b[0;34m(self, manifest_entry, local)\u001b[0m\n\u001b[1;32m    905\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mload_reference\u001b[39m(\n\u001b[1;32m    906\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m    907\u001b[0m     manifest_entry: ArtifactManifestEntry,\n\u001b[1;32m    908\u001b[0m     local: \u001b[38;5;28mbool\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[1;32m    909\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28mstr\u001b[39m:\n\u001b[0;32m--> 910\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_handler\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload_path\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmanifest_entry\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlocal\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/wandb/sdk/wandb_artifacts.py:1115\u001b[0m, in \u001b[0;36mMultiHandler.load_path\u001b[0;34m(self, manifest_entry, local)\u001b[0m\n\u001b[1;32m   1112\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m   1113\u001b[0m         \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mNo storage handler registered for scheme \u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;241m%\u001b[39m \u001b[38;5;28mstr\u001b[39m(url\u001b[38;5;241m.\u001b[39mscheme)\n\u001b[1;32m   1114\u001b[0m     )\n\u001b[0;32m-> 1115\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_handlers\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;28;43mstr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43murl\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mscheme\u001b[49m\u001b[43m)\u001b[49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload_path\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmanifest_entry\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlocal\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlocal\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/wandb/sdk/wandb_artifacts.py:1228\u001b[0m, in \u001b[0;36mLocalFileHandler.load_path\u001b[0;34m(self, manifest_entry, local)\u001b[0m\n\u001b[1;32m   1227\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mexists(local_path):\n\u001b[0;32m-> 1228\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m   1229\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mLocal file reference: Failed to find file at path \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m local_path\n\u001b[1;32m   1230\u001b[0m     )\n\u001b[1;32m   1232\u001b[0m path, hit, cache_open \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_cache\u001b[38;5;241m.\u001b[39mcheck_md5_obj_path(\n\u001b[1;32m   1233\u001b[0m     B64MD5(manifest_entry\u001b[38;5;241m.\u001b[39mdigest),  \u001b[38;5;66;03m# TODO(spencerpearson): unsafe cast\u001b[39;00m\n\u001b[1;32m   1234\u001b[0m     manifest_entry\u001b[38;5;241m.\u001b[39msize \u001b[38;5;28;01mif\u001b[39;00m manifest_entry\u001b[38;5;241m.\u001b[39msize \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;241m0\u001b[39m,\n\u001b[1;32m   1235\u001b[0m )\n",
      "\u001b[0;31mValueError\u001b[0m: Local file reference: Failed to find file at path /home/macu/data/wandb_artifacts/-4091920695254897660",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[15], line 5\u001b[0m\n\u001b[1;32m      3\u001b[0m     enc_learner \u001b[38;5;241m=\u001b[39m enc_artifact\u001b[38;5;241m.\u001b[39mto_obj()\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m:\n\u001b[0;32m----> 5\u001b[0m     enc_learner \u001b[38;5;241m=\u001b[39m \u001b[43menc_artifact\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto_obj\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      6\u001b[0m enc_learner\n",
      "File \u001b[0;32m~/work/dvats/utils.py:73\u001b[0m, in \u001b[0;36mto_obj\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     71\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m     72\u001b[0m original_path \u001b[38;5;241m=\u001b[39m ReferenceArtifact\u001b[38;5;241m.\u001b[39mdefault_storage_path\u001b[38;5;241m/\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmetadata[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mref\u001b[39m\u001b[38;5;124m'\u001b[39m][\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mhash\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[0;32m---> 73\u001b[0m path \u001b[38;5;241m=\u001b[39m original_path \u001b[38;5;28;01mif\u001b[39;00m original_path\u001b[38;5;241m.\u001b[39mexists() \u001b[38;5;28;01melse\u001b[39;00m Path(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdownload\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m)\u001b[38;5;241m.\u001b[39mls()[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m     74\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mopen\u001b[39m(path, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mrb\u001b[39m\u001b[38;5;124m'\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m f:\n\u001b[1;32m     75\u001b[0m     obj \u001b[38;5;241m=\u001b[39m pickle\u001b[38;5;241m.\u001b[39mload(f)\n",
      "File \u001b[0;32m/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/wandb/apis/public.py:4753\u001b[0m, in \u001b[0;36mArtifact.download\u001b[0;34m(self, root, recursive)\u001b[0m\n\u001b[1;32m   4750\u001b[0m download_logger \u001b[38;5;241m=\u001b[39m _ArtifactDownloadLogger(nfiles\u001b[38;5;241m=\u001b[39mnfiles)\n\u001b[1;32m   4752\u001b[0m pool \u001b[38;5;241m=\u001b[39m multiprocessing\u001b[38;5;241m.\u001b[39mdummy\u001b[38;5;241m.\u001b[39mPool(\u001b[38;5;241m32\u001b[39m)\n\u001b[0;32m-> 4753\u001b[0m \u001b[43mpool\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmap\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   4754\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpartial\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_download_file\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mroot\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdirpath\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdownload_logger\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdownload_logger\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   4755\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmanifest\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mentries\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   4756\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   4757\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m recursive:\n\u001b[1;32m   4758\u001b[0m     pool\u001b[38;5;241m.\u001b[39mmap(\u001b[38;5;28;01mlambda\u001b[39;00m artifact: artifact\u001b[38;5;241m.\u001b[39mdownload(), \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dependent_artifacts)\n",
      "File \u001b[0;32m/usr/local/share/miniconda3/envs/env/lib/python3.10/multiprocessing/pool.py:367\u001b[0m, in \u001b[0;36mPool.map\u001b[0;34m(self, func, iterable, chunksize)\u001b[0m\n\u001b[1;32m    362\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mmap\u001b[39m(\u001b[38;5;28mself\u001b[39m, func, iterable, chunksize\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[1;32m    363\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m'''\u001b[39;00m\n\u001b[1;32m    364\u001b[0m \u001b[38;5;124;03m    Apply `func` to each element in `iterable`, collecting the results\u001b[39;00m\n\u001b[1;32m    365\u001b[0m \u001b[38;5;124;03m    in a list that is returned.\u001b[39;00m\n\u001b[1;32m    366\u001b[0m \u001b[38;5;124;03m    '''\u001b[39;00m\n\u001b[0;32m--> 367\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_map_async\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43miterable\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmapstar\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mchunksize\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/local/share/miniconda3/envs/env/lib/python3.10/multiprocessing/pool.py:774\u001b[0m, in \u001b[0;36mApplyResult.get\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    772\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_value\n\u001b[1;32m    773\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 774\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_value\n",
      "File \u001b[0;32m/usr/local/share/miniconda3/envs/env/lib/python3.10/multiprocessing/pool.py:125\u001b[0m, in \u001b[0;36mworker\u001b[0;34m(inqueue, outqueue, initializer, initargs, maxtasks, wrap_exception)\u001b[0m\n\u001b[1;32m    123\u001b[0m job, i, func, args, kwds \u001b[38;5;241m=\u001b[39m task\n\u001b[1;32m    124\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 125\u001b[0m     result \u001b[38;5;241m=\u001b[39m (\u001b[38;5;28;01mTrue\u001b[39;00m, \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[1;32m    126\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    127\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m wrap_exception \u001b[38;5;129;01mand\u001b[39;00m func \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m _helper_reraises_exception:\n",
      "File \u001b[0;32m/usr/local/share/miniconda3/envs/env/lib/python3.10/multiprocessing/pool.py:48\u001b[0m, in \u001b[0;36mmapstar\u001b[0;34m(args)\u001b[0m\n\u001b[1;32m     47\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mmapstar\u001b[39m(args):\n\u001b[0;32m---> 48\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mmap\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/wandb/apis/public.py:4848\u001b[0m, in \u001b[0;36mArtifact._download_file\u001b[0;34m(self, name, root, download_logger)\u001b[0m\n\u001b[1;32m   4844\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_download_file\u001b[39m(\n\u001b[1;32m   4845\u001b[0m     \u001b[38;5;28mself\u001b[39m, name, root, download_logger: Optional[_ArtifactDownloadLogger] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   4846\u001b[0m ):\n\u001b[1;32m   4847\u001b[0m     \u001b[38;5;66;03m# download file into cache and copy to target dir\u001b[39;00m\n\u001b[0;32m-> 4848\u001b[0m     downloaded_path \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_path\u001b[49m\u001b[43m(\u001b[49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdownload\u001b[49m\u001b[43m(\u001b[49m\u001b[43mroot\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   4849\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m download_logger \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m   4850\u001b[0m         download_logger\u001b[38;5;241m.\u001b[39mnotify_downloaded()\n",
      "File \u001b[0;32m/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/wandb/apis/public.py:4154\u001b[0m, in \u001b[0;36m_DownloadedArtifactEntry.download\u001b[0;34m(self, root)\u001b[0m\n\u001b[1;32m   4151\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m dest_path\n\u001b[1;32m   4153\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mref \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m-> 4154\u001b[0m     cache_path \u001b[38;5;241m=\u001b[39m \u001b[43mmanifest\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstorage_policy\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload_reference\u001b[49m\u001b[43m(\u001b[49m\u001b[43mentry\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlocal\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m   4155\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   4156\u001b[0m     cache_path \u001b[38;5;241m=\u001b[39m manifest\u001b[38;5;241m.\u001b[39mstorage_policy\u001b[38;5;241m.\u001b[39mload_file(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_parent_artifact, entry)\n",
      "File \u001b[0;32m/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/wandb/sdk/wandb_artifacts.py:910\u001b[0m, in \u001b[0;36mWandbStoragePolicy.load_reference\u001b[0;34m(self, manifest_entry, local)\u001b[0m\n\u001b[1;32m    905\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mload_reference\u001b[39m(\n\u001b[1;32m    906\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m    907\u001b[0m     manifest_entry: ArtifactManifestEntry,\n\u001b[1;32m    908\u001b[0m     local: \u001b[38;5;28mbool\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[1;32m    909\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28mstr\u001b[39m:\n\u001b[0;32m--> 910\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_handler\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload_path\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmanifest_entry\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlocal\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/wandb/sdk/wandb_artifacts.py:1115\u001b[0m, in \u001b[0;36mMultiHandler.load_path\u001b[0;34m(self, manifest_entry, local)\u001b[0m\n\u001b[1;32m   1111\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_default_handler\u001b[38;5;241m.\u001b[39mload_path(manifest_entry, local\u001b[38;5;241m=\u001b[39mlocal)\n\u001b[1;32m   1112\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m   1113\u001b[0m         \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mNo storage handler registered for scheme \u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;241m%\u001b[39m \u001b[38;5;28mstr\u001b[39m(url\u001b[38;5;241m.\u001b[39mscheme)\n\u001b[1;32m   1114\u001b[0m     )\n\u001b[0;32m-> 1115\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_handlers\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;28;43mstr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43murl\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mscheme\u001b[49m\u001b[43m)\u001b[49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload_path\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmanifest_entry\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlocal\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlocal\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/wandb/sdk/wandb_artifacts.py:1228\u001b[0m, in \u001b[0;36mLocalFileHandler.load_path\u001b[0;34m(self, manifest_entry, local)\u001b[0m\n\u001b[1;32m   1226\u001b[0m local_path \u001b[38;5;241m=\u001b[39m util\u001b[38;5;241m.\u001b[39mlocal_file_uri_to_path(\u001b[38;5;28mstr\u001b[39m(manifest_entry\u001b[38;5;241m.\u001b[39mref))\n\u001b[1;32m   1227\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mexists(local_path):\n\u001b[0;32m-> 1228\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m   1229\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mLocal file reference: Failed to find file at path \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m local_path\n\u001b[1;32m   1230\u001b[0m     )\n\u001b[1;32m   1232\u001b[0m path, hit, cache_open \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_cache\u001b[38;5;241m.\u001b[39mcheck_md5_obj_path(\n\u001b[1;32m   1233\u001b[0m     B64MD5(manifest_entry\u001b[38;5;241m.\u001b[39mdigest),  \u001b[38;5;66;03m# TODO(spencerpearson): unsafe cast\u001b[39;00m\n\u001b[1;32m   1234\u001b[0m     manifest_entry\u001b[38;5;241m.\u001b[39msize \u001b[38;5;28;01mif\u001b[39;00m manifest_entry\u001b[38;5;241m.\u001b[39msize \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;241m0\u001b[39m,\n\u001b[1;32m   1235\u001b[0m )\n\u001b[1;32m   1236\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m hit:\n",
      "\u001b[0;31mValueError\u001b[0m: Local file reference: Failed to find file at path /home/macu/data/wandb_artifacts/-4091920695254897660"
     ]
    }
   ],
   "source": [
    "# TODO: This only works when you run it two timeS! WTF?\n",
    "try:\n",
    "    enc_learner = enc_artifact.to_obj()\n",
    "except:\n",
    "    enc_learner = enc_artifact.to_obj()\n",
    "enc_learner"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Restore the dataset artifact used for training the encoder. Even if we do not compute the dimensionality reduction over this dataset, we need to know the metadata of the encoder training set, to check that \n",
    "it matches with the dataset that we want to reduce."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "enc_logger = enc_artifact.logged_by()\n",
    "print(enc_logger)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "enc_artifact_train = artifacts_gettr(enc_logger.config['train_artifact'], type='dataset')\n",
    "if enc_logger.config['valid_artifact'] is not None:\n",
    "    enc_artifact_valid = artifacts_gettr(enc_logger.config['valid_artifact'], type='dataset')\n",
    "    enc_artifact_train.name, enc_artifact_valid.name\n",
    "print(\"enc_artifact_train: \", enc_artifact_train.name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we need to check whether the artifact that is going to be used fort the dimensionality reduction matches the artifact used to train the encoder. Matching means having the same number of variables, the same window size and stride, and the same frequency."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if config_dr.dr_artifact_name is not None:\n",
    "    dr_artifact = artifacts_gettr(config_dr.dr_artifact_name)\n",
    "else:\n",
    "    dr_artifact = enc_artifact_train\n",
    "dr_artifact.name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = dr_artifact.to_df()\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "w = enc_logger.config['w']\n",
    "stride = enc_logger.config['stride']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"w: \" + str(w))\n",
    "print(\"stride: \" + str(stride))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "enc_input, _ = SlidingWindow(window_len=enc_logger.config['w'], \n",
    "                             stride=enc_logger.config['stride'], \n",
    "                             get_y=[])(df)\n",
    "enc_input.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Getting the embeddings (activations) from the encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "embs = get_enc_embs(enc_input, enc_learner, cpu=False)\n",
    "test_eq(embs.shape[0], enc_input.shape[0])\n",
    "embs.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Average embeddings in the time dimension, if needed"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dimensionality reduction using UMAP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#dr_methods = ['UMAP', 'TSNE', 'PCA']\n",
    "#dr_method = dr_methods[0]\n",
    "#match dr_method:\n",
    "    #case 'UMAP':\n",
    "     #    action-1\n",
    "    #case pattern-2:\n",
    "         #action-2\n",
    "    #case pattern-3:\n",
    "     #    action-3\n",
    "    #case _:\n",
    "     #   action-default\n",
    "        \n",
    "#res = switch(input$dr_method,\n",
    " #            UMAP = dvats$,\n",
    "  #           TSNE = dvats$get_TSNE_prjs(X = embs, cpu=F, random_state=as.integer(1234)),\n",
    "   #          PCA = dvats$get_PCA_prjs(X = embs, cpu=F, random_state=as.integer(1234)))\n",
    "      #res = res %>% as.data.frame # TODO: This should be a matrix for improved efficiency\n",
    "      #colnames(res) = c(\"xcoord\", \"ycoord\")\n",
    "      #on.exit(print(\" prj_object -->\"))\n",
    "      #res"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We use DR techniques to provide an alternative view for users to visually analyze and explore the time-series data. The algorithm UMAP shows its high competitiveness compared to t-SNE. t-SNE suffers from some limitations such as loss of large-scale information (the inter-cluster relationships). UMAP has a faster runtime and provides better scaling which helps to gain a meaningful organization of clusters, outliers and the preservation of continuums compared to t-SNE\n",
    "\n",
    "For this part of the implementation, the package [umap-learn](https://github.com/lmcinnes/umap) is used. The input of the algoritm is the $n \\times \\delta$ that contains, for each slice of the time series, the corresponding $\\delta$ latent embeddings given by the encoder.\n",
    "\n",
    "The hyperparameters of UMAP are given values by default here. If the value has been already set previously, that means this notebook is being called from a wandb sweep, and we must use the value that the sweep is bringing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "umap_params = {\n",
    "    'n_neighbors' : config_dr.n_neighbors,\n",
    "    'min_dist' : config_dr.min_dist,\n",
    "    'random_state': config_dr.random_state\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Comprobado que es necesario para que no falle sunspot\n",
    "#Ensure no nan ((Intento de Macu. La celda de comentada abajo es la original. Pero falla por Nan con sunspot))\n",
    "embs_no_nan = embs[~np.isnan(embs).any(axis=1)]\n",
    "embs_no_nan.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prjs = get_UMAP_prjs(embs_no_nan, cpu=False, **umap_params)\n",
    "prjs.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Save the projections as an artifact"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if config.use_wandb: \n",
    "    run_dr.log_artifact(ReferenceArtifact(prjs, 'projections', type='projections', \n",
    "metadata=dict(run_dr.config)), aliases=f'run-{run_dr.project}-{run_dr.id}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Precomputed Clusters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In order to integrate precomputed clusters into the embedding space, it's necessary to log artifacts that include the labels of the newly created clusters. \n",
    "\n",
    "The cluster creation process is presented below. This creation procedure can be modified according to specific needs. However, the structure of the new artifact must be preserved (it must be a numpy.ndarray and the number of elements must be equal to the number of points in the embedding space)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'HDBSCAN supported metrics: {list(hdbscan.dist_metrics.METRIC_MAPPING.keys())}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define HDBSCAN parameters\n",
    "hdbscan_kwargs = {\n",
    "    'min_cluster_size' : 5,\n",
    "    'min_samples' : 7,\n",
    "    'cluster_selection_epsilon' : 0.0001,\n",
    "}\n",
    "metric_kwargs = {\n",
    "    'metric' : 'euclidean' #'jaccard' \n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create clusters using HDBSCAN\n",
    "clusters = hdbscan.HDBSCAN(**hdbscan_kwargs, **metric_kwargs).fit(prjs)\n",
    "clusters_labels = clusters.labels_\n",
    "clusters_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Testing artifact structure \n",
    "test_eq_type(type(clusters_labels), np.ndarray)\n",
    "test_eq(clusters_labels.size, prjs.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create and log 'clusters_labels' artifact\n",
    "clusters_ar = ReferenceArtifact(obj=clusters_labels, name='clusters_labels')\n",
    "clusters_ar.metadata, clusters_ar.manifest.entries.values()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "run_dr.log_artifact(clusters_ar, aliases=['hdbscan_jaccard'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2D Visualization "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "While the connected scatter plot is a simple visualization technique, it has very specific functions in our approach. Every sliding window is represented as a dot in the plot after the projection process (Fig. 4C, D of the paper). Before labeling, all points have the same color and transparency, and when they are concentrated in one area, the densities are accumulated. Lines are used to connect consecutive points preserving the temporal ordering of the data and allowing the user to see temporal connections (Fig. 4B of the paper). Thus, the point is linked to the previous point (inner) and to the posterior point (outer) as an indication of the flow of time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def plot_projections(prjs, umap_params, fig_size = (25,25)):\n",
    "    \"Plot 2D projections thorugh a connected scatter plot\"\n",
    "    df_prjs = pd.DataFrame(prjs, columns = ['x1', 'x2'])\n",
    "    fig = plt.figure(figsize=(fig_size[0],fig_size[1]))\n",
    "    ax = fig.add_subplot(111)\n",
    "    ax.scatter(df_prjs['x1'], df_prjs['x2'], marker='o', facecolors='none', edgecolors='b', alpha=0.1)\n",
    "    ax.plot(df_prjs['x1'], df_prjs['x2'], alpha=0.5, picker=1)\n",
    "    plt.title('DR params -  n_neighbors:{:d} min_dist:{:f}'.format(\n",
    "        umap_params['n_neighbors'],umap_params['min_dist']))\n",
    "    return ax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "# Color cluster & lines out\n",
    "def plot_projections_clusters(prjs, clusters_labels, umap_params, fig_size = (25,25)):\n",
    "    \"Plot 2D projections thorugh a connected scatter plot\"\n",
    "    df_prjs = pd.DataFrame(prjs, columns = ['x1', 'x2'])\n",
    "    df_prjs['cluster'] = clusters_labels\n",
    "    \n",
    "    fig = plt.figure(figsize=(fig_size[0],fig_size[1]))\n",
    "    ax = fig.add_subplot(111)\n",
    "    \n",
    "    # Create a scatter plot for each cluster with different colors\n",
    "    unique_labels = df_prjs['cluster'].unique()\n",
    "    print(unique_labels)\n",
    "    for label in unique_labels:\n",
    "        cluster_data = df_prjs[df_prjs['cluster'] == label]\n",
    "        ax.scatter(cluster_data['x1'], cluster_data['x2'], label=f'Cluster {label}')\n",
    "        #ax.scatter(df_prjs['x1'], df_prjs['x2'], marker='o', facecolors='none', edgecolors='b', alpha=0.1)\n",
    "    \n",
    "    #ax.plot(df_prjs['x1'], df_prjs['x2'], alpha=0.5, picker=1)\n",
    "    plt.title('DR params -  n_neighbors:{:d} min_dist:{:f}'.format(\n",
    "        umap_params['n_neighbors'],umap_params['min_dist']))\n",
    "    return ax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prjs_plt = plot_projections(prjs, umap_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prjs_plt = plot_projections_clusters(prjs, clusters_labels, umap_params)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Log this plot as part of the current wandb run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "\n",
    "# Get the figure of the embedding plot, and save it on thea wandb run.\n",
    "run_dr.log({\"img\": [wandb.Image(prjs_plt.get_figure(), caption=\"dr_projections_plot\")]})\n",
    "\n",
    "#run_dr.log({'embeddings_plot': embeddings_plot})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "run_dr.finish()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Explainability with SHAP (future work)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %matplotlib inline\n",
    "\n",
    "# fig = plt.figure(figsize=(10,10))\n",
    "# ax = fig.add_subplot(111)\n",
    "\n",
    "# ax.scatter(df_embeddings['x1'], df_embeddings['x2'], marker='o', facecolors='none', edgecolors='b', alpha=0.1)\n",
    "# ax.plot(df_embeddings['x1'], df_embeddings['x2'], alpha=0.5, picker=1)\n",
    "# ax.set_title('Select the point you want to visualize as a time window in the original space')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Make the plot interactive to allow selection of subsets of the plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# selected_indices = None\n",
    "# selected_points = None\n",
    "\n",
    "# def onpick(event):\n",
    "#     global selected_points\n",
    "#     thisline = event.artist\n",
    "#     xdata = thisline.get_xdata()\n",
    "#     ydata = thisline.get_ydata()\n",
    "#     global selected_indices\n",
    "#     selected_indices = event.ind\n",
    "#     selected_points = tuple(zip(xdata[selected_indices], ydata[selected_indices]))\n",
    "#     print('onpick points (first):', selected_points[0])\n",
    "\n",
    "# fig.canvas.mpl_connect('pick_event', onpick)\n",
    "\n",
    "# plt.show()\n",
    "# fig.tight_layout()\n",
    "# fig.savefig(f'../img/w={w}.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hyperparameter tuning for the dimensionality reduction\n",
    "\n",
    "There are a number of parameters that can be set for the UMAP algorithm. The major \n",
    "ones are `n_neighbors` and `min_dist`. Thus, we will carry out a hyperparameter \n",
    "sweep in Weights and Biases for these two parameters. Note that there is no objective\n",
    "way of deciding that some embeddings are better than others. Thus, we must rely on our\n",
    "intuition by visualizing the 2D plots of each of the runs in the sweep.\n",
    "\n",
    "The first thing we need is gather all the pipeline of the previous section into a function"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## Linking back points of the 2D projection to the original time series"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The variable `selected_points` and `ind` contain an array of the points and indices selected in the previous 2D projection. We will take the first of them (there can be many selected points with just one click), and use its index to get the corresponding time window of the original space."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# selected_window = input_data[df_embeddings.sample(n=1).index][0] if selected_indices is None else input_data[selected_indices[0]]\n",
    "# selected_window"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualizing all the variables in the time window (default)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %matplotlib inline\n",
    "# g = sns.FacetGrid(df_output_tidy, col=\"variable\", col_wrap=3, aspect=2)\n",
    "# g = g.map(plt.plot, \"timestamp\", \"value\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Contribution: Visualize only the most relevant variables"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In high dimensional time series, not only is interesting to see the window associated to a point in the 2D space, but also it is extremely important to spot which variables are mainly causing that the window is positioned in that point of the 2D space.\n",
    "\n",
    "Since UMAP does not provide capabilities to understand feature importance, there are [different ways](https://stats.stackexchange.com/questions/438025/understand-important-features-in-umap) to tackle this problem:\n",
    "\n",
    "1. Use another dimensionality reduction technique that provides importance, such as [sparse PCA](https://scikit-learn.org/stable/modules/generated/sklearn.decomposition.SparsePCA.html)\n",
    "\n",
    "2. Create a surrogate model on top of the inputs/output of UMAP and explain it using XAI techniques. We will try here this option."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The idea is to have a surrogate model that takes the multivariate time series as input and produces the associated points in the 2D space as ouput. Since we already have a Deep Convolutional Autoencoder (DCAE) that takes a multivariate time series as input, and it contains the latent features that represent that input, we can use it for the surrogate. We will use the intermediate model that goes from the input to the layer containing the latent space, and then add a `Dense` layer with 2 units and linear activation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "# def train_surrogate_model(dcae, embeddings, lat_ln='latent_features'):\n",
    "#     \"Train a surrogate model that learns the `embeddings` from the latent features contained in the layer \\\n",
    "#     `lat_ln` of a previously trained Deep Convolutional AutoEncoder `dcae`\"\n",
    "#     x = dcae.get_layer(lat_ln).output\n",
    "#     x = Dense(units=embeddings.shape[1], activation='linear')(x)\n",
    "#     surrogate_model = Model(dcae.input, x)\n",
    "#     l_nms = [layer.name for layer in surrogate_model.layers]\n",
    "#     layer_idx = l_nms.index(lat_ln)\n",
    "#     # The layers that are already trained from the autoencoder must be `frozen`\n",
    "#     for layer in surrogate_model.layers[:layer_idx]:\n",
    "#         layer.trainable = False\n",
    "#     return surrogate_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sm = train_surrogate_model(m, embeddings, lat_ln='latent_features')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test.equals(sm.input.shape, m.input.shape)\n",
    "# test.equals(sm.output.shape[1], embeddings.shape[1])\n",
    "# l_nms = [layer.name for layer in sm.layers]\n",
    "# layer_idx = l_nms.index('latent_features')\n",
    "# test.all_equal([layer.trainable for layer in sm.layers], \\\n",
    "#                np.repeat([False, True], [layer_idx + 1, len(sm.layers) -1 -layer_idx]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Configure the training hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loss = 'mean_squared_error'\n",
    "# opt = 'adam'\n",
    "# bs = 100\n",
    "# epochs = 10\n",
    "# val = .2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sm.output_shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# input_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# embeddings.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sm.fit(x=input_data, y=embeddings, batch_size=bs, validation_split=val, epochs=epochs, callbacks=[WandbCallback()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import innvestigate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# analyzer = innvestigate.create_analyzer(\"gradient\", intermediate_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# asd= innvestigate.create_analyzer(\"gradient\", m)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from keras.datasets import mnist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# (x_train, y_train), (x_test, y_test) = mnist.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# x_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# input_data[np.random.choice(input_data.shape[0], 100, replace=False)].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import shap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# background = input_data[np.random.choice(input_data.shape[0], 100, replace=False)]\n",
    "# e = shap.DeepExplainer(intermediate_model, background)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# shap_values = e.shap_values(input_data[0:4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# shap_values[0][0]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
