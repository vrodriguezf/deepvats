{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "<h1> Using MOMENT for Imputation </h1>\n",
    "<hr>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Contents\n",
    "### 1. A Quick Introduction to Imputation\n",
    "### 2. Loading MOMENT\n",
    "### 3. Inputs and Outputs\n",
    "### 4. Zero-shot Imputation\n",
    "#### &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; 4.1 Masking Time Series Patches\n",
    "#### &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; 4.2 Imputation using MOMENT\n",
    "#### &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; 4.3 Results\n",
    "### 5. Example Code to Fine-tune MOMENT for Imputation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. A Quick Introduction to Imputation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Multivariate time series are prevalent in real world applications such as finance, meteorology and healthcare. These time series often contain missing values due to various reasons, including equipment malfunctions and human errors. Missing values can impede the meaningful analyis of time series, and hence numerous studies have focused on the task of imputing these missing values using machine learning methodologies. In this tutorial, we will use MOMENT to address the issue of missing values. Formally, the imputation task can be defined as follows:\n",
    "\n",
    "**Problem**: We are given a time series $T = [x_1, ..., x_L], \\ x_i \\in \\mathbb{R}^{C}$ of length $L$ with $C$ channels (sensors or variables), and a boolean mask of same length $mask = [m_1, ..., m_L]$ indicating missing values. The objective of the imputation problem is to infer missing values and recover the original time series."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Loading MOMENT\n",
    "\n",
    "We will first install the MOMENT package, load some essential packages and the pre-trained model. \n",
    "\n",
    "MOMENT can be loaded in 4 modes: (1) `reconstruction`, (2) `embedding`, (3) `forecasting`, and (4) `classification`.\n",
    "\n",
    "In the `reconstruction` mode, MOMENT reconstructs input time series, potentially containing missing values. We can solve imputation and anomaly detection problems in this mode. This mode is suitable for solving imputation and anomaly detection tasks. During pre-training, MOMENT is trained to predict the missing values within uniformly randomly masked patches (disjoint sub-sequences) of the input time series, leveraging information from observed data in other patches. As a result, MOMENT comes equipped with a pre-trained reconstruction head, enabling it to address imputation and anomaly detection challenges in a zero-shot manner! Check out the `anomaly_detection.ipynb` notebook for more details!\n",
    "\n",
    "In the `embedding` model, MOMENT learns a $d$-dimensional embedding (e.g., $d=1024$ for `MOMENT-1-large`) for each input time series. These embeddings can be used for clustering and classification. MOMENT can learn embeddings in a zero-shot setting! Check out `representation_learning.ipynb` and `classification.ipynb` notebooks for more details! \n",
    "\n",
    "The `forecasting` and `classification` modes are used for forecasting and classification tasks, respectively. In these modes, MOMENT learns representations which are subsequently mapped to the forecast horizon or the number of classes, using linear forecasting and classification heads. Both the forecasting and classification head are randomly initialized, and therefore must be fine-tuned before use. Check out the `forecasting.ipynb` and `classification.ipynb` notebooks for more details!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: numpy in /usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages (1.25.2)\n",
      "Requirement already satisfied: pandas in /usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages (1.5.3)\n",
      "Requirement already satisfied: scikit-learn in /usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages (1.2.2)\n",
      "Requirement already satisfied: matplotlib in /usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages (3.8.1)\n",
      "Requirement already satisfied: tqdm in /usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages (4.66.2)\n",
      "Requirement already satisfied: python-dateutil>=2.8.1 in /usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages (from pandas) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in /usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages (from pandas) (2024.1)\n",
      "Requirement already satisfied: scipy>=1.3.2 in /usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages (from scikit-learn) (1.12.0)\n",
      "Requirement already satisfied: joblib>=1.1.1 in /usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages (from scikit-learn) (1.3.2)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages (from scikit-learn) (3.3.0)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages (from matplotlib) (1.2.0)\n",
      "Requirement already satisfied: cycler>=0.10 in /usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages (from matplotlib) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages (from matplotlib) (4.49.0)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages (from matplotlib) (1.4.5)\n",
      "Requirement already satisfied: packaging>=20.0 in /usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages (from matplotlib) (23.2)\n",
      "Requirement already satisfied: pillow>=8 in /usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages (from matplotlib) (10.2.0)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages (from matplotlib) (3.1.1)\n",
      "Requirement already satisfied: six>=1.5 in /usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages (from python-dateutil>=2.8.1->pandas) (1.16.0)\n",
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Collecting git+https://github.com/moment-timeseries-foundation-model/moment.git\n",
      "  Cloning https://github.com/moment-timeseries-foundation-model/moment.git to /tmp/pip-req-build-4tld8913\n",
      "  Running command git clone --filter=blob:none --quiet https://github.com/moment-timeseries-foundation-model/moment.git /tmp/pip-req-build-4tld8913\n",
      "  Resolved https://github.com/moment-timeseries-foundation-model/moment.git to commit c96275abc26410f63d3c5f7949483e15fb82639e\n",
      "  Installing build dependencies ... \u001b[?25ldone\n",
      "\u001b[?25h  Getting requirements to build wheel ... \u001b[?25ldone\n",
      "\u001b[?25h  Preparing metadata (pyproject.toml) ... \u001b[?25ldone\n",
      "\u001b[?25hRequirement already satisfied: huggingface-hub==0.24.0 in /usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages (from momentfm==0.1.2) (0.24.0)\n",
      "Requirement already satisfied: numpy==1.25.2 in /usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages (from momentfm==0.1.2) (1.25.2)\n",
      "Requirement already satisfied: torch~=2.0 in /usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages (from momentfm==0.1.2) (2.4.1)\n",
      "Requirement already satisfied: transformers==4.33.3 in /usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages (from momentfm==0.1.2) (4.33.3)\n",
      "Requirement already satisfied: filelock in /usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages (from huggingface-hub==0.24.0->momentfm==0.1.2) (3.13.1)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages (from huggingface-hub==0.24.0->momentfm==0.1.2) (2024.2.0)\n",
      "Requirement already satisfied: packaging>=20.9 in /usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages (from huggingface-hub==0.24.0->momentfm==0.1.2) (23.2)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages (from huggingface-hub==0.24.0->momentfm==0.1.2) (6.0.1)\n",
      "Requirement already satisfied: requests in /usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages (from huggingface-hub==0.24.0->momentfm==0.1.2) (2.31.0)\n",
      "Requirement already satisfied: tqdm>=4.42.1 in /usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages (from huggingface-hub==0.24.0->momentfm==0.1.2) (4.66.2)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages (from huggingface-hub==0.24.0->momentfm==0.1.2) (4.9.0)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages (from transformers==4.33.3->momentfm==0.1.2) (2024.7.24)\n",
      "Requirement already satisfied: tokenizers!=0.11.3,<0.14,>=0.11.1 in /usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages (from transformers==4.33.3->momentfm==0.1.2) (0.13.3)\n",
      "Requirement already satisfied: safetensors>=0.3.1 in /usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages (from transformers==4.33.3->momentfm==0.1.2) (0.4.4)\n",
      "Requirement already satisfied: sympy in /usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages (from torch~=2.0->momentfm==0.1.2) (1.13.3)\n",
      "Requirement already satisfied: networkx in /usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages (from torch~=2.0->momentfm==0.1.2) (3.4)\n",
      "Requirement already satisfied: jinja2 in /usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages (from torch~=2.0->momentfm==0.1.2) (3.1.3)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages (from torch~=2.0->momentfm==0.1.2) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages (from torch~=2.0->momentfm==0.1.2) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages (from torch~=2.0->momentfm==0.1.2) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages (from torch~=2.0->momentfm==0.1.2) (9.1.0.70)\n",
      "Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages (from torch~=2.0->momentfm==0.1.2) (12.1.3.1)\n",
      "Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages (from torch~=2.0->momentfm==0.1.2) (11.0.2.54)\n",
      "Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages (from torch~=2.0->momentfm==0.1.2) (10.3.2.106)\n",
      "Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages (from torch~=2.0->momentfm==0.1.2) (11.4.5.107)\n",
      "Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages (from torch~=2.0->momentfm==0.1.2) (12.1.0.106)\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.20.5 in /usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages (from torch~=2.0->momentfm==0.1.2) (2.20.5)\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages (from torch~=2.0->momentfm==0.1.2) (12.1.105)\n",
      "Requirement already satisfied: triton==3.0.0 in /usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages (from torch~=2.0->momentfm==0.1.2) (3.0.0)\n",
      "Requirement already satisfied: nvidia-nvjitlink-cu12 in /usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages (from nvidia-cusolver-cu12==11.4.5.107->torch~=2.0->momentfm==0.1.2) (12.6.77)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages (from jinja2->torch~=2.0->momentfm==0.1.2) (2.1.5)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages (from requests->huggingface-hub==0.24.0->momentfm==0.1.2) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages (from requests->huggingface-hub==0.24.0->momentfm==0.1.2) (3.6)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages (from requests->huggingface-hub==0.24.0->momentfm==0.1.2) (2.2.1)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages (from requests->huggingface-hub==0.24.0->momentfm==0.1.2) (2024.8.30)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages (from sympy->torch~=2.0->momentfm==0.1.2) (1.3.0)\n",
      "Building wheels for collected packages: momentfm\n",
      "  Building wheel for momentfm (pyproject.toml) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for momentfm: filename=momentfm-0.1.2-py3-none-any.whl size=33753 sha256=09eabf9584af082fb083609ed20a7fef2e5d761bd2c4cd49668b8cacc02ee599\n",
      "  Stored in directory: /tmp/pip-ephem-wheel-cache-l0_z2sc3/wheels/6e/62/da/a5752a90276fbaebe0da5c0d02272f6549f43e9ceaac72907e\n",
      "Successfully built momentfm\n",
      "Installing collected packages: momentfm\n",
      "Successfully installed momentfm-0.1.2\n"
     ]
    }
   ],
   "source": [
    "!pip install numpy pandas scikit-learn matplotlib tqdm\n",
    "!pip install git+https://github.com/moment-timeseries-foundation-model/moment.git"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/transformers/utils/generic.py:311: FutureWarning: `torch.utils._pytree._register_pytree_node` is deprecated. Please use `torch.utils._pytree.register_pytree_node` instead.\n",
      "  torch.utils._pytree._register_pytree_node(\n"
     ]
    }
   ],
   "source": [
    "from momentfm.utils.utils import control_randomness\n",
    "control_randomness(seed=13) # Set random seeds for PyTorch, Numpy etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9d760181c9de48f88dba5f2304d03e5c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/951 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a9a77a9a2e454b53a9b066da01f9c8c0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/1.39G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from momentfm import MOMENTPipeline\n",
    "\n",
    "model = MOMENTPipeline.from_pretrained(\n",
    "    \"AutonLab/MOMENT-1-large\",\n",
    "    model_kwargs={'task_name': 'reconstruction'} # For imputation, we will load MOMENT in `reconstruction` mode\n",
    "    local_files_only=True,  # Whether or not to only look at local files (i.e., do not try to download the model).\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MOMENTPipeline(\n",
      "  (normalizer): RevIN()\n",
      "  (tokenizer): Patching()\n",
      "  (patch_embedding): PatchEmbedding(\n",
      "    (value_embedding): Linear(in_features=8, out_features=1024, bias=False)\n",
      "    (position_embedding): PositionalEmbedding()\n",
      "    (dropout): Dropout(p=0.1, inplace=False)\n",
      "  )\n",
      "  (encoder): T5Stack(\n",
      "    (embed_tokens): Embedding(32128, 1024)\n",
      "    (block): ModuleList(\n",
      "      (0): T5Block(\n",
      "        (layer): ModuleList(\n",
      "          (0): T5LayerSelfAttention(\n",
      "            (SelfAttention): T5Attention(\n",
      "              (q): Linear(in_features=1024, out_features=1024, bias=False)\n",
      "              (k): Linear(in_features=1024, out_features=1024, bias=False)\n",
      "              (v): Linear(in_features=1024, out_features=1024, bias=False)\n",
      "              (o): Linear(in_features=1024, out_features=1024, bias=False)\n",
      "              (relative_attention_bias): Embedding(32, 16)\n",
      "            )\n",
      "            (layer_norm): T5LayerNorm()\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "          (1): T5LayerFF(\n",
      "            (DenseReluDense): T5DenseGatedActDense(\n",
      "              (wi_0): Linear(in_features=1024, out_features=2816, bias=False)\n",
      "              (wi_1): Linear(in_features=1024, out_features=2816, bias=False)\n",
      "              (wo): Linear(in_features=2816, out_features=1024, bias=False)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "              (act): NewGELUActivation()\n",
      "            )\n",
      "            (layer_norm): T5LayerNorm()\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (1-23): 23 x T5Block(\n",
      "        (layer): ModuleList(\n",
      "          (0): T5LayerSelfAttention(\n",
      "            (SelfAttention): T5Attention(\n",
      "              (q): Linear(in_features=1024, out_features=1024, bias=False)\n",
      "              (k): Linear(in_features=1024, out_features=1024, bias=False)\n",
      "              (v): Linear(in_features=1024, out_features=1024, bias=False)\n",
      "              (o): Linear(in_features=1024, out_features=1024, bias=False)\n",
      "            )\n",
      "            (layer_norm): T5LayerNorm()\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "          (1): T5LayerFF(\n",
      "            (DenseReluDense): T5DenseGatedActDense(\n",
      "              (wi_0): Linear(in_features=1024, out_features=2816, bias=False)\n",
      "              (wi_1): Linear(in_features=1024, out_features=2816, bias=False)\n",
      "              (wo): Linear(in_features=2816, out_features=1024, bias=False)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "              (act): NewGELUActivation()\n",
      "            )\n",
      "            (layer_norm): T5LayerNorm()\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (final_layer_norm): T5LayerNorm()\n",
      "    (dropout): Dropout(p=0.1, inplace=False)\n",
      "  )\n",
      "  (head): PretrainHead(\n",
      "    (dropout): Dropout(p=0.1, inplace=False)\n",
      "    (linear): Linear(in_features=1024, out_features=8, bias=True)\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "model.init()\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of parameters: 341231104\n"
     ]
    }
   ],
   "source": [
    "# Number of parameters in the encoder\n",
    "num_params = sum(p.numel() for p in model.encoder.parameters())\n",
    "print(f\"Number of parameters: {num_params}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Inputs and Outputs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's begin by performing a forward pass through MOMENT and examining its outputs!\n",
    "\n",
    "MOMENT takes 3 inputs: \n",
    "1. An input time series of length $T=512$ timesteps and $C$ channels, and \n",
    "2. Two optional masks, both of length $T=512$. \n",
    "    - The input mask is utilized to regulate the time steps or patches that the model should attend to. For instance, in the case of shorter time series, you may opt not to attend to padding. To implement this, you can provide an input mask with zeros in the padded locations.  \n",
    "    - The second mask, referred to simply as mask, denotes masked or unobserved values. We employ mask tokens to replace all patches containing any masked time step (for further details, refer to Section 3.2 in our [paper](https://arxiv.org/abs/2402.03885)). MOMENT can attend to these mask tokens during reconstruction.\n",
    "    - By default, all time steps are observed and attended to.\n",
    "\n",
    "MOMENT returns a `TimeseriesOutputs` object. Since this is a reconstruction task, it returns a `reconstruction` of the input. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TimeseriesOutputs(forecast=None,\n",
      "                  anomaly_scores=None,\n",
      "                  logits=None,\n",
      "                  labels=None,\n",
      "                  input_mask=tensor([[1., 1., 1.,  ..., 1., 1., 1.],\n",
      "        [1., 1., 1.,  ..., 1., 1., 1.],\n",
      "        [1., 1., 1.,  ..., 1., 1., 1.],\n",
      "        ...,\n",
      "        [1., 1., 1.,  ..., 1., 1., 1.],\n",
      "        [1., 1., 1.,  ..., 1., 1., 1.],\n",
      "        [1., 1., 1.,  ..., 1., 1., 1.]]),\n",
      "                  pretrain_mask=tensor([[1, 1, 1,  ..., 1, 1, 1],\n",
      "        [1, 1, 1,  ..., 1, 1, 1],\n",
      "        [1, 1, 1,  ..., 1, 1, 1],\n",
      "        ...,\n",
      "        [1, 1, 1,  ..., 1, 1, 1],\n",
      "        [1, 1, 1,  ..., 1, 1, 1],\n",
      "        [1, 1, 1,  ..., 1, 1, 1]]),\n",
      "                  reconstruction=tensor([[[ 0.2324,  0.1094,  0.2164,  ...,  0.0588, -0.0759, -0.0502],\n",
      "         [-0.0367,  0.1259,  0.1714,  ...,  0.0368,  0.0780,  0.0990],\n",
      "         [ 0.2103,  0.1353,  0.1216,  ..., -0.0357, -0.1504, -0.0600]],\n",
      "\n",
      "        [[ 0.1444,  0.0818,  0.2749,  ...,  0.1330,  0.1471,  0.0560],\n",
      "         [ 0.1323,  0.0957,  0.1591,  ...,  0.1153, -0.0131, -0.0679],\n",
      "         [ 0.1455, -0.0061,  0.1360,  ...,  0.0947, -0.0925, -0.0703]],\n",
      "\n",
      "        [[ 0.1345, -0.1776,  0.0859,  ...,  0.4450, -0.3549,  0.2221],\n",
      "         [-0.0186, -0.0233, -0.0727,  ...,  0.0089, -0.0757, -0.0513],\n",
      "         [ 0.0017,  0.0097,  0.0138,  ..., -0.0823, -0.1285, -0.2974]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[ 0.0913,  0.0814, -0.0212,  ...,  0.1376, -0.1661,  0.0133],\n",
      "         [ 0.1319,  0.0745,  0.0552,  ...,  0.0835,  0.0968,  0.2126],\n",
      "         [-0.1128, -0.0881, -0.0577,  ..., -0.0912, -0.0826, -0.1761]],\n",
      "\n",
      "        [[-0.0324,  0.0248,  0.1007,  ...,  0.2538,  0.0606,  0.3513],\n",
      "         [ 0.1181,  0.0438, -0.1943,  ..., -0.3164, -0.1028, -0.4682],\n",
      "         [ 0.0747, -0.0727,  0.0134,  ..., -0.1612, -0.0771, -0.1138]],\n",
      "\n",
      "        [[ 0.2721, -0.0086,  0.2753,  ...,  0.3071, -0.0486,  0.1064],\n",
      "         [ 0.0528, -0.0977,  0.1071,  ..., -0.1194,  0.0434, -0.0449],\n",
      "         [-0.1765, -0.1192,  0.0614,  ...,  0.2009, -0.0360,  0.1736]]],\n",
      "       grad_fn=<AddBackward0>),\n",
      "                  embeddings=None,\n",
      "                  metadata=None,\n",
      "                  illegal_output=None)\n"
     ]
    }
   ],
   "source": [
    "from pprint import pprint\n",
    "import torch\n",
    "\n",
    "# takes in tensor of shape [batch_size, n_channels, context_length]\n",
    "x = torch.randn(100, 3, 512)\n",
    "output = model(x_enc=x)\n",
    "pprint(output)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Zero-shot Imputation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we'll show you how to use MOMENT to do zero-shot imputation!\n",
    "\n",
    "In these experiments, we will use Hourly Electricity Transformer Temperature (ETTh1) dataset introduced by [Zhou et al., 2020](https://arxiv.org/abs/2012.07436). Check out [ETDataset](https://github.com/zhouhaoyi/ETDataset) for more information! We will use the ETTh1 dataset since missing values are common in this domain!\n",
    "\n",
    "We'll start by reading and pre-processing this dataset using the `InformerDataset` class. Since we can do zero-shot imputation, we will just load the testing part of this data. Note that MOMENT was not exposed to the testing part of this dataset during pre-training. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "#! mkdir ../data\n",
    "#! wget \"https://github.com/moment-timeseries-foundation-model/moment/blob/main/data/ETTh1.csv\" \n",
    "#! mv ./ETTh1.csv ../data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "from momentfm.data.informer_dataset import InformerDataset\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "#test_dataset = InformerDataset(\n",
    "    #data_split='test', \n",
    "    #task_name='imputation', \n",
    "    #data_stride_len=512) # Falla por alg√∫n motivo que desconozco\n",
    "\n",
    "test_dataset = x\n",
    "test_dataloader = DataLoader(test_dataset, batch_size=64, shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's visualize the time series"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "n_channels = test_dataset[0][0].shape[0]\n",
    "idx = np.random.randint(0, len(test_dataset))\n",
    "channel_idx = np.random.randint(0, n_channels)\n",
    "#plt.plot(test_dataset[idx][0][channel_idx, :].squeeze(), c='darkblue')\n",
    "#plt.title(f'idx={idx}  | channel={channel_idx}')\n",
    "#plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.1 Masking Time Series Patches\n",
    "\n",
    "Since there are no missing values in this dataset, we will randomly mask time series subsequences to evaluate MOMENT's ability to reason about missing values. Instead of masking individual time steps at random, we will mask time series patches uniformly at random using the `Masking` class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "from momentfm.utils.masking import Masking\n",
    "\n",
    "mask_generator = Masking(mask_ratio=0.25) # Mask 25% of patches randomly "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001b[0;31mType:\u001b[0m           Masking\n",
       "\u001b[0;31mString form:\u001b[0m    <momentfm.utils.masking.Masking object at 0x7fcb1fcab9a0>\n",
       "\u001b[0;31mFile:\u001b[0m           ~/.local/lib/python3.10/site-packages/momentfm/utils/masking.py\n",
       "\u001b[0;31mSource:\u001b[0m        \n",
       "\u001b[0;32mclass\u001b[0m \u001b[0mMasking\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0;32mdef\u001b[0m \u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m        \u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmask_ratio\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mfloat\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0.3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpatch_len\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mint\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m8\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstride\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mOptional\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m        \u001b[0;34m\"\"\"\u001b[0m\n",
       "\u001b[0;34m        Indices with 0 mask are hidden, and with 1 are observed.\u001b[0m\n",
       "\u001b[0;34m        \"\"\"\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m        \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmask_ratio\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmask_ratio\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m        \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpatch_len\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpatch_len\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m        \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstride\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpatch_len\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mstride\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mstride\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0;34m@\u001b[0m\u001b[0mstaticmethod\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0;32mdef\u001b[0m \u001b[0mconvert_seq_to_patch_view\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m        \u001b[0mmask\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpatch_len\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mint\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m8\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstride\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mOptional\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m        \u001b[0;34m\"\"\"\u001b[0m\n",
       "\u001b[0;34m        Input:\u001b[0m\n",
       "\u001b[0;34m            mask : torch.Tensor of shape [batch_size x seq_len]\u001b[0m\n",
       "\u001b[0;34m        Output\u001b[0m\n",
       "\u001b[0;34m            mask : torch.Tensor of shape [batch_size x n_patches]\u001b[0m\n",
       "\u001b[0;34m        \"\"\"\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m        \u001b[0mstride\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpatch_len\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mstride\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mstride\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m        \u001b[0mmask\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmask\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munfold\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdimension\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpatch_len\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstep\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstride\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m        \u001b[0;31m# mask : [batch_size x n_patches x patch_len]\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m        \u001b[0;32mreturn\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mmask\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mpatch_len\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlong\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0;34m@\u001b[0m\u001b[0mstaticmethod\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0;32mdef\u001b[0m \u001b[0mconvert_patch_to_seq_view\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m        \u001b[0mmask\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m        \u001b[0mpatch_len\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mint\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m8\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m        \u001b[0;34m\"\"\"\u001b[0m\n",
       "\u001b[0;34m        Input:\u001b[0m\n",
       "\u001b[0;34m            mask : torch.Tensor of shape [batch_size x n_patches]\u001b[0m\n",
       "\u001b[0;34m        Output:\u001b[0m\n",
       "\u001b[0;34m            mask : torch.Tensor of shape [batch_size x seq_len]\u001b[0m\n",
       "\u001b[0;34m        \"\"\"\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m        \u001b[0;32mreturn\u001b[0m \u001b[0mmask\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrepeat_interleave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpatch_len\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0;32mdef\u001b[0m \u001b[0mgenerate_mask\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_mask\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mOptional\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m        \u001b[0;34m\"\"\"\u001b[0m\n",
       "\u001b[0;34m        Input:\u001b[0m\n",
       "\u001b[0;34m            x : torch.Tensor of shape\u001b[0m\n",
       "\u001b[0;34m            [batch_size x n_channels x n_patches x patch_len] or\u001b[0m\n",
       "\u001b[0;34m            [batch_size x n_channels x seq_len]\u001b[0m\n",
       "\u001b[0;34m            input_mask: torch.Tensor of shape [batch_size x seq_len] or\u001b[0m\n",
       "\u001b[0;34m            [batch_size x n_patches]\u001b[0m\n",
       "\u001b[0;34m        Output:\u001b[0m\n",
       "\u001b[0;34m            mask : torch.Tensor of shape [batch_size x seq_len]\u001b[0m\n",
       "\u001b[0;34m        \"\"\"\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m        \u001b[0;32mif\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndim\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m4\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m            \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_mask_patch_view\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_mask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minput_mask\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m        \u001b[0;32melif\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndim\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m            \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_mask_seq_view\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_mask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minput_mask\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0;32mdef\u001b[0m \u001b[0m_mask_patch_view\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_mask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m        \u001b[0;34m\"\"\"\u001b[0m\n",
       "\u001b[0;34m        Input:\u001b[0m\n",
       "\u001b[0;34m            x : torch.Tensor of shape\u001b[0m\n",
       "\u001b[0;34m            [batch_size x n_channels x n_patches x patch_len]\u001b[0m\n",
       "\u001b[0;34m            input_mask: torch.Tensor of shape [batch_size x seq_len]\u001b[0m\n",
       "\u001b[0;34m        Output:\u001b[0m\n",
       "\u001b[0;34m            mask : torch.Tensor of shape [batch_size x n_patches]\u001b[0m\n",
       "\u001b[0;34m        \"\"\"\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m        \u001b[0minput_mask\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconvert_seq_to_patch_view\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m            \u001b[0minput_mask\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpatch_len\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstride\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m        \u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m        \u001b[0mn_observed_patches\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minput_mask\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkeepdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# batch_size x 1\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m        \u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_patches\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m        \u001b[0mlen_keep\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mceil\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_observed_patches\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmask_ratio\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlong\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m        \u001b[0mnoise\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrand\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m            \u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_patches\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m        \u001b[0;34m)\u001b[0m  \u001b[0;31m# noise in [0, 1], batch_size x n_channels x n_patches\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m        \u001b[0mnoise\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwhere\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m            \u001b[0minput_mask\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnoise\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mones_like\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnoise\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m        \u001b[0;34m)\u001b[0m  \u001b[0;31m# only keep the noise of observed patches\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m        \u001b[0;31m# Sort noise for each sample\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m        \u001b[0mids_shuffle\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margsort\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m            \u001b[0mnoise\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m        \u001b[0;34m)\u001b[0m  \u001b[0;31m# Ascend: small is keep, large is remove\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m        \u001b[0mids_restore\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margsort\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m            \u001b[0mids_shuffle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m        \u001b[0;34m)\u001b[0m  \u001b[0;31m# ids_restore: [batch_size x n_patches]\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m        \u001b[0;31m# Generate the binary mask: 0 is keep, 1 is remove\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m        \u001b[0mmask\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzeros\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m            \u001b[0;34m[\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_patches\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m        \u001b[0;34m)\u001b[0m  \u001b[0;31m# mask: [batch_size x n_patches]\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m        \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m            \u001b[0mmask\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m \u001b[0mlen_keep\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m        \u001b[0;31m# Unshuffle to get the binary mask\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m        \u001b[0mmask\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgather\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmask\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mids_restore\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m        \u001b[0;32mreturn\u001b[0m \u001b[0mmask\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlong\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0;32mdef\u001b[0m \u001b[0m_mask_seq_view\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_mask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m        \u001b[0;34m\"\"\"\u001b[0m\n",
       "\u001b[0;34m        Input:\u001b[0m\n",
       "\u001b[0;34m            x : torch.Tensor of shape\u001b[0m\n",
       "\u001b[0;34m            [batch_size x n_channels x seq_len]\u001b[0m\n",
       "\u001b[0;34m            input_mask: torch.Tensor of shape [batch_size x seq_len]\u001b[0m\n",
       "\u001b[0;34m        Output:\u001b[0m\n",
       "\u001b[0;34m            mask : torch.Tensor of shape [batch_size x seq_len]\u001b[0m\n",
       "\u001b[0;34m        \"\"\"\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m        \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munfold\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdimension\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpatch_len\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstep\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstride\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m        \u001b[0mmask\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_mask_patch_view\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_mask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minput_mask\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m        \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconvert_patch_to_seq_view\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmask\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpatch_len\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlong\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
       "\u001b[0;31mInit docstring:\u001b[0m Indices with 0 mask are hidden, and with 1 are observed."
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "?? mask_generator"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.2 Imputation using MOMENT\n",
    "\n",
    "Since there are no missing values in this dataset, we will randomly mask time series subsequences to evaluate MOMENT's ability to reason about missing values. Instead of masking individual time steps at random, we will mask time series patches uniformly at random using the `Masking` class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001b[0;31mSignature:\u001b[0m\n",
       " \u001b[0mmask_generator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgenerate_mask\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0minput_mask\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mOptional\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
       "\u001b[0;31mSource:\u001b[0m   \n",
       "    \u001b[0;32mdef\u001b[0m \u001b[0mgenerate_mask\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_mask\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mOptional\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m        \u001b[0;34m\"\"\"\u001b[0m\n",
       "\u001b[0;34m        Input:\u001b[0m\n",
       "\u001b[0;34m            x : torch.Tensor of shape\u001b[0m\n",
       "\u001b[0;34m            [batch_size x n_channels x n_patches x patch_len] or\u001b[0m\n",
       "\u001b[0;34m            [batch_size x n_channels x seq_len]\u001b[0m\n",
       "\u001b[0;34m            input_mask: torch.Tensor of shape [batch_size x seq_len] or\u001b[0m\n",
       "\u001b[0;34m            [batch_size x n_patches]\u001b[0m\n",
       "\u001b[0;34m        Output:\u001b[0m\n",
       "\u001b[0;34m            mask : torch.Tensor of shape [batch_size x seq_len]\u001b[0m\n",
       "\u001b[0;34m        \"\"\"\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m        \u001b[0;32mif\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndim\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m4\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m            \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_mask_patch_view\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_mask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minput_mask\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m        \u001b[0;32melif\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndim\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m            \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_mask_seq_view\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_mask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minput_mask\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
       "\u001b[0;31mFile:\u001b[0m      ~/.local/lib/python3.10/site-packages/momentfm/utils/masking.py\n",
       "\u001b[0;31mType:\u001b[0m      method"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "?? mask_generator.generate_mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0% 0/2 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'batch_x' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[35], line 9\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mno_grad():\n\u001b[1;32m      8\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m tqdm(test_dataloader, total\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mlen\u001b[39m(test_dataloader)):\n\u001b[0;32m----> 9\u001b[0m         trues\u001b[38;5;241m.\u001b[39mappend(\u001b[43mbatch_x\u001b[49m\u001b[38;5;241m.\u001b[39mnumpy())\n\u001b[1;32m     11\u001b[0m         batch_x \u001b[38;5;241m=\u001b[39m batch_x\u001b[38;5;241m.\u001b[39mto(device)\u001b[38;5;241m.\u001b[39mfloat()\n\u001b[1;32m     12\u001b[0m         n_channels \u001b[38;5;241m=\u001b[39m batch_x\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m1\u001b[39m]\n",
      "\u001b[0;31mNameError\u001b[0m: name 'batch_x' is not defined"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "device = \"cuda:1\" if torch.cuda.is_available() else \"cpu\"\n",
    "model = model.to(device).float()\n",
    "\n",
    "trues, preds, masks = [], [], []\n",
    "with torch.no_grad():\n",
    "    for batch_x, batch_masks in tqdm(test_dataloader, total=len(test_dataloader)):\n",
    "        trues.append(batch_x.numpy())\n",
    "        \n",
    "        batch_x = batch_x.to(device).float()\n",
    "        n_channels = batch_x.shape[1]\n",
    "        \n",
    "        # Reshape to [batch_size * n_channels, 1, window_size]\n",
    "        batch_x = batch_x.reshape((-1, 1, 512)) \n",
    "        \n",
    "        batch_masks = batch_masks.to(device).long()\n",
    "        batch_masks = batch_masks.repeat_interleave(n_channels, axis=0)\n",
    "        \n",
    "        mask = mask_generator.generate_mask(\n",
    "            x=batch_x, input_mask=batch_masks).to(device).long()\n",
    "\n",
    "        output = model(x_enc=batch_x, input_mask=batch_masks, mask=mask) # [batch_size, n_channels, window_size]\n",
    "        \n",
    "        reconstruction = output.reconstruction.detach().cpu().numpy()\n",
    "        mask = mask.detach().squeeze().cpu().numpy()\n",
    "        \n",
    "        # Reshape back to [batch_size, n_channels, window_size]\n",
    "        reconstruction = reconstruction.reshape((-1, n_channels, 512)) \n",
    "        mask = mask.reshape((-1, n_channels, 512))\n",
    "                \n",
    "        preds.append(reconstruction)\n",
    "        masks.append(mask)\n",
    "\n",
    "preds = np.concatenate(preds)\n",
    "trues = np.concatenate(trues)\n",
    "masks = np.concatenate(masks)\n",
    "\n",
    "print(f\"Shapes: preds={preds.shape} | trues={trues.shape} | masks={masks.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.3 Results\n",
    "\n",
    "Since there are no missing values in this dataset, we will randomly mask time series subsequences to evaluate MOMENT's ability to reason about missing values. Instead of masking individual time steps at random, we will mask time series patches uniformly at random using the `Masking` class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from momentfm.utils.forecasting_metrics import mse, mae\n",
    "\n",
    "print(f\"Mean Squarred Error (MSE)={mse(y=trues[masks==0], y_hat=preds[masks==0], reduction='mean')}\")\n",
    "print(f\"Mean Absolute Error (MAE)={mae(y=trues[masks==0], y_hat=preds[masks==0], reduction='mean')}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's visualize random time series windows! White patches are masked and black patches are observed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "idx = np.random.randint(trues.shape[0])\n",
    "channel_idx = np.random.randint(trues.shape[1])\n",
    "\n",
    "fig, axs = plt.subplots(2, 1, figsize=(10, 5))\n",
    "axs[0].set_title(f\"Channel={channel_idx}\")\n",
    "axs[0].plot(trues[idx, channel_idx, :].squeeze(), label='Ground Truth', c='darkblue')\n",
    "axs[0].plot(preds[idx, channel_idx, :].squeeze(), label='Predictions', c='red')\n",
    "axs[0].legend(fontsize=16)\n",
    "\n",
    "axs[1].imshow(np.tile(masks[np.newaxis, idx, channel_idx], reps=(8, 1)), cmap='binary')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Example Code to Fine-tune MOMENT for Imputation\n",
    "\n",
    "To improve MOMENT's imputation performance, you can fine-tune it on any dataset. In our [paper](https://arxiv.org/abs/2402.03885), we fine-tune the final reconstruction head, but you can also fine-tune the entire model on your data. Here is some example code:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Optimize Mean Squarred Error using your favourite optimizer\n",
    "criterion = torch.nn.MSELoss() \n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-4)\n",
    "\n",
    "mask_generator = Masking(mask_ratio=0.3) # Mask 30% of patches randomly \n",
    "\n",
    "for batch_x, batch_masks in tqdm(test_dataloader, total=len(test_dataloader)):\n",
    "    n_channels = batch_x.shape[1]\n",
    "    \n",
    "    # Reshape to [batch_size * n_channels, 1, window_size]\n",
    "    batch_x = batch_x.reshape((-1, 1, 512)) \n",
    "\n",
    "    print(f\"batch_x ~ {batch_x.shape}\")\n",
    "    \n",
    "    batch_masks = batch_masks.to(device).long()\n",
    "    batch_masks = batch_masks.repeat_interleave(n_channels, axis=0)\n",
    "\n",
    "    print(f\"batch_masks ~ {batch_masks.shape}\")\n",
    "    # Randomly mask some patches of data\n",
    "    mask = mask_generator.generate_mask(\n",
    "        x=batch_x, input_mask=batch_masks).to(device).long()\n",
    "\n",
    "    # Forward\n",
    "    output = model(x_enc=batch_x, input_mask=batch_masks, mask=mask) \n",
    "    \n",
    "    # Compute loss\n",
    "    recon_loss = criterion(output.reconstruction, original)\n",
    "    observed_mask = batch_masks * (1 - mask)\n",
    "    masked_loss = observed_mask * recon_loss\n",
    "    \n",
    "    loss = masked_loss.nansum() / (observed_mask.nansum() + 1e-7)\n",
    "    \n",
    "    print(f\"loss: {loss.item()}\")\n",
    "    \n",
    "    # Backward\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
