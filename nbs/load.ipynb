{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#| default_exp load"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load\n",
    "\n",
    "> Methods for loading data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#| export\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from fastcore.all import *\n",
    "import wandb\n",
    "from datetime import datetime, timedelta\n",
    "from dvats.imports import *\n",
    "from dvats.utils import *\n",
    "import pickle\n",
    "import pyarrow.feather as ft"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "from tsai.imports import beep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Path('/home/macu')"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "base_path = Path.home()\n",
    "base_path"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Time series artifacts (to be used with weights and biases)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This class is meant to extend `wandb.Artifact` for logging/using files with time series data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#| export\n",
    "class TSArtifact(wandb.Artifact):\n",
    "\n",
    "    default_storage_path = Path(Path.home()/'data/wandb_artifacts/')\n",
    "    date_format = '%Y-%m-%d %H:%M:%S' # TODO add milliseconds\n",
    "    handle_missing_values_techniques = {\n",
    "        'linear_interpolation': lambda df : df.interpolate(method='linear', limit_direction='both'),\n",
    "        'overall_mean': lambda df : df.fillna(df.mean()),\n",
    "        'overall_median': lambda df : df.fillna(df.median()),\n",
    "        'backward_fill' : lambda df : df.fillna(method='bfill'),\n",
    "        'forward_fill' : lambda df : df.fillna(method='ffill')\n",
    "    }\n",
    "\n",
    "    \"Class that represents a wandb artifact containing time series data. sd stands for start_date \\\n",
    "    and ed for end_date. Both should be pd.Timestamps\"\n",
    "\n",
    "    @delegates(wandb.Artifact.__init__)\n",
    "    def __init__(self, name, sd:pd.Timestamp, ed:pd.Timestamp, **kwargs):\n",
    "        super().__init__(type='dataset', name=name, **kwargs)\n",
    "        self.sd = sd\n",
    "        self.ed = ed\n",
    "        if self.metadata is None:\n",
    "            self.metadata = dict()\n",
    "        self.metadata['TS'] = dict(sd = self.sd.strftime(self.date_format),\n",
    "                                   ed = self.ed.strftime(self.date_format))\n",
    "\n",
    "\n",
    "    @classmethod\n",
    "    def from_daily_csv_files(\n",
    "        cls, \n",
    "        root_path, \n",
    "        fread     = pd.read_csv, \n",
    "        start_date= None, \n",
    "        end_date  = None, \n",
    "        metadata  = None, \n",
    "        **kwargs\n",
    "    ):\n",
    "\n",
    "        \"Create a wandb artifact of type `dataset`, containing the CSV files from `start_date` \\\n",
    "        to `end_date`. Dates must be pased as `datetime.datetime` objects. If a `wandb_run` is \\\n",
    "        defined, the created artifact will be logged to that run, using the longwall name as \\\n",
    "        artifact name, and the date range as version.\"\n",
    "\n",
    "        return None\n",
    "\n",
    "\n",
    "    @classmethod\n",
    "    @delegates(__init__)\n",
    "    def from_df(\n",
    "        cls, \n",
    "        df:pd.DataFrame, \n",
    "        name:str, \n",
    "        path:str=None, \n",
    "        sd:pd.Timestamp=None, \n",
    "        ed:pd.Timestamp=None,\n",
    "        normalize:bool=False, \n",
    "        missing_values_technique:str=None, \n",
    "        resampling_freq:str=None, \n",
    "        verbose:int = 0,\n",
    "        **kwargs,\n",
    "    ):\n",
    "\n",
    "        \"\"\"\n",
    "        Create a TSArtifact of type `dataset`, using the DataFrame `df` samples from \\\n",
    "        `sd` (start date) to `ed` (end date). Dates must be passed as `datetime.datetime` \\\n",
    "        objects. The transformed DataFrame is stored as a pickle file in the path `path` \\\n",
    "        and its reference is added to the artifact entries. Additionally, the dataset can \\\n",
    "        be normalized (see `normalize` argument) or transformed using missing values \\\n",
    "        handling techniques (see `missing_values_technique` argument) or resampling (see \\\n",
    "        `resampling_freq` argument).\n",
    "\n",
    "        Arguments:\n",
    "            df: (DataFrame) The dataframe you want to convert into an artifact.\n",
    "            name: (str) The artifact name.\n",
    "            path: (str, optional) The path where the file, containing the new transformed \\\n",
    "                dataframe, is saved. Default None.\n",
    "            sd: (sd, optional) Start date. By default, the first index of `df` is taken.\n",
    "            ed: (ed, optional) End date. By default, the last index of `df` is taken.\n",
    "            normalize: (bool, optional) If the dataset values should be normalized. Default\\\n",
    "                False.\n",
    "            missing_values_technique: (str, optional) The technique used to handle missing \\\n",
    "                values. Options: \"linear_iterpolation\", \"overall_mean\", \"overall_median\" or \\\n",
    "                None. Default None.\n",
    "            resampling_freq: (str, optional) The offset string or object representing \\\n",
    "                frequency conversion for time series resampling. Default None.\n",
    "\n",
    "        Returns:\n",
    "            TSArtifact object.\n",
    "        \"\"\"\n",
    "        sd = df.index[0] if sd is None else sd\n",
    "        ed = df.index[-1] if ed is None else ed\n",
    "        if (verbose > 1): print(f\"[ From df ] sd {sd}, ed {ed}\")\n",
    "        obj = cls(name, sd=sd, ed=ed, **kwargs)\n",
    "        df = df.query('@obj.sd <= index <= @obj.ed')\n",
    "        if (verbose > 1): print(f\"[ From df ] df_query~{df.shape}\")\n",
    "        obj.metadata['TS']['created'] = 'from-df'\n",
    "        obj.metadata['TS']['n_vars'] = df.columns.__len__()\n",
    "\n",
    "        # Handle Missing Values\n",
    "        df = obj.handle_missing_values_techniques[missing_values_technique](df) if missing_values_technique is not None else df\n",
    "        obj.metadata['TS']['handle_missing_values_technique'] = missing_values_technique.__str__()\n",
    "        obj.metadata['TS']['has_missing_values'] = np.any(df.isna().values).__str__()\n",
    "        if (verbose > 1): print(f\"[ From df ] df_missing~{df.shape}\")\n",
    "\n",
    "        # Indexing and Resampling\n",
    "        if resampling_freq: df = df.resample(resampling_freq).mean()\n",
    "        obj.metadata['TS']['n_samples'] = len(df)\n",
    "        obj.metadata['TS']['freq'] = str(df.index.freq)\n",
    "        if (verbose > 1): print(f\"[ From df ] df_resampled~{df.shape}\")\n",
    "\n",
    "        # Time Series Variables\n",
    "        obj.metadata['TS']['vars'] = list(df.columns)\n",
    "\n",
    "        # Normalization - Save the previous means and stds\n",
    "        if normalize:\n",
    "            obj.metadata['TS']['normalization'] = dict(means = df.describe().loc['mean'].to_dict(),\n",
    "                                                       stds = df.describe().loc['std'].to_dict())\n",
    "            df = normalize_columns(df)\n",
    "\n",
    "        # Hash and save\n",
    "        hash_code = str(pd.util.hash_pandas_object(df).sum()) # str(hash(df.values.tobytes()))\n",
    "        path = obj.default_storage_path/f'{hash_code}' if path is None else Path(path)/f'{hash_code}'\n",
    "        if verbose > 0: print(\"About to write df to \", path)\n",
    "        ft.write_feather(df, path, compression = 'lz4')\n",
    "        #feather.write_dataframe\n",
    "        obj.metadata['TS']['hash'] = hash_code\n",
    "        obj.add_file(str(path))\n",
    "\n",
    "        return obj"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "About to write df to  /home/macu/data/wandb_artifacts/-3933983096744628927\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/pandas/util/__init__.py:16: FutureWarning: pandas.util.testing is deprecated. Use the functions in the public API at pandas.testing instead.\n",
      "  import pandas.util.testing\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'TS': {'sd': '2021-01-01 00:00:00',\n",
       "  'ed': '2021-01-01 00:00:29',\n",
       "  'created': 'from-df',\n",
       "  'n_vars': 4,\n",
       "  'handle_missing_values_technique': 'overall_median',\n",
       "  'has_missing_values': 'False',\n",
       "  'n_samples': 6,\n",
       "  'freq': '<5 * Seconds>',\n",
       "  'vars': ['A', 'B', 'C', 'D'],\n",
       "  'normalization': {'means': {'A': 0.5793017637464674,\n",
       "    'B': -0.01435794152299131,\n",
       "    'C': 0.18652442067880057,\n",
       "    'D': 0.1774423121784866},\n",
       "   'stds': {'A': 0.24036713821726258,\n",
       "    'B': 0.33552092994088434,\n",
       "    'C': 0.24197909079207297,\n",
       "    'D': 0.33616659725660236}},\n",
       "  'hash': '-3933983096744628927'}}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# TSArtifact class TEST\n",
    "\n",
    "# resampling frequency\n",
    "resampling_freq = '5s'\n",
    "# handle missing values technique\n",
    "missing_values_technique='overall_median'\n",
    "\n",
    "# testing dataframe\n",
    "df_test = pd.util.testing.makeMissingDataframe()\n",
    "df_test.index = pd.date_range(start='2021-01-01', periods=len(df_test), freq='s')\n",
    "\n",
    "artifact = TSArtifact.from_df(df_test, \n",
    "                              name='JNK', \n",
    "                              missing_values_technique=missing_values_technique,\n",
    "                              resampling_freq=resampling_freq, \n",
    "                              normalize=True)\n",
    "artifact.metadata"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "../../data/wandb_artifacts/-3933983096744628927\n",
      "                            A         B         C         D\n",
      "2021-01-01 00:00:00  0.857944 -0.699607  1.212592 -1.179111\n",
      "2021-01-01 00:00:05  0.549631  0.408782  0.974450  0.972283\n",
      "2021-01-01 00:00:10 -1.941459 -0.160862 -0.534859  1.023989\n",
      "2021-01-01 00:00:15 -0.072018 -1.407364 -1.275477 -0.687901\n",
      "2021-01-01 00:00:20  0.346691  0.377773 -0.734337  0.688445\n",
      "2021-01-01 00:00:25  0.259210  1.481277  0.357630 -0.817704\n"
     ]
    }
   ],
   "source": [
    "hash = artifact.metadata['TS']['hash']\n",
    "path = \"../../data/wandb_artifacts/\"+hash\n",
    "print(path)\n",
    "f = ft.read_feather(path)\n",
    "print(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = ft.read_feather(\"/home/macu/data/wandb_artifacts/-2535364569820284064\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pandas.core.frame.DataFrame"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "At the end, we are interested in working with time series as a dataframe. So we need a function to download the files contained in a `wandb.apis.public.Artifact` object and process them into a TS dataframe. The process of passing from files to dataframe must be different depending on what type of creation method was used to generate the original `TSArtifact`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#| export\n",
    "@patch\n",
    "def to_df(self:wandb.apis.public.Artifact):\n",
    "    \"Download the files of a saved wandb artifact and process them as a single dataframe. The artifact must \\\n",
    "    come from a call to `run.use_artifact` with a proper wandb run.\"\n",
    "    # The way we have to ensure that the argument comes from a TS arfitact is the metadata\n",
    "    if self.metadata.get('TS') is None:\n",
    "        print(f'ERROR:{self} does not come from a logged TSArtifact')\n",
    "        return None\n",
    "    dir = Path(self.download())\n",
    "    if self.metadata['TS']['created'] == 'from-df':\n",
    "        # Call read_pickle with the single file from dir\n",
    "        #return pd.read_pickle(dir.ls()[0])\n",
    "        return ft.read_feather(dir.ls()[0])\n",
    "    else:\n",
    "        print(\"ERROR: Only from_df method is allowed yet\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For convenience, we can write a method to cast a downloaded wandb artifact (instance from `wandb.apis.public,Artifact`) to a TSArtifact"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "@patch\n",
    "def to_tsartifact(self:wandb.apis.public.Artifact):\n",
    "    \"Cast an artifact as a TS artifact. The artifact must have been created from one of the \\\n",
    "    class creation methods of the class `TSArtifact`. This is useful to go back to a TSArtifact \\\n",
    "    after downloading an artifact through the wand API\"\n",
    "    return TSArtifact(name=self.digest, #TODO change this\n",
    "                      sd=pd.to_datetime(self.metadata['TS']['sd'], format=TSArtifact.date_format),\n",
    "                      ed=pd.to_datetime(self.metadata['TS']['sd'], format=TSArtifact.date_format),\n",
    "                      description=self.description,\n",
    "                      metadata=self.metadata)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Inject or infer frequencies in a dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "@delegates(pd.to_datetime)\n",
    "def infer_or_inject_freq(df, injected_freq='1s', start_date=None, verbose = 0, **kwargs):\n",
    "    \"\"\"\n",
    "        Infer index frequency. If there's not a proper time index, create fake timestamps,\n",
    "        keeping the desired `injected_freq`. If that is None, set a default one of 1 second.\n",
    "        start_date: the first date of the index (int or string).\n",
    "    \"\"\"\n",
    "    inferred_freq = pd.infer_freq(df.index)\n",
    "    if inferred_freq == 'N':\n",
    "        if injected_freq.endswith('mo'):\n",
    "            months = int(injected_freq[:-2])\n",
    "            freq = f'{months}M'\n",
    "            if verbose > 1: print(f\"df~{df.shape} | freq {freq}\")\n",
    "            start_date = pd.to_datetime(ifnone(start_date, df.index[0]))\n",
    "            new_index = pd.date_range(start=start_date, periods=len(df), freq=freq)\n",
    "            df.index = new_index\n",
    "            if verbose > 1: print(df.shape)\n",
    "            df.index.freq = pd.infer_freq(df.index)\n",
    "        else:\n",
    "            try:\n",
    "                timedelta = pd.to_timedelta(injected_freq)\n",
    "                df.index = pd.to_datetime(ifnone(start_date, 0), **kwargs) + timedelta*df.index\n",
    "                df.index.freq = pd.infer_freq(df.index)\n",
    "            except Exception as e: \n",
    "                print(f\"Infer/Inject freq retry. Error: {e}\")\n",
    "                timedelta = pd.to_timedelta(injected_freq)\n",
    "                start_date = pd.to_datetime(ifnone(start_date, df.index[0]), **kwargs)\n",
    "                new_index = pd.date_range(\n",
    "                    start = start_date, periods = len(df), \n",
    "                    freq = timedelta)\n",
    "                df.index = new_index\n",
    "                df.index.freq = pd.infer_freq(df.index)\n",
    "    else:\n",
    "        df.index.freq = inferred_freq\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(                     0\n",
       " 1970-01-01 00:00:00  1\n",
       " 1970-01-01 00:00:01  2\n",
       " 1970-01-01 00:00:02  3,\n",
       "                      0\n",
       " 1970-01-01 00:00:00  1\n",
       " 1970-01-01 00:00:02  2\n",
       " 1970-01-01 00:00:04  3)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#| hide\n",
    "foo = pd.DataFrame([1, 2, 3])\n",
    "bar = pd.DataFrame([1, 2, 3])\n",
    "foo = infer_or_inject_freq(foo)\n",
    "bar = infer_or_inject_freq(bar, injected_freq='2s')\n",
    "test_eq(foo.index.freq, '1s')\n",
    "test_eq(bar.index.freq, '2s')\n",
    "foo, bar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide \n",
    "foo = pd.DataFrame([1, 2, 3])\n",
    "bar = infer_or_inject_freq(foo, injected_freq='1W', start_date='01/01/2020')\n",
    "baz = infer_or_inject_freq(foo, injected_freq='1W', start_date='2020-01-01', format = '%Y-%m-%d')\n",
    "test_eq(bar, baz)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#| export\n",
    "import requests\n",
    "import zipfile\n",
    "from pathlib import Path\n",
    "\n",
    "def get_confirm_token(response):\n",
    "    for key, value in response.cookies.items():\n",
    "        if key.startswith('download_warning'):\n",
    "            return value\n",
    "    return None\n",
    "\n",
    "def save_response_content(response, destination):\n",
    "    with open(destination, \"wb\") as f:\n",
    "        for chunk in response.iter_content(chunk_size=32768):\n",
    "            if chunk:  # filter out keep-alive new chunks\n",
    "                f.write(chunk)\n",
    "\n",
    "def download_file_from_google_drive(id, destination):\n",
    "    URL = \"https://docs.google.com/uc?export=download\"\n",
    "\n",
    "    session = requests.Session()\n",
    "    response = session.get(URL, params={'id': id}, stream=True)\n",
    "    token = get_confirm_token(response)\n",
    "\n",
    "    if token:\n",
    "        params = {'id': id, 'confirm': token}\n",
    "        response = session.get(URL, params=params, stream=True)\n",
    "\n",
    "    # Check if the file is HTML (incorrect download)\n",
    "    if 'text/html' in response.headers['Content-Type']:\n",
    "        print(\"Failed to download the zip file. The link may require additional permissions or the ID may be incorrect.\")\n",
    "    else:\n",
    "        save_response_content(response, destination)\n",
    "        print(f\"File downloaded as: {destination}\")\n",
    "\n",
    "def zip_contents(zip_path):\n",
    "    with zipfile.ZipFile(zip_path, 'r') as zip_file:\n",
    "        return zip_file.namelist()\n",
    "\n",
    "\n",
    "def unzip_mat(all_one, zip_path, extract_path, case = '', verbose = 0):\n",
    "    if verbose > 0: print(\"--> Unzip_mat\", all_one, zip_path, extract_path, case, verbose)\n",
    "    with zipfile.ZipFile(zip_path, 'r') as zip_ref:\n",
    "        mat_files = [file for file in zip_ref.namelist() if file.endswith('.mat') and not file.startswith('__MACOSX/')]\n",
    "        if verbose > 0: print(mat_files)\n",
    "        if all_one == \"all\":\n",
    "            # Extract\n",
    "            for file in mat_files:\n",
    "                zip_ref.extract(file, extract_path)\n",
    "            return f\"{mat_files} extracted to {extract_path}\"\n",
    "        \n",
    "        elif all_one == \"one\":\n",
    "            if case == \"\":\n",
    "                # Extract first .mat\n",
    "                zip_ref.extract(mat_files[0], extract_path)\n",
    "                return f\"{mat_files[0]} extracted to  {extract_path}\"\n",
    "            else:\n",
    "                # Extract <case>.mat\n",
    "                mat_file = next((file for file in mat_files if case in file), None)\n",
    "                if mat_file:\n",
    "                    zip_ref.extract(mat_file, extract_path)\n",
    "                    return f\"{mat_file} extracted to {extract_path}\"\n",
    "                else:\n",
    "                    return \"None \"+case+\".mat found.\"\n",
    "        else:\n",
    "            return \"First parameter must be 'all' or 'one'.\"\n",
    "        if verbose > 0: print(\"unzip_path -->\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "200.0"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "3000/15"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data: /home/macu/data, destination: /home/macu/data/exoDataFig1.zip\n",
      "Failed to download the zip file. The link may require additional permissions or the ID may be incorrect.\n"
     ]
    }
   ],
   "source": [
    "file_id = '1Li9D5YyspA6eQtpGRihOi0y9D85cq4GE'\n",
    "name = 'exoDataFig1'\n",
    "data_path = os.path.expanduser('~/data')\n",
    "destination = os.path.join(data_path, name + '.zip')\n",
    "print(f\"Data: {data_path}, destination: {destination}\")\n",
    "download_file_from_google_drive(file_id, destination)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File downloaded as: /home/macu/data/InsectData-fig11.zip\n",
      "--> Unzip_mat all /home/macu/data/InsectData-fig11.zip /home/macu/data  True\n",
      "['Insect_one_million.mat']\n",
      "['Insect_one_million.mat'] extracted to /home/macu/data\n",
      "--> Unzip_mat one /home/macu/data/InsectData-fig11.zip /home/macu/data  True\n",
      "['Insect_one_million.mat']\n",
      "Insect_one_million.mat extracted to  /home/macu/data\n",
      "--> Unzip_mat one /home/macu/data/InsectData-fig11.zip /home/macu/data Insect_one_million True\n",
      "['Insect_one_million.mat']\n",
      "Insect_one_million.mat extracted to /home/macu/data\n",
      "--> Unzip_mat one /home/macu/data/InsectData-fig11.zip /home/macu/data Insect_one_millione True\n",
      "['Insect_one_million.mat']\n",
      "None Insect_one_millione.mat found.\n"
     ]
    }
   ],
   "source": [
    "#| hide\n",
    "# Downloading insects (by Eamonn Keogh)\n",
    "file_id = '1qq1z2mVRd7PzDqX0TDAwY7BcWVjnXUfQ'\n",
    "data_path = os.path.expanduser('~/data')\n",
    "destination = os.path.join(data_path, 'InsectData-fig11.zip')\n",
    "\n",
    "# Llamada a la función\n",
    "download_file_from_google_drive(file_id, destination)\n",
    "zip_contents(destination)\n",
    "print(unzip_mat('all', destination,  data_path))\n",
    "print(unzip_mat('one', destination,  data_path))\n",
    "print(unzip_mat('one', destination,  data_path, 'Insect_one_million'))\n",
    "print(unzip_mat('one', destination,  data_path, 'Insect_one_millione'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#| export\n",
    "import scipy.io\n",
    "import pandas as pd\n",
    "\n",
    "def mat2csv(mat_file_path, csv_file_folder = '~/data/', verbose = 0):\n",
    "    # Carga el archivo .mat, omitiendo las variables meta de MATLAB\n",
    "    mat = scipy.io.loadmat(mat_file_path, squeeze_me=True, struct_as_record=False)\n",
    "    \n",
    "    # Itera sobre todas las variables encontradas en el archivo .mat\n",
    "    for variable_name, data in mat.items():\n",
    "        if variable_name.startswith('__') or isinstance(data, scipy.io.matlab.mio5_params.mat_struct):\n",
    "            # Omite variables meta de MATLAB o estructuras (que requieren un manejo especial)\n",
    "            continue\n",
    "        \n",
    "        # Convierte la data a un DataFrame de pandas, manejando diferentes tipos de datos\n",
    "        if isinstance(data, np.ndarray):\n",
    "            if data.dtype.names:  # Es un ndarray estructurado\n",
    "                data_df = pd.DataFrame(data)\n",
    "            else:  # Es un ndarray regular\n",
    "                data_df = pd.DataFrame(data, columns=[variable_name])\n",
    "        else:\n",
    "            # Para otros tipos de datos, los convertimos en un DataFrame simple\n",
    "            data_df = pd.DataFrame([data], columns=[variable_name])\n",
    "        \n",
    "        # Define la ruta del archivo .csv de salida\n",
    "        csv_file_path = csv_file_folder+ variable_name + '.csv'\n",
    "        \n",
    "        # Guarda el DataFrame como un archivo .csv\n",
    "        data_df.to_csv(csv_file_path, index=False)\n",
    "        if verbose > 0:\n",
    "            print(data_df.shape)\n",
    "            display(data_df.head(5))\n",
    "            print(f\"Matlab matrix '{variable_name}' converted to CSV in: {csv_file_path}\")\n",
    "        return data_df\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(109842, 1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_12359/919120205.py:11: DeprecationWarning: Please import `mat_struct` from the `scipy.io.matlab` namespace; the `scipy.io.matlab.mio5_params` namespace is deprecated and will be removed in SciPy 2.0.0.\n",
      "  if variable_name.startswith('__') or isinstance(data, scipy.io.matlab.mio5_params.mat_struct):\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>penguin_sample</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.253906</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.259033</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.269287</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.271240</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.265137</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   penguin_sample\n",
       "0        0.253906\n",
       "1        0.259033\n",
       "2        0.269287\n",
       "3        0.271240\n",
       "4        0.265137"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Matlab matrix 'penguin_sample' converted to CSV in: ~/data/penguin_sample.csv\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>penguin_sample</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.253906</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.259033</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.269287</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.271240</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.265137</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>109837</th>\n",
       "      <td>0.070312</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>109838</th>\n",
       "      <td>0.053955</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>109839</th>\n",
       "      <td>0.055908</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>109840</th>\n",
       "      <td>0.064209</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>109841</th>\n",
       "      <td>0.059082</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>109842 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        penguin_sample\n",
       "0             0.253906\n",
       "1             0.259033\n",
       "2             0.269287\n",
       "3             0.271240\n",
       "4             0.265137\n",
       "...                ...\n",
       "109837        0.070312\n",
       "109838        0.053955\n",
       "109839        0.055908\n",
       "109840        0.064209\n",
       "109841        0.059082\n",
       "\n",
       "[109842 rows x 1 columns]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#| hide\n",
    "path = '/home/macu/data/MP_first_test_penguin_sample.mat'\n",
    "mat2csv(path, verbose = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_12359/919120205.py:11: DeprecationWarning: Please import `mat_struct` from the `scipy.io.matlab` namespace; the `scipy.io.matlab.mio5_params` namespace is deprecated and will be removed in SciPy 2.0.0.\n",
      "  if variable_name.startswith('__') or isinstance(data, scipy.io.matlab.mio5_params.mat_struct):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1000000, 1)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Insect_one_million</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.236820</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.236820</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.238040</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.206300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.026855</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Insect_one_million\n",
       "0            0.236820\n",
       "1            0.236820\n",
       "2            0.238040\n",
       "3            0.206300\n",
       "4            0.026855"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Matlab matrix 'Insect_one_million' converted to CSV in: ~/data/Insect_one_million.csv\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Insect_one_million</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.236820</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.236820</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.238040</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.206300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.026855</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>999995</th>\n",
       "      <td>0.014648</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>999996</th>\n",
       "      <td>0.030518</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>999997</th>\n",
       "      <td>0.034180</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>999998</th>\n",
       "      <td>0.013428</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>999999</th>\n",
       "      <td>-0.053711</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1000000 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        Insect_one_million\n",
       "0                 0.236820\n",
       "1                 0.236820\n",
       "2                 0.238040\n",
       "3                 0.206300\n",
       "4                 0.026855\n",
       "...                    ...\n",
       "999995            0.014648\n",
       "999996            0.030518\n",
       "999997            0.034180\n",
       "999998            0.013428\n",
       "999999           -0.053711\n",
       "\n",
       "[1000000 rows x 1 columns]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#| hide\n",
    "path = '/home/macu/data/Insect_one_million.mat'\n",
    "mat2csv(path, verbose = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "import requests\n",
    "import zipfile\n",
    "from pathlib import Path\n",
    "\n",
    "def get_confirm_token(response):\n",
    "    for key, value in response.cookies.items():\n",
    "        if key.startswith('download_warning'):\n",
    "            return value\n",
    "    return None\n",
    "\n",
    "def save_response_content(response, destination):\n",
    "    with open(destination, \"wb\") as f:\n",
    "        for chunk in response.iter_content(chunk_size=32768):\n",
    "            if chunk:  # filter out keep-alive new chunks\n",
    "                f.write(chunk)\n",
    "\n",
    "def download_file_from_google_drive(id, destination):\n",
    "    URL = \"https://docs.google.com/uc?export=download\"\n",
    "\n",
    "    session = requests.Session()\n",
    "    response = session.get(URL, params={'id': id}, stream=True)\n",
    "    token = get_confirm_token(response)\n",
    "\n",
    "    if token:\n",
    "        params = {'id': id, 'confirm': token}\n",
    "        response = session.get(URL, params=params, stream=True)\n",
    "\n",
    "    # Check if the file is HTML (incorrect download)\n",
    "    if 'text/html' in response.headers['Content-Type']:\n",
    "        print(\"Failed to download the zip file. The link may require additional permissions or the ID may be incorrect.\")\n",
    "    else:\n",
    "        save_response_content(response, destination)\n",
    "        print(f\"File downloaded as: {destination}\")\n",
    "\n",
    "def zip_contents(zip_path):\n",
    "    with zipfile.ZipFile(zip_path, 'r') as zip_file:\n",
    "        return zip_file.namelist()\n",
    "\n",
    "\n",
    "def unzip_mat(all_one, zip_path, extract_path, case = '', verbose = 0):\n",
    "    if verbose > 0: print(\"--> Unzip_mat\", all_one, zip_path, extract_path, case, verbose)\n",
    "    with zipfile.ZipFile(zip_path, 'r') as zip_ref:\n",
    "        mat_files = [file for file in zip_ref.namelist() if file.endswith('.mat') and not file.startswith('__MACOSX/')]\n",
    "        if verbose > 0: print(mat_files)\n",
    "        if all_one == \"all\":\n",
    "            # Extract\n",
    "            for file in mat_files:\n",
    "                zip_ref.extract(file, extract_path)\n",
    "            return f\"{mat_files} extracted to {extract_path}\"\n",
    "        \n",
    "        elif all_one == \"one\":\n",
    "            if case == \"\":\n",
    "                # Extract first .mat\n",
    "                zip_ref.extract(mat_files[0], extract_path)\n",
    "                return f\"{mat_files[0]} extracted to  {extract_path}\"\n",
    "            else:\n",
    "                # Extract <case>.mat\n",
    "                mat_file = next((file for file in mat_files if case in file), None)\n",
    "                if mat_file:\n",
    "                    zip_ref.extract(mat_file, extract_path)\n",
    "                    return f\"{mat_file} extracted to {extract_path}\"\n",
    "                else:\n",
    "                    return \"None \"+case+\".mat found.\"\n",
    "        else:\n",
    "            return \"First parameter must be 'all' or 'one'.\"\n",
    "        if verbose > 0: print(\"unzip_path -->\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "200.0"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "3000/15"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data: /home/macu/data, destination: /home/macu/data/exoDataFig1.zip\n",
      "Failed to download the zip file. The link may require additional permissions or the ID may be incorrect.\n"
     ]
    }
   ],
   "source": [
    "file_id = '1Li9D5YyspA6eQtpGRihOi0y9D85cq4GE'\n",
    "name = 'exoDataFig1'\n",
    "data_path = os.path.expanduser('~/data')\n",
    "destination = os.path.join(data_path, name + '.zip')\n",
    "print(f\"Data: {data_path}, destination: {destination}\")\n",
    "download_file_from_google_drive(file_id, destination)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "# Downloading insects (by Eamonn Keogh)\n",
    "file_id = '1qq1z2mVRd7PzDqX0TDAwY7BcWVjnXUfQ'\n",
    "data_path = os.path.expanduser('~/data')\n",
    "destination = os.path.join(data_path, 'InsectData-fig11.zip')\n",
    "\n",
    "# Llamada a la función\n",
    "download_file_from_google_drive(file_id, destination)\n",
    "zip_contents(destination)\n",
    "print(unzip_mat('all', destination,  data_path))\n",
    "print(unzip_mat('one', destination,  data_path))\n",
    "print(unzip_mat('one', destination,  data_path, 'Insect_one_million'))\n",
    "print(unzip_mat('one', destination,  data_path, 'Insect_one_millione'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "                <audio  controls=\"controls\" autoplay=\"autoplay\">\n",
       "                    <source src=\"data:audio/wav;base64,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\" type=\"audio/wav\" />\n",
       "                    Your browser does not support the audio element.\n",
       "                </audio>\n",
       "              "
      ],
      "text/plain": [
       "<IPython.lib.display.Audio object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#| hide\n",
    "#from nbdev.export import *\n",
    "#notebook2script()\n",
    "beep(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
