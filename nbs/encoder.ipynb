{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0e6a4a02-5015-4a3e-9a64-6089de4e9532",
   "metadata": {},
   "source": [
    "# Encoder\n",
    "\n",
    "> Architectures and functions for creating encoders that create the embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "b014a18f-8538-4ed7-98ee-ddb165692553",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#export\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from fastcore.all import *\n",
    "from tsai.callback.MVP import *\n",
    "from tsai.imports import *\n",
    "from tsai.models.InceptionTimePlus import InceptionTimePlus\n",
    "from tsai.models.explainability import get_acts_and_grads\n",
    "from tsai.models.layers import *\n",
    "from tsai.data.validation import combine_split_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "33c94f65",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#hide\n",
    "from tsai.all import *"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04637a46",
   "metadata": {},
   "source": [
    "### Architectures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "c036898b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#export \n",
    "class DCAE_torch(Module):\n",
    "    def __init__(self, c_in, seq_len, delta, nfs=[64, 32, 12], kss=[10, 5, 5],\n",
    "                 pool_szs=[2,2,3], output_fsz=10):\n",
    "        \"\"\"\n",
    "        Create a Deep Convolutional Autoencoder for multivariate time series of `d` dimensions,\n",
    "        sliced with a window size of `w`. The parameter `delta` sets the number of latent features that will be\n",
    "        contained in the Dense layer of the network. The the number of features\n",
    "        maps (filters), the filter size and the pool size can also be adjusted.\"\n",
    "        \"\"\"\n",
    "        assert all_equal([len(x) for x in [nfs, kss, pool_szs]], np.repeat(len(nfs), 3)), \\\n",
    "            'nfs, kss, and pool_szs must have the same length'\n",
    "        assert np.prod(pool_szs) == nfs[-1], \\\n",
    "            'The number of filters in the last conv layer must be equal to the product of pool sizes'\n",
    "        assert seq_len % np.prod(pool_szs) == 0, \\\n",
    "            'The product of pool sizes must be a divisor of the window size'\n",
    "        layers = []\n",
    "        for i in range_of(kss):\n",
    "            layers += [Conv1d(ni=nfs[i-1] if i>0 else c_in, nf=nfs[i], ks=kss[i]),\n",
    "                       nn.MaxPool1d(kernel_size=pool_szs[i])]\n",
    "        self.downsample = nn.Sequential(*layers)\n",
    "        self.bottleneck = nn.Sequential(OrderedDict([\n",
    "            ('flatten', nn.Flatten()),\n",
    "            ('latent_in', nn.Linear(seq_len, delta)),\n",
    "            ('latent_out', nn.Linear(delta, seq_len)),\n",
    "            ('reshape', Reshape(nfs[-1], seq_len // np.prod(pool_szs)))\n",
    "        ]))\n",
    "        layers = []\n",
    "        for i in reversed(range_of(kss)):\n",
    "            layers += [Conv1d(ni=nfs[i+1] if i != (len(nfs)-1) else nfs[-1],\n",
    "                              nf=nfs[i], ks=kss[i]),\n",
    "                       nn.Upsample(scale_factor=pool_szs[i])]\n",
    "        layers += [Conv1d(ni=nfs[0], nf=c_in, kernel_size=output_fsz)]\n",
    "        self.upsample = nn.Sequential(*layers)\n",
    "\n",
    "\n",
    "    def forward(self, x):\n",
    "        print(x)\n",
    "        x = self.downsample(x)\n",
    "        x = self.bottleneck(x)\n",
    "        x = self.upsample(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "3d14bd46",
   "metadata": {},
   "outputs": [],
   "source": [
    "#export \n",
    "from nbs.orelm.utils import *\n",
    "from nbs.orelm.foselm_torch import *\n",
    "from nbs.orelm.linear_recurrent import *\n",
    "import nbs.orelm.elm_torch as elm\n",
    "import nbs.orelm.mse_loss_i as mse\n",
    "class ORELM_torch(elm.ELM_torch):\n",
    "    def valid_parameters(self, inputs, outputs, numHiddenNeurons, activationFunction, LN,AE, ORTH, inputWeightForgettingFactor, outputWeightForgettingFactor, seq_len):\n",
    "        assert isinstance(inputs, (int, float)) and inputs >= 1, \\\n",
    "          'inputs must be numeric and greater than or equal to 1'\n",
    "        assert isinstance(outputs, (int, float)) and outputs >= 1, \\\n",
    "          'outputs must be numeric and greater than or equal to 1'\n",
    "        assert isinstance(numHiddenNeurons, (int, float)) and numHiddenNeurons >= 1, \\\n",
    "          'numHiddenNeurons must be numeric and greater than or equal to 1'\n",
    "        assert isinstance(ORTH, bool), \\\n",
    "          'orth must be a logical value'\n",
    "        assert isinstance(inputWeightForgettingFactor, (int, float)) and 0 < inputWeightForgettingFactor <= 1, \\\n",
    "          'inputWeightForgettingFactor must be numeric between 0 and 1'\n",
    "        assert isinstance(outputWeightForgettingFactor, (int, float)) and 0 < outputWeightForgettingFactor <= 1, \\\n",
    "          'outputWeightForgettingFactor must be numeric between 0 and 1'\n",
    "        assert seq_len > 0, \\\n",
    "            'Sequence len (seq_len) must be bigger than 0'\n",
    "\n",
    "    def __init__(\n",
    "        self, \n",
    "        inputs, \n",
    "        outputs, \n",
    "        numHiddenNeurons, \n",
    "        activationFunction = \"sig\", #? Must always be \"sig\"\n",
    "        LN    = True,  #? - Layer normalization boolean\n",
    "        AE    = True,  #? - Para Alaiñe, siempre es True\n",
    "        ORTH  = True, \n",
    "        inputWeightForgettingFactor   = 0.999,\n",
    "        outputWeightForgettingFactor  = 0.999,\n",
    "        seq_len = 1,\n",
    "    ): \n",
    "        super().__init__(inputs, outputs, numHiddenNeurons)\n",
    "        self.valid_parameters(inputs, outputs, numHiddenNeurons, activationFunction, LN,AE, ORTH, inputWeightForgettingFactor, outputWeightForgettingFactor, seq_len)\n",
    "        print(\"inputs: \" + str(inputs))\n",
    "        print(\"outputs: \" + str(outputs))\n",
    "        print(\"numNeurons: \" + str(numHiddenNeurons))\n",
    "        print(\"Out weight FF: \" + str(outputWeightForgettingFactor))\n",
    "        print(\"Window size: \" + str(seq_len))\n",
    "        \n",
    "        self.initialized = 0\n",
    "        \n",
    "        self.activationFunction = activationFunction #?\n",
    "        self.outputs            = outputs\n",
    "        self.numHiddenNeurons   = numHiddenNeurons\n",
    "        self.inputs             = inputs\n",
    "        self.window_size        = seq_len\n",
    "\n",
    "        # input to hidden weights\n",
    "        print(\"(\"+str(self.numHiddenNeurons) +\", \"+ str(self.inputs)+\")\")\n",
    "        self.get_random_InputWeights()\n",
    "        # hidden layer to hidden layer wieghts\n",
    "        self.get_random_HiddenWeights()\n",
    "    \n",
    "        # initial hidden layer activation\n",
    "        self.initial_H  = self.get_random_matrix(1, self.numHiddenNeurons) * 2 - 1\n",
    "        self.H          = self.initial_H\n",
    "        \n",
    "        print(\"orelm-H ~ \", self.H.shape)\n",
    "        self.LN         = LN #?\n",
    "        self.AE         = AE #? \n",
    "        self.ORTH       = ORTH\n",
    "        \n",
    "        # bias of hidden units\n",
    "        self.get_random_Bias()\n",
    "        # hidden to output layer connection\n",
    "        self.beta = self.get_random_matrix(self.numHiddenNeurons, self.outputs)\n",
    "        \n",
    "        # auxiliary matrix used for sequential learning\n",
    "        self.M = torch.inverse(0.00001 * torch.eye(self.numHiddenNeurons)) #eye: diagonal, inv: inverse\n",
    "        \n",
    "        self.forgettingFactor       = outputWeightForgettingFactor\n",
    "        self.inputForgettingFactor  = inputWeightForgettingFactor\n",
    "\n",
    "        self.trace      = 0\n",
    "        self.thresReset = 0.001\n",
    "        print(\"-------- num_inputs, window_size = \" + str(self.inputs) + \",\" + str(self.window_size))\n",
    "\n",
    "        if self.AE: #En OTSAD -> directamente FOSELM\n",
    "            self.inputAE = FOSELM_torch(\n",
    "                inputs              = inputs,\n",
    "                outputs             = inputs,\n",
    "                numHiddenNeurons    = numHiddenNeurons,\n",
    "                activationFunction  = activationFunction, #?\n",
    "                LN                  = LN, #?\n",
    "                forgettingFactor    = inputWeightForgettingFactor,\n",
    "                ORTH = ORTH,\n",
    "                seq_len = self.window_size\n",
    "            )\n",
    "\n",
    "            print(\"input FOSELM model\", self.inputAE)\n",
    "            print(\"input, output\" ,self.inputAE.inputs, self.inputAE.outputs)\n",
    "\n",
    "            \n",
    "            self.hiddenAE = FOSELM_torch(\n",
    "                inputs              = numHiddenNeurons,\n",
    "                outputs             = numHiddenNeurons,\n",
    "                numHiddenNeurons    = numHiddenNeurons,\n",
    "                activationFunction  = activationFunction,#?\n",
    "                LN                  = LN,\n",
    "                ORTH                = ORTH,\n",
    "                seq_len             = self.window_size\n",
    "            )\n",
    "\n",
    "            print(\"Output FOSELM model\", self.hiddenAE)\n",
    "            print(\"input, output\", self.hiddenAE.inputs, self.hiddenAE.outputs)\n",
    "        \n",
    "    def __calculateInputWeightsUsingAE(self, features):\n",
    "        print(\"--> Input AE\")\n",
    "        self.inputAE.train_func(features=features,targets=features)\n",
    "        print(\"Input AE -->\")\n",
    "        return self.inputAE.beta\n",
    "\n",
    "    def __calculateHiddenWeightsUsingAE(self, features):\n",
    "        print(\"--> Hidden AE\")\n",
    "        self.hiddenAE.train_func(features=features,targets=features)\n",
    "        print(\"Hidden AE -->\")\n",
    "        return self.hiddenAE.beta\n",
    "    \n",
    "    def calculateHiddenLayerActivation(self, features, flag_debug=0):\n",
    "        \"\"\"\n",
    "        Calculate activation level of the hidden layer\n",
    "        :param features feature matrix with dimension (numSamples, numInputs) #Aqui se añade numWindows\n",
    "        :return: activation level (numSamples, numHiddenNeurons)\n",
    "        \"\"\"\n",
    "        #? Este paso lo quita Alaiñe... porque sólo está implementada la opción de \"sig\"\n",
    "        if self.activationFunction == \"sig\": \n",
    "            if self.AE:\n",
    "                self.inputWeights = self.__calculateInputWeightsUsingAE(features)\n",
    "                print(\"Features ~ \", features.shape)\n",
    "                num_samples = features.shape[0]\n",
    "                self.H = torch.zeros(num_samples, self.numHiddenNeurons, self.numHiddenNeurons)\n",
    "                for i in range(num_samples):\n",
    "                    self.H[i]  = self.get_random_matrix(1, self.numHiddenNeurons) * 2 - 1\n",
    "                print(\"orelm-H ~ \", self.H.shape)\n",
    "                self.hiddenWeights = self.__calculateHiddenWeightsUsingAE(self.H)\n",
    "            self.fprint(\"Before LR \" + str(flag_debug) + \": \" + str(features.shape), self.print_flag)\n",
    "            #Linear recurrent RNN layer setup\n",
    "            hidden_size = self.numHiddenNeurons     \n",
    "            input_size  = hidden_size #self.inputs \n",
    "            numLayers   =1                  #Num Linear Recurrent layers\n",
    "            batch_size = features.shape[0]  #numSamples\n",
    "            #Create layer\n",
    "            self.fprint(\"Create layer\", self.print_flag)\n",
    "            lr_layer  = nn.RNN(input_size,hidden_size,numLayers,bias=True, batch_first=True)\n",
    "            #Setup bias matrices\n",
    "            self.fprint(\"Setup bias\", self.print_flag)\n",
    "            lr_layer.bias_ih_l0 = nn.Parameter(self.bias)\n",
    "            lr_layer.bias_hh_l0 = nn.Parameter(self.bias)\n",
    "            #Create tensor for initial hiddenState\n",
    "            #lr_initial_hidden_state = torch.zeros(numLayers, batch_size, self.numHiddenNeurons)  \n",
    "            lr_initial_hidden_state = torch.zeros(numLayers, batch_size, features.shape[2])  \n",
    "            self.fprint(\"Apply LR layer\", self.print_flag)\n",
    "            self.fprint(\"features ~ \" + str(features.shape), self.print_flag)\n",
    "            self.fprint(\"Lr initial hidden state ~ \" + str(lr_initial_hidden_state.shape), self.print_flag)\n",
    "            lr_output, lr_new_hidden_state = lr_layer(features, lr_initial_hidden_state)\n",
    "            #lr_layer = linear_recurrent(features    = features,inputW      = self.inputWeights,hiddenW     = self.hiddenWeights, hiddenA     = self.H, bias        = self.bias)\n",
    "            #Layer normalization\n",
    "            if self.LN: #? -> Aqui es siempre true para Alaiñe\n",
    "                #Batch normalization\n",
    "                self.fprint(\"ORELM: Create normalization layer\", self.print_flag)\n",
    "                ln_layer  = self.get_ln_layer(lr_output)\n",
    "                self.fprint(\"ORELM: Normalize lr output\", self.print_flag)\n",
    "                lr_output = ln_layer(lr_output)\n",
    "            #Layer activation\n",
    "            self.fprint(\"Get hidden layer activation\", self.print_flag)\n",
    "            self.H = torch.sigmoid(lr_output)\n",
    "            print(\"orelm-H ~ \", self.H.shape)\n",
    "        else:\n",
    "            print (\"Unknown activation function type: \" + self.activationFunction )\n",
    "            raise NotImplementedError\n",
    "        print(\"ORELM: calculate hidden layer activation \"+str(flag_debug)+\" -->\")\n",
    "        return self.H\n",
    "    \n",
    "    def initializePhase(self, lamb=0.0001):\n",
    "        \"\"\"\n",
    "        Step 1: Initialization phase\n",
    "        :param features feature matrix with dimension (numSamples, numInputs)\n",
    "        :param targets target matrix with dimension (numSamples, numOutputs)\n",
    "        \"\"\"\n",
    "\n",
    "        if self.activationFunction == \"sig\":\n",
    "            self.get_random_Bias()\n",
    "        else:\n",
    "            print (\" Unknown activation function type: \" + self.activationFunction)\n",
    "            raise NotImplementedError   \n",
    "    \n",
    "        self.M      = torch.inverse(lamb*torch.eye(self.numHiddenNeurons))\n",
    "        self.beta   = torch.zeros([self.numHiddenNeurons,self.outputs])\n",
    "        \n",
    "        # randomly initialize the input->hidden connections\n",
    "        self.get_random_InputWeights()\n",
    "        self.inputWeights = self.inputWeights * 2 - 1\n",
    "        print(\"--> Initialize_Phase: Input Weights initialized. Shape: \"+ str(self.inputWeights.shape)) #? \n",
    "        if self.AE:\n",
    "            self.inputAE.initializePhase(lamb=0.00001)\n",
    "            self.hiddenAE.initializePhase(lamb=0.00001)\n",
    "        else:\n",
    "            # randomly initialize the input->hidden connections\n",
    "            self.get_random_InputWeights()\n",
    "            self.inputWeights = self.inputWeights*2-1\n",
    "        # ... ? Esta parte no está en Alaiñe\n",
    "        if self.ORTH: \n",
    "            if self.numHiddenNeurons > self.inputs:\n",
    "                self.inputWeights = orthogonalization(self.inputWeights)\n",
    "        else:\n",
    "            self.inputWeights = orthogonalization(self.inputWeights.t())\n",
    "            self.inputWeights = self.inputWeights.t()\n",
    "        # hidden layer to hidden layer weights\n",
    "        self.get_random_HiddenWeights()\n",
    "        self.hiddenWeights = self.hiddenWeights *2-1\n",
    "        if self.ORTH:\n",
    "            self.hiddenWeights = orthogonalization(self.hiddenWeights)\n",
    "        #? ...\n",
    "    def reset(self):#?\n",
    "        self.H = self.initial_H\n",
    "    \n",
    "\n",
    "    \n",
    "    def train_func(self, features, targets,RESETTING=False):\n",
    "        \"\"\"\n",
    "        Step 2: Sequential learning phase\n",
    "        :param features feature matrix with dimension (numSamples, numInputs)\n",
    "        :param targets target matrix with dimension (numSamples, numOutputs)\n",
    "        \"\"\"\n",
    "        sys.stdout.flush()\n",
    "        (numSamples, numOutputs) = targets.shape\n",
    "        (numWeights, _) = features.shape\n",
    "        print(\"ORELM:TRAIN:samples = weights: \" +  str(numSamples) + \" | outputs: \" + str(numOutputs))\n",
    "        print(\"ORELM:TRAIN:Features shape: \" + str(features.shape) + \"=> Columns: \" + str(features.shape[0]))\n",
    "        print(\"ORELM:TRAIN:Weights number: \" + str(numWeights) + \" = \" + str(numSamples))\n",
    "        sys.stdout.flush()\n",
    "        assert (features.shape[0] == numSamples), \\\n",
    "            \"Number of columns of features and weights differ\"\n",
    "        self.fprint(\"--> Calculate Hidden Activation 1\", self.print_flag)\n",
    "        H = self.calculateHiddenLayerActivation(features, 1)\n",
    "        self.fprint(\"Calculate Hidden Activation 1 -->\", self.print_flag)\n",
    "        Ht = H.t()\n",
    "        try:\n",
    "            scale = 1/(self.forgettingFactor)\n",
    "            aux = scale * self.M\n",
    "            self.M = aux -  torch.mm(aux,\n",
    "                                torch.mm(Ht, torch.mm(\n",
    "                                    torch.pinverse(torch.eye(numSamples) + torch.mm(H, torch.mm(aux, Ht))),\n",
    "                                    torch.mm(H, aux)\n",
    "                                    )\n",
    "                                )\n",
    "                            )\n",
    "            #...? Falta en el trozo de Alaiñe\n",
    "            if RESETTING:\n",
    "                beforeTrace=self.trace\n",
    "                self.trace=self.M.trace()\n",
    "                print (torch.abs(beforeTrace - self.trace))\n",
    "                if torch.abs(beforeTrace - self.trace) < self.thresReset:\n",
    "                    print (self.M)\n",
    "                    #eig,_=torch.eig(self.M, eigenvectors=True)\n",
    "                    eig,_=torch.eig(self.M, eigenvectors=False)\n",
    "                    lambMin=min(eig)\n",
    "                    lambMax=max(eig)\n",
    "                    #lamb = (lambMax+lambMin)/2\n",
    "                    lamb = lambMax\n",
    "                    lamb = lamb.real\n",
    "                    self.M= lamb*torch.eye(self.numHiddenNeurons)\n",
    "                    print (\"reset\")\n",
    "                    print (self.M)\n",
    "            #? ...\n",
    "            aux = self.forgettingFactor*self.beta\n",
    "            self.beta = aux +   torch.mm(\n",
    "                                    self.M, \n",
    "                                    torch.mm(Ht, targets - torch.mm(H, aux))\n",
    "                                )\n",
    "        except torch.linalg.LinAlgError:\n",
    "            print (\"SVD not converge, ignore the current training cycle\")\n",
    "\n",
    "        print(\"ORELM train -->\") \n",
    "    \n",
    "    def orelm_splitter(self, model): #Ver cómo escribirlo bien para que no de guerra\n",
    "        return [list(self.inputAE.parameters()), list(self.hiddenAE.parameters())]\n",
    "    \n",
    "    \n",
    "    def forward(self, features): #Predict\n",
    "        \"\"\"\n",
    "        Make prediction with feature matrix\n",
    "        :param features: feature matrix with dimension (numSamples, numInputs, time_steps)\n",
    "        :return: predictions with dimension (numSamples, numOutputs, time_steps)\n",
    "        \"\"\"\n",
    "\n",
    "        self.fprint(\"--> ORELM Forward\", self.print_flag)\n",
    "\n",
    "        (_, num_inputs, _)  = features.shape \n",
    "        assert num_inputs == self.inputs, \\\n",
    "            \"FOSELM ~ Invalid number of inputs for the model features ~ \" + str(features.shape) + \\\n",
    "                  \"num_inputs \" + str( num_inputs) \n",
    "\n",
    "        self.fprint(\"--> ORELM Calculate Hidden Activation 3\", self.print_flag)\n",
    "        self.fprint(\"ORELM Features ~ \" + str(features.shape), self.print_flag)\n",
    "        H = self.calculateHiddenLayerActivation(features,2 )\n",
    "        self.fprint(\"ORELM Get prediction\", self.print_flag)\n",
    "        prediction = torch.matmul(H, self.beta)\n",
    "        self.fprint(\"ORELM Calculate Hidden Activation 3 --> Features ~ \" + str(features.shape), self.print_flag)\n",
    "        print(\"ORELM Forward --> result ~ \" + str(prediction.shape))\n",
    "        return prediction        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "197a2562",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[0.7610, 0.8849, 0.3878, 0.9022, 0.6658, 0.5451, 0.7694, 0.9382,\n",
      "          0.0163, 0.0407, 0.5795, 0.1361, 0.2772, 0.5478, 0.4534, 0.7783,\n",
      "          0.6110, 0.5836, 0.8994, 0.0716, 0.3055, 0.3723, 0.6483, 0.7274,\n",
      "          0.6773, 0.4872, 0.7221, 0.0855, 0.1757, 0.6080, 0.6779, 0.0587,\n",
      "          0.0946, 0.1294, 0.2324, 0.3407, 0.1457, 0.6236, 0.9381, 0.6164,\n",
      "          0.5394, 0.1681, 0.9705, 0.0111, 0.7146, 0.8209, 0.5371, 0.9354]],\n",
      "\n",
      "        [[0.3764, 0.2050, 0.6222, 0.9329, 0.8208, 0.6351, 0.8877, 0.1968,\n",
      "          0.5386, 0.3968, 0.0889, 0.9493, 0.3365, 0.7428, 0.5363, 0.8361,\n",
      "          0.4192, 0.7279, 0.9594, 0.1738, 0.8017, 0.8979, 0.6681, 0.3260,\n",
      "          0.9741, 0.4791, 0.0251, 0.3857, 0.7384, 0.7745, 0.6473, 0.0871,\n",
      "          0.3717, 0.9305, 0.7989, 0.0722, 0.1155, 0.5438, 0.7354, 0.2599,\n",
      "          0.7566, 0.0797, 0.8565, 0.1156, 0.9854, 0.1915, 0.1503, 0.4660]],\n",
      "\n",
      "        [[0.5143, 0.7183, 0.0100, 0.0275, 0.6500, 0.1778, 0.6169, 0.5700,\n",
      "          0.1096, 0.6638, 0.8608, 0.7357, 0.3343, 0.2134, 0.0913, 0.4360,\n",
      "          0.1552, 0.6304, 0.4596, 0.4852, 0.9471, 0.2693, 0.9440, 0.2197,\n",
      "          0.9015, 0.0294, 0.9453, 0.8651, 0.9829, 0.2313, 0.9331, 0.7296,\n",
      "          0.8241, 0.8152, 0.3563, 0.4606, 0.3873, 0.6404, 0.9013, 0.8155,\n",
      "          0.1224, 0.0335, 0.1617, 0.4267, 0.5992, 0.9259, 0.8353, 0.9096]]])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "torch.Size([3, 1, 48])"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "foo = torch.rand(3, 1, 48)\n",
    "m = DCAE_torch(c_in=foo.shape[1], seq_len=foo.shape[2], delta=12)\n",
    "m(foo).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c616046d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "1c1a4a1d-389c-481a-a54d-3f86cd2115f5",
   "metadata": {},
   "source": [
    "### Dictionary to get the default backbone modules to get the embeddings from"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "3eb9f1b6-ae45-4b6e-b535-c7f121208721",
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "ENCODER_EMBS_MODULE_NAME = {\n",
    "    InceptionTimePlus: 'backbone', # for mvp based models\n",
    "    DCAE_torch: 'bottleneck.latent_in',\n",
    "    ORELM_torch: 'outputs'\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "268a268f-8b4e-4432-b203-79263a247c4c",
   "metadata": {},
   "source": [
    "### Getting the embeddings (activations) from the encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "65c66ae6-3178-49dc-bd16-64c082012e0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def get_enc_embs(X, enc_learn, module=None, cpu=False, average_seq_dim=True, to_numpy=True):\n",
    "    \"\"\"\n",
    "        Get the embeddings of X from an encoder, passed in `enc_learn as a fastai\n",
    "        learner. By default, the embeddings are obtained from the last layer\n",
    "        before the model head, although any layer can be passed to `model`.\n",
    "        Input\n",
    "        - `cpu`: Whether to do the model inference in cpu of gpu (GPU recommended)\n",
    "        - `average_seq_dim`: Whether to aggregate the embeddings in the sequence dimensions\n",
    "        - `to_numpy`: Whether to return the result as a numpy array (if false returns a tensor)\n",
    "    \"\"\"\n",
    "    if cpu:\n",
    "        enc_learn.dls.cpu()\n",
    "        enc_learn.cpu()\n",
    "    else:\n",
    "        enc_learn.dls.cuda()\n",
    "        enc_learn.cuda()\n",
    "    if enc_learn.dls.bs == 0: enc_learn.dls.bs = 64\n",
    "    aux_dl = enc_learn.dls.valid.new_dl(X=X)\n",
    "    aux_dl.bs = enc_learn.dls.bs if enc_learn.dls.bs>0 else 64\n",
    "    module = nested_attr(enc_learn.model,\n",
    "                         ENCODER_EMBS_MODULE_NAME[type(enc_learn.model)]) \\\n",
    "                if module is None else module\n",
    "    embs = [get_acts_and_grads(model=enc_learn.model,\n",
    "                               modules=module,\n",
    "                               x=xb[0], cpu=cpu)[0] for xb in aux_dl]\n",
    "    embs = to_concat(embs)\n",
    "    if embs.ndim == 3 and average_seq_dim: embs = embs.mean(axis=2)\n",
    "    if to_numpy: embs = embs.numpy() if cpu else embs.cpu().numpy()\n",
    "    return embs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "93dc6c6c-df80-44de-a49e-f27e86b8964a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m:   1 of 1 files downloaded.  \n"
     ]
    }
   ],
   "source": [
    "import wandb\n",
    "from dvats.utils import *\n",
    "wandb_api = wandb.Api()\n",
    "#enc_artifact = wandb_api.artifact('tchub/learner-mvp:run-tchub-3tipekxw')\n",
    "enc_artifact = wandb_api.artifact('mi-santamaria/test-project/dcae:v0')\n",
    "enc_learner = enc_artifact.to_obj()\n",
    "X = torch.rand(9, 1, 48)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "1bf504f6-a765-4a8e-b7e3-7ea521bdd96a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "UsageError: Line magic function `%%time` not found.\n"
     ]
    }
   ],
   "source": [
    "#slow\n",
    "%%time\n",
    "embs = get_enc_embs(X, enc_learner, cpu=True)\n",
    "test_eq(embs.shape[0], X.shape[0])\n",
    "embs.shape, embs.__class__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "2e4ddae2-e646-442f-86c2-2a8c8ad8606c",
   "metadata": {},
   "outputs": [
    {
     "ename": "AssertionError",
     "evalue": "Torch not compiled with CUDA enabled",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "File \u001b[0;32m<timed exec>:1\u001b[0m\n",
      "\u001b[1;32m/home/macu/work/nbs/encoder.ipynb Celda 15\u001b[0m line \u001b[0;36m1\n\u001b[1;32m     <a href='vscode-notebook-cell://attached-container%2B7b22636f6e7461696e65724e616d65223a222f64766174732d6a7570797465722d31222c2273657474696e6773223a7b22686f7374223a227373683a2f2f67342e6574736973692e75706d2e6573227d7d/home/macu/work/nbs/encoder.ipynb#X20sdnNjb2RlLXJlbW90ZQ%3D%3D?line=14'>15</a>\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m     <a href='vscode-notebook-cell://attached-container%2B7b22636f6e7461696e65724e616d65223a222f64766174732d6a7570797465722d31222c2273657474696e6773223a7b22686f7374223a227373683a2f2f67342e6574736973692e75706d2e6573227d7d/home/macu/work/nbs/encoder.ipynb#X20sdnNjb2RlLXJlbW90ZQ%3D%3D?line=15'>16</a>\u001b[0m     enc_learn\u001b[39m.\u001b[39mdls\u001b[39m.\u001b[39mcuda()\n\u001b[0;32m---> <a href='vscode-notebook-cell://attached-container%2B7b22636f6e7461696e65724e616d65223a222f64766174732d6a7570797465722d31222c2273657474696e6773223a7b22686f7374223a227373683a2f2f67342e6574736973692e75706d2e6573227d7d/home/macu/work/nbs/encoder.ipynb#X20sdnNjb2RlLXJlbW90ZQ%3D%3D?line=16'>17</a>\u001b[0m     enc_learn\u001b[39m.\u001b[39;49mcuda()\n\u001b[1;32m     <a href='vscode-notebook-cell://attached-container%2B7b22636f6e7461696e65724e616d65223a222f64766174732d6a7570797465722d31222c2273657474696e6773223a7b22686f7374223a227373683a2f2f67342e6574736973692e75706d2e6573227d7d/home/macu/work/nbs/encoder.ipynb#X20sdnNjb2RlLXJlbW90ZQ%3D%3D?line=17'>18</a>\u001b[0m \u001b[39mif\u001b[39;00m enc_learn\u001b[39m.\u001b[39mdls\u001b[39m.\u001b[39mbs \u001b[39m==\u001b[39m \u001b[39m0\u001b[39m: enc_learn\u001b[39m.\u001b[39mdls\u001b[39m.\u001b[39mbs \u001b[39m=\u001b[39m \u001b[39m64\u001b[39m\n\u001b[1;32m     <a href='vscode-notebook-cell://attached-container%2B7b22636f6e7461696e65724e616d65223a222f64766174732d6a7570797465722d31222c2273657474696e6773223a7b22686f7374223a227373683a2f2f67342e6574736973692e75706d2e6573227d7d/home/macu/work/nbs/encoder.ipynb#X20sdnNjb2RlLXJlbW90ZQ%3D%3D?line=18'>19</a>\u001b[0m aux_dl \u001b[39m=\u001b[39m enc_learn\u001b[39m.\u001b[39mdls\u001b[39m.\u001b[39mvalid\u001b[39m.\u001b[39mnew_dl(X\u001b[39m=\u001b[39mX)\n",
      "File \u001b[0;32m~/env/lib/python3.10/site-packages/torch/nn/modules/module.py:749\u001b[0m, in \u001b[0;36mModule.cuda\u001b[0;34m(self, device)\u001b[0m\n\u001b[1;32m    732\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mcuda\u001b[39m(\u001b[39mself\u001b[39m: T, device: Optional[Union[\u001b[39mint\u001b[39m, device]] \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m T:\n\u001b[1;32m    733\u001b[0m \u001b[39m    \u001b[39m\u001b[39mr\u001b[39m\u001b[39m\"\"\"Moves all model parameters and buffers to the GPU.\u001b[39;00m\n\u001b[1;32m    734\u001b[0m \n\u001b[1;32m    735\u001b[0m \u001b[39m    This also makes associated parameters and buffers different objects. So\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    747\u001b[0m \u001b[39m        Module: self\u001b[39;00m\n\u001b[1;32m    748\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 749\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_apply(\u001b[39mlambda\u001b[39;49;00m t: t\u001b[39m.\u001b[39;49mcuda(device))\n",
      "File \u001b[0;32m~/env/lib/python3.10/site-packages/torch/nn/modules/module.py:641\u001b[0m, in \u001b[0;36mModule._apply\u001b[0;34m(self, fn)\u001b[0m\n\u001b[1;32m    639\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_apply\u001b[39m(\u001b[39mself\u001b[39m, fn):\n\u001b[1;32m    640\u001b[0m     \u001b[39mfor\u001b[39;00m module \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mchildren():\n\u001b[0;32m--> 641\u001b[0m         module\u001b[39m.\u001b[39;49m_apply(fn)\n\u001b[1;32m    643\u001b[0m     \u001b[39mdef\u001b[39;00m \u001b[39mcompute_should_use_set_data\u001b[39m(tensor, tensor_applied):\n\u001b[1;32m    644\u001b[0m         \u001b[39mif\u001b[39;00m torch\u001b[39m.\u001b[39m_has_compatible_shallow_copy_type(tensor, tensor_applied):\n\u001b[1;32m    645\u001b[0m             \u001b[39m# If the new tensor has compatible tensor type as the existing tensor,\u001b[39;00m\n\u001b[1;32m    646\u001b[0m             \u001b[39m# the current behavior is to change the tensor in-place using `.data =`,\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    651\u001b[0m             \u001b[39m# global flag to let the user control whether they want the future\u001b[39;00m\n\u001b[1;32m    652\u001b[0m             \u001b[39m# behavior of overwriting the existing tensor or not.\u001b[39;00m\n",
      "File \u001b[0;32m~/env/lib/python3.10/site-packages/torch/nn/modules/module.py:641\u001b[0m, in \u001b[0;36mModule._apply\u001b[0;34m(self, fn)\u001b[0m\n\u001b[1;32m    639\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_apply\u001b[39m(\u001b[39mself\u001b[39m, fn):\n\u001b[1;32m    640\u001b[0m     \u001b[39mfor\u001b[39;00m module \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mchildren():\n\u001b[0;32m--> 641\u001b[0m         module\u001b[39m.\u001b[39;49m_apply(fn)\n\u001b[1;32m    643\u001b[0m     \u001b[39mdef\u001b[39;00m \u001b[39mcompute_should_use_set_data\u001b[39m(tensor, tensor_applied):\n\u001b[1;32m    644\u001b[0m         \u001b[39mif\u001b[39;00m torch\u001b[39m.\u001b[39m_has_compatible_shallow_copy_type(tensor, tensor_applied):\n\u001b[1;32m    645\u001b[0m             \u001b[39m# If the new tensor has compatible tensor type as the existing tensor,\u001b[39;00m\n\u001b[1;32m    646\u001b[0m             \u001b[39m# the current behavior is to change the tensor in-place using `.data =`,\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    651\u001b[0m             \u001b[39m# global flag to let the user control whether they want the future\u001b[39;00m\n\u001b[1;32m    652\u001b[0m             \u001b[39m# behavior of overwriting the existing tensor or not.\u001b[39;00m\n",
      "File \u001b[0;32m~/env/lib/python3.10/site-packages/torch/nn/modules/module.py:641\u001b[0m, in \u001b[0;36mModule._apply\u001b[0;34m(self, fn)\u001b[0m\n\u001b[1;32m    639\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_apply\u001b[39m(\u001b[39mself\u001b[39m, fn):\n\u001b[1;32m    640\u001b[0m     \u001b[39mfor\u001b[39;00m module \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mchildren():\n\u001b[0;32m--> 641\u001b[0m         module\u001b[39m.\u001b[39;49m_apply(fn)\n\u001b[1;32m    643\u001b[0m     \u001b[39mdef\u001b[39;00m \u001b[39mcompute_should_use_set_data\u001b[39m(tensor, tensor_applied):\n\u001b[1;32m    644\u001b[0m         \u001b[39mif\u001b[39;00m torch\u001b[39m.\u001b[39m_has_compatible_shallow_copy_type(tensor, tensor_applied):\n\u001b[1;32m    645\u001b[0m             \u001b[39m# If the new tensor has compatible tensor type as the existing tensor,\u001b[39;00m\n\u001b[1;32m    646\u001b[0m             \u001b[39m# the current behavior is to change the tensor in-place using `.data =`,\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    651\u001b[0m             \u001b[39m# global flag to let the user control whether they want the future\u001b[39;00m\n\u001b[1;32m    652\u001b[0m             \u001b[39m# behavior of overwriting the existing tensor or not.\u001b[39;00m\n",
      "File \u001b[0;32m~/env/lib/python3.10/site-packages/torch/nn/modules/module.py:664\u001b[0m, in \u001b[0;36mModule._apply\u001b[0;34m(self, fn)\u001b[0m\n\u001b[1;32m    660\u001b[0m \u001b[39m# Tensors stored in modules are graph leaves, and we don't want to\u001b[39;00m\n\u001b[1;32m    661\u001b[0m \u001b[39m# track autograd history of `param_applied`, so we have to use\u001b[39;00m\n\u001b[1;32m    662\u001b[0m \u001b[39m# `with torch.no_grad():`\u001b[39;00m\n\u001b[1;32m    663\u001b[0m \u001b[39mwith\u001b[39;00m torch\u001b[39m.\u001b[39mno_grad():\n\u001b[0;32m--> 664\u001b[0m     param_applied \u001b[39m=\u001b[39m fn(param)\n\u001b[1;32m    665\u001b[0m should_use_set_data \u001b[39m=\u001b[39m compute_should_use_set_data(param, param_applied)\n\u001b[1;32m    666\u001b[0m \u001b[39mif\u001b[39;00m should_use_set_data:\n",
      "File \u001b[0;32m~/env/lib/python3.10/site-packages/torch/nn/modules/module.py:749\u001b[0m, in \u001b[0;36mModule.cuda.<locals>.<lambda>\u001b[0;34m(t)\u001b[0m\n\u001b[1;32m    732\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mcuda\u001b[39m(\u001b[39mself\u001b[39m: T, device: Optional[Union[\u001b[39mint\u001b[39m, device]] \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m T:\n\u001b[1;32m    733\u001b[0m \u001b[39m    \u001b[39m\u001b[39mr\u001b[39m\u001b[39m\"\"\"Moves all model parameters and buffers to the GPU.\u001b[39;00m\n\u001b[1;32m    734\u001b[0m \n\u001b[1;32m    735\u001b[0m \u001b[39m    This also makes associated parameters and buffers different objects. So\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    747\u001b[0m \u001b[39m        Module: self\u001b[39;00m\n\u001b[1;32m    748\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 749\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_apply(\u001b[39mlambda\u001b[39;00m t: t\u001b[39m.\u001b[39;49mcuda(device))\n",
      "File \u001b[0;32m~/env/lib/python3.10/site-packages/torch/cuda/__init__.py:221\u001b[0m, in \u001b[0;36m_lazy_init\u001b[0;34m()\u001b[0m\n\u001b[1;32m    217\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mRuntimeError\u001b[39;00m(\n\u001b[1;32m    218\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mCannot re-initialize CUDA in forked subprocess. To use CUDA with \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    219\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mmultiprocessing, you must use the \u001b[39m\u001b[39m'\u001b[39m\u001b[39mspawn\u001b[39m\u001b[39m'\u001b[39m\u001b[39m start method\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m    220\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mhasattr\u001b[39m(torch\u001b[39m.\u001b[39m_C, \u001b[39m'\u001b[39m\u001b[39m_cuda_getDeviceCount\u001b[39m\u001b[39m'\u001b[39m):\n\u001b[0;32m--> 221\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mAssertionError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39mTorch not compiled with CUDA enabled\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m    222\u001b[0m \u001b[39mif\u001b[39;00m _cudart \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    223\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mAssertionError\u001b[39;00m(\n\u001b[1;32m    224\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mlibcudart functions unavailable. It looks like you have a broken build?\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "\u001b[0;31mAssertionError\u001b[0m: Torch not compiled with CUDA enabled"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "embs = get_enc_embs(X, enc_learner, cpu=False, to_numpy=False)\n",
    "test_eq(embs.shape[0], X.shape[0])\n",
    "embs.shape, embs.__class__, embs.device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed7336d9-7e63-4635-8552-4a5d86492ff1",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "embs = get_enc_embs(X, enc_learner, cpu=False, to_numpy=True)\n",
    "test_eq(embs.shape[0], X.shape[0])\n",
    "embs.shape, embs.__class__"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "824e92c8-3932-470f-8f6a-1b7810032c18",
   "metadata": {},
   "source": [
    "## Export -"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11c6132f-be0d-4e4e-abab-754cbe9a365c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#hide\n",
    "from nbdev.export import notebook2script\n",
    "notebook2script()\n",
    "beep(1)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "d45d555be0220b07bf61be557bfa0ebbf7a95015976aec9a23277863e1bd4593"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
